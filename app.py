import streamlit as st
import pdfplumber
import pandas as pd
import re
import io
from dateutil import parser

# ==========================================
# 1. é—œéµå­—å®šç¾© (åŒ–å­¸ç‰©è³ª)
# ==========================================

TARGET_ITEMS = [
    "Pb", "Cd", "Hg", "Cr6+", "PBBs", "PBDEs",
    "DEHP", "DBP", "BBP", "DIBP",
    "F", "Cl", "Br", "I",
    "PFOS", "PFAS", "DATE", "FILENAME"
]

# åŒ–å­¸ç‰©è³ªé—œéµå­—æ˜ å°„
KEYWORDS_MAP = {
    r"(?i)\b(Lead|Pb)\b": "Pb",
    r"(?i)\b(Cadmium|Cd)\b": "Cd",
    r"(?i)\b(Mercury|Hg)\b": "Hg",
    r"(?i)\b(Hexavalent Chromium|Cr\(?VI\)?|Cr6\+)\b": "Cr6+",
    r"(?i)\b(DEHP|Di\(2-ethylhexyl\)\s*phthalate)\b": "DEHP",
    r"(?i)\b(DBP|Dibutyl\s*phthalate)\b": "DBP",
    r"(?i)\b(BBP|Butyl\s*benzyl\s*phthalate)\b": "BBP",
    r"(?i)\b(DIBP|Diisobutyl\s*phthalate)\b": "DIBP",
    r"(?i)\b(Fluorine|F)\b": "F",
    r"(?i)\b(Chlorine|Cl)\b": "Cl",
    r"(?i)\b(Bromine|Br)\b": "Br",
    r"(?i)\b(Iodine|I)\b": "I",
    r"(?i)\b(PFOS|Perfluorooctane\s*sulfonates)\b": "PFOS"
}

# å­é …åŠ ç¸½ç‰¹å¾µ
PBB_SUBITEMS = r"(?i)(Monobromobiphenyl|Dibromobiphenyl|Tribromobiphenyl|Tetrabromobiphenyl|Pentabromobiphenyl|Hexabromobiphenyl|Heptabromobiphenyl|Octabromobiphenyl|Nonabromobiphenyl|Decabromobiphenyl)"
PBDE_SUBITEMS = r"(?i)(Monobromodiphenyl ether|Dibromodiphenyl ether|Tribromodiphenyl ether|Tetrabromodiphenyl ether|Pentabromodiphenyl ether|Hexabromodiphenyl ether|Heptabromodiphenyl ether|Octabromodiphenyl ether|Nonabromodiphenyl ether|Decabromodiphenyl ether)"

# ==========================================
# 2. æ ¸å¿ƒé‚è¼¯ï¼šæ—¥æœŸæå–èˆ‡æ¨™æº–åŒ–
# ==========================================

def standardize_date(date_str):
    """
    å°‡å„ç¨®é›œäº‚çš„æ—¥æœŸæ ¼å¼çµ±ä¸€è½‰æ›ç‚º YYYY/MM/DD
    """
    if not date_str:
        return "Unknown"
    
    # æ¸…ç†é›œè¨Š
    clean_str = str(date_str).strip()
    
    # 1. è™•ç†ä¸­æ–‡æ ¼å¼ (2024å¹´10æœˆ10æ—¥ -> 2024/10/10)
    clean_str = clean_str.replace("å¹´", "/").replace("æœˆ", "/").replace("æ—¥", "")
    
    # 2. è™•ç†éŸ“æ–‡/ISO å¸¶é»æ ¼å¼ (2024. 10. 17. -> 2024/10/17)
    clean_str = clean_str.replace(".", "/").strip("/") 
    
    try:
        # ä½¿ç”¨ fuzzy=True è‡ªå‹•å¿½ç•¥æ—¥æœŸå­—ä¸²ä¸­çš„éæ—¥æœŸæ–‡å­— (å¦‚ 'Date:', 'No.:')
        dt = parser.parse(clean_str, fuzzy=True)
        # å¼·åˆ¶æ ¼å¼åŒ–ç‚º YYYY/MM/DD
        return dt.strftime("%Y/%m/%d")
    except:
        return clean_str # è§£æå¤±æ•—å›å‚³åŸå€¼ï¼Œæ–¹ä¾¿é™¤éŒ¯

def extract_report_date(text_page1):
    """
    é›™å€å¡Šæƒæç­–ç•¥ (Head-then-Tail) + é»‘åå–®éæ¿¾
    """
    lines = text_page1.split('\n')
    found_date_str = None
    
    # --- å®šç¾©é—œéµå­— ---
    # é»‘åå–®ï¼šè‹¥è©²è¡Œå‡ºç¾é€™äº›å­—ï¼Œçµ•å°ä¸æ˜¯å ±å‘Šæ—¥æœŸ
    BLACKLIST = [r"(?i)Receive", r"(?i)Period", r"(?i)Tested", r"(?i)Due", r"(?i)Sample"]
    
    # ç™½åå–®ï¼šæ˜ç¢ºçš„å ±å‘Šæ—¥æœŸæ¨™ç±¤ (è‹±/ä¸­/éŸ“)
    # æ³¨æ„ï¼šSGS æœ‰æ™‚åªå¯« "Date:"ï¼ŒCTI æœ‰æ™‚åœ¨ç°½åå€å¯« "Date"
    LABEL_PATTERNS = [
        r"(?i)Report\s*Date", 
        r"(?i)Issue\s*Date", 
        r"æŠ¥å‘Šæ—¥æœŸ", 
        r"æ—¥æœŸ", 
        r"ë°œí–‰ì¼ì",
        r"(?i)^Date\s*[:ï¼š]", # åš´æ ¼çš„ Date é–‹é ­
        r"(?i)Date\s*[:ï¼š]"   # ä¸€èˆ¬ Date æ¨™ç±¤
    ]

    # æ—¥æœŸæ•¸å€¼æ­£å‰‡ (è¼”åŠ©æŠ“å–ç„¡æ¨™ç±¤çš„æ—¥æœŸï¼Œå¦‚ CTI ç°½åæ—)
    # æŠ“å– 202x-xx-xx æˆ– 202x/xx/xx æˆ– 202x.xx.xx
    DATE_VALUE_PATTERN = r"(20\d{2}[-./å¹´]\s?\d{1,2}[-./æœˆ]\s?\d{1,2}[æ—¥]?|[A-Za-z]{3}\s+\d{1,2},\s+20\d{2})"

    # --- ç­–ç•¥ 1: æƒæé é¦– (å‰ 20 è¡Œ) ---
    for i, line in enumerate(lines[:25]):
        # 1. é»‘åå–®æª¢æŸ¥
        if any(re.search(b, line) for b in BLACKLIST):
            continue
            
        # 2. ç™½åå–®æ¨™ç±¤æª¢æŸ¥
        for label in LABEL_PATTERNS:
            if re.search(label, line):
                # å˜—è©¦æå–æ¨™ç±¤å¾Œçš„å…§å®¹
                # ä¾‹å¦‚ "Date: 2024/10/10" -> æŠ“å– "2024/10/10"
                # åˆ©ç”¨ split æŠ“å†’è™Ÿå¾Œé¢çš„æ±è¥¿ï¼Œæˆ–æ˜¯åˆ©ç”¨ regex æŠ“å–æ—¥æœŸæ ¼å¼
                match = re.search(DATE_VALUE_PATTERN, line)
                if match:
                    return standardize_date(match.group(0))
                
                # è‹¥ç„¡æ˜é¡¯æ—¥æœŸæ ¼å¼ï¼Œå˜—è©¦æŠ“æ¨™ç±¤å¾Œçš„å‰©é¤˜å­—ä¸²
                parts = re.split(r"[:ï¼š]", line, 1)
                if len(parts) > 1 and len(parts[1].strip()) > 5:
                    return standardize_date(parts[1])

    # --- ç­–ç•¥ 2: æƒæé å°¾ (å¾Œ 15 è¡Œ) ---
    # é‡å° CTI é€™ç¨®ç°½ååœ¨åº•éƒ¨çš„å ±å‘Š
    total_lines = len(lines)
    start_line = max(0, total_lines - 20)
    
    for line in lines[start_line:]:
        # å°‹æ‰¾ "Date" é—œéµå­—é™„è¿‘çš„æ—¥æœŸ
        if re.search(r"(?i)Date", line) or re.search(r"\d{4}", line): # å¯¬é¬†æ¢ä»¶
             match = re.search(DATE_VALUE_PATTERN, line)
             if match:
                 # å†æ¬¡ç¢ºèªä¸æ˜¯é»‘åå–® (é›–ç„¶é å°¾å¾ˆå°‘å‡ºç¾æ”¶ä»¶æ—¥æœŸ)
                 if not any(re.search(b, line) for b in BLACKLIST):
                     return standardize_date(match.group(0))

    return "Unknown"

# ==========================================
# 3. æ•¸å€¼æ¸…ç†èˆ‡è™•ç†
# ==========================================

def clean_value(val_str):
    if not val_str: return None
    val_str = str(val_str).strip()
    if re.search(r"(?i)(n\.?d\.?|not detected|<)", val_str): return "N.D."
    if re.search(r"(?i)negative", val_str): return "NEGATIVE"
    match = re.search(r"(\d+\.?\d*)", val_str)
    if match: return float(match.group(1))
    return "N.D."

def get_value_priority(val):
    if isinstance(val, (int, float)): return (3, val)
    if val == "NEGATIVE": return (2, 0)
    if val == "N.D.": return (1, 0)
    return (0, 0)

# ==========================================
# 4. å–®ä¸€æª”æ¡ˆè™•ç†é‚è¼¯
# ==========================================

def process_single_file(uploaded_file):
    filename = uploaded_file.name
    result = {k: None for k in TARGET_ITEMS}
    result["FILENAME"] = filename
    
    pbb_sum = 0
    pbde_sum = 0
    pbb_found = False
    pbde_found = False
    
    try:
        with pdfplumber.open(uploaded_file) as pdf:
            full_text = ""
            
            for i, page in enumerate(pdf.pages):
                text = page.extract_text()
                if not text: continue
                full_text += text + "\n"

                # *** æ—¥æœŸæŠ“å–åƒ…é‡å°ç¬¬ä¸€é  ***
                if i == 0:
                    result["DATE"] = extract_report_date(text)

                # è¡¨æ ¼æ•¸æ“šæå–
                tables = page.extract_tables()
                if tables:
                    for table in tables:
                        for row in table:
                            # å°‡ row è½‰ç‚ºå­—ä¸²ä¸¦ç§»é™¤æ›è¡Œç¬¦è™Ÿä»¥ä¾¿ regex æœå°‹
                            row_str = " ".join([str(cell) for cell in row if cell]).replace("\n", " ")
                            
                            # ä¸€èˆ¬ç‰©è³ªæå–
                            for pattern, key in KEYWORDS_MAP.items():
                                if re.search(pattern, row_str):
                                    raw_cells = [str(cell).strip() for cell in row if cell]
                                    cleaned_values = [clean_value(c) for c in raw_cells]
                                    
                                    # éæ¿¾ Limit å€¼ (é¿å…æŠ“åˆ° 100/1000)
                                    valid_vals = []
                                    for val in cleaned_values:
                                        if isinstance(val, (int, float)):
                                            valid_vals.append(val)
                                        elif val in ["N.D.", "NEGATIVE"]:
                                            valid_vals.append(val)
                                    
                                    final_val = None
                                    if valid_vals:
                                        final_val = valid_vals[-1] # å–æœ€å¾Œä¸€å€‹æœ‰æ•ˆå€¼
                                        # ç°¡å–®é˜²å‘†
                                        if isinstance(final_val, (int, float)) and final_val in [100.0, 1000.0]:
                                            others = [v for v in valid_vals if v != final_val]
                                            if others: final_val = others[-1]

                                    if final_val is not None:
                                        priority_curr = get_value_priority(result[key])
                                        priority_new = get_value_priority(final_val)
                                        if priority_new > priority_curr:
                                            result[key] = final_val
                                        break 

                            # PBBs åŠ ç¸½
                            if re.search(PBB_SUBITEMS, row_str):
                                pbb_found = True
                                cells = [clean_value(str(cell)) for cell in row if cell]
                                for val in cells:
                                    if isinstance(val, (int, float)) and val not in [100.0, 1000.0]:
                                        pbb_sum += val
                                        break
                            
                            # PBDEs åŠ ç¸½
                            if re.search(PBDE_SUBITEMS, row_str):
                                pbde_found = True
                                cells = [clean_value(str(cell)) for cell in row if cell]
                                for val in cells:
                                    if isinstance(val, (int, float)) and val not in [100.0, 1000.0]:
                                        pbde_sum += val
                                        break

            # PFAS å…¨æ–‡æœç´¢
            if "PFAS" in full_text or "Per- and polyfluoroalkyl substances" in full_text:
                result["PFAS"] = "REPORT"
            else:
                result["PFAS"] = ""

            result["PBBs"] = pbb_sum if pbb_found and pbb_sum > 0 else "N.D."
            result["PBDEs"] = pbde_sum if pbde_found and pbde_sum > 0 else "N.D."

            return result

    except Exception as e:
        st.error(f"Error processing {filename}: {e}")
        return None

# ==========================================
# 5. Streamlit ä¸»ç¨‹å¼
# ==========================================

def main():
    st.set_page_config(page_title="RoHS å ±å‘Šå½™æ•´å·¥å…·", layout="wide")
    st.title("ğŸ“„ åŒ–å­¸æ¸¬è©¦å ±å‘Šè‡ªå‹•å½™æ•´å·¥å…·")
    st.markdown("""
    **åŠŸèƒ½èªªæ˜ï¼š**
    1. æ”¯æ´ SGSã€CTIã€Intertek ç­‰å¤šç¨®å ±å‘Šæ ¼å¼ã€‚
    2. è‡ªå‹•æŠ“å– **å ±å‘Šç™¼è¡Œæ—¥æœŸ** ä¸¦çµ±ä¸€æ ¼å¼ç‚º `YYYY/MM/DD`ã€‚
    3. è‡ªå‹•éæ¿¾æ³•è¦é™å€¼ (Limit)ï¼ŒåªæŠ“å–æ¸¬è©¦çµæœ (Result)ã€‚
    """)

    uploaded_files = st.file_uploader("è«‹é¸æ“‡ PDF æª”æ¡ˆ (å¯å¤šé¸)", type="pdf", accept_multiple_files=True)

    if uploaded_files:
        if st.button("é–‹å§‹åˆ†æ"):
            with st.spinner("æ­£åœ¨è®€å–ä¸¦åˆ†æ PDF..."):
                all_results = []
                progress_bar = st.progress(0)
                
                for i, file in enumerate(uploaded_files):
                    res = process_single_file(file)
                    if res:
                        all_results.append(res)
                    progress_bar.progress((i + 1) / len(uploaded_files))
                
                if not all_results:
                    st.warning("æœªèƒ½å¾æª”æ¡ˆä¸­æå–åˆ°æœ‰æ•ˆæ•¸æ“šã€‚")
                    return

                # å»ºç«‹ DataFrame
                df_detail = pd.DataFrame(all_results)
                
                # èª¿æ•´æ¬„ä½é †åºï¼šFILENAME, DATE æ”¾æœ€å‰é¢
                cols = ["FILENAME", "DATE"] + [c for c in TARGET_ITEMS if c not in ["FILENAME", "DATE"]]
                df_detail = df_detail[cols]

                st.success("åˆ†æå®Œæˆï¼")
                st.subheader("ğŸ“Š åˆ†æçµæœé è¦½")
                st.dataframe(df_detail)

                # åŒ¯å‡º Excel
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df_detail.to_excel(writer, index=False, sheet_name='Summary')
                
                output.seek(0)
                
                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰ Excel å ±å‘Š",
                    data=output,
                    file_name=f"RoHS_Summary_{pd.Timestamp.now().strftime('%Y%m%d')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

if __name__ == "__main__":
    main()
