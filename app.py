import streamlit as st
import pdfplumber
import pandas as pd
import re
from dateutil import parser
import io

st.set_page_config(page_title="SGS Report Parser", layout="wide")
st.title("ğŸ“„ SGS Report æª¢æ¸¬çµæœå½™ç¸½å·¥å…· (é¦¬ä¾†è¥¿äºä¿®æ­£ç‰ˆ)")

# =========================
# [cite_start]æ¬„ä½å®šç¾©ï¼ˆé †åºå›ºå®šï¼‰ [cite: 1, 2]
# =========================
ITEM_RULES = {
    "Pb": r"Lead\s*\(Pb\)",
    "Cd": r"Cadmium\s*\(Cd\)",
    "Hg": r"Mercury\s*\(Hg\)",
    "CrVI": r"Hexavalent Chromium",
    "PBBs": r"Sum of PBBs",
    "PBDEs": r"Sum of PBDEs",
    "DEHP": r"DEHP",
    "BBP": r"BBP",
    "DBP": r"DBP",
    "DIBP": r"DIBP",
    "F": r"Fluorine",
    "CL": r"Chlorine",
    "BR": r"Bromine",
    "I": r"Iodine",
    "PFOS": r"PFOS"
}

FINAL_COLUMNS = [
    "Pb","Cd","Hg","CrVI","PBBs","PBDEs",
    "DEHP","BBP","DBP","DIBP",
    "F","CL","BR","I",
    "PFOS","PFAS","DATE"
]

# =========================
# å·¥å…·å‡½å¼
# =========================
def extract_text_and_pages(pdf_file):
    full_text = ""
    pages_text = []
    with pdfplumber.open(pdf_file) as pdf:
        for page in pdf.pages:
            text = page.extract_text() or ""
            pages_text.append(text)
            full_text += text + "\n"
    [cite_start]return full_text, pages_text [cite: 3]


def extract_result(text, keyword):
    """
    ä¿®æ­£ç‰ˆ V4 (åŒ…å«é™¤å™ªèˆ‡å„ªå…ˆåˆ¤å®š N.D. é‚è¼¯)ï¼š
    1. å¼·åŠ›æ¸…æ´—ï¼šåœ¨è®€å–æ•¸æ“šå‰ï¼Œå¼·åˆ¶åˆªé™¤ Max, MDL, CAS, Year ç­‰å¹²æ“¾é …ã€‚
    2. N.D. å„ªå…ˆï¼šåªè¦åµæ¸¬åˆ° N.D. è®Šé«”ï¼Œç›´æ¥å›å‚³æ¨™æº– "N.D."ï¼Œä¸çœ‹å¾ŒçºŒæ•¸å­—ã€‚
    3. æŠ“å–æ•¸å€¼ï¼šåªåœ¨æ²’æœ‰ N.D. æ™‚æ‰æŠ“å–å‰©é¤˜çš„ç¬¬ä¸€å€‹æ•¸å­—ã€‚
    """
    lines = text.splitlines()

    for i, line in enumerate(lines):
        # æ­¥é©Ÿ A: é–å®šé—œéµå­—æ‰€åœ¨çš„è¡Œ
        if re.search(keyword, line, re.IGNORECASE):
            # æŠ“å–ä¸Šä¸‹æ–‡ (ç•¶è¡Œ + ä¸‹ä¸€è¡Œ)ï¼Œç¸®å°ç¯„åœé¿å…æŠ“åˆ°éš”å£æ¬„ä½
            context = " ".join(lines[i:i+2])

            # ==========================================
            # æ­¥é©Ÿ B: æ‰‹è¡“å®¤ - å¼·åŠ›åˆ‡é™¤å¹²æ“¾æº (é †åºå¾ˆé‡è¦)
            # ==========================================
            
            # 1. åˆ‡é™¤å–®ä½ (mg/kg, ppm, %, wt%)
            context = re.sub(r"mg/kg|ppm|%|wt%", " ", context, flags=re.IGNORECASE)

            # 2. åˆ‡é™¤ CAS No. (ä¾‹å¦‚ "(CAS No. 84-74-2)" -> åˆªé™¤æ•´å€‹æ‹¬è™Ÿå…§å®¹)
            # é¿å…æŠ“åˆ° 84 æˆ– 117
            context = re.sub(r"\(?CAS\s*No\.?[\s\d-]+\)?", " ", context, flags=re.IGNORECASE)

            # 3. åˆ‡é™¤ æ¨™æº–ç·¨è™Ÿèˆ‡å¹´ä»½ (ä¾‹å¦‚ "IEC 62321-5:2013")
            # é€™ä¸€æ­¥éå¸¸é—œéµï¼Œé¿å…æŠ“åˆ° 2013, 2017
            context = re.sub(r"IEC\s*62321[-\d:+A]*", " ", context, flags=re.IGNORECASE)
            # é¡å¤–æ¸…é™¤ç¨ç«‹çš„å¹´ä»½ (1990-2030)
            context = re.sub(r"\b(19|20)\d{2}\b", " ", context)

            # 4. åˆ‡é™¤ Limit / MDL æ¨™ç±¤èˆ‡æ•¸å€¼ (ä¾‹å¦‚ "Max 1000", "MDL 2")
            # é¿å…æŠ“åˆ° 1000 æˆ– 2 (æ”¯æ´å°æ•¸é»)
            context = re.sub(r"(Max|Limit|MDL|LOQ)\s*\d+(\.\d+)?", " ", context, flags=re.IGNORECASE)

            # ==========================================
            # æ­¥é©Ÿ C: åˆ¤æ–·çµæœ - N.D. å„ªå…ˆ
            # ==========================================

            # è¦å‰‡ï¼šè©ç•Œ(\b) + N + ä»»æ„é»æˆ–ç©º + D + è©ç•Œ OR Not Detected
            # é€™å¯ä»¥æŠ“åˆ°: "N.D.", "ND", "N. D.", "Not Detected"
            nd_pattern = r"(\bN\s*\.?\s*D\s*\.?\b)|(Not\s*Detected)"
            
            if re.search(nd_pattern, context, re.IGNORECASE):
                # æ‚¨çš„éœ€æ±‚ï¼šä¸ç®¡åŸæ–‡å¯«ä»€éº¼ï¼Œçµ±ä¸€å›å‚³ "N.D."
                return "N.D."

            # åˆ¤æ–· NEGATIVE
            if re.search(r"NEGATIVE", context, re.IGNORECASE):
                return "NEGATIVE"

            # ==========================================
            # æ­¥é©Ÿ D: æŠ“å–æ•¸å€¼
            # ==========================================
            
            # å› ç‚ºä¸Šé¢å·²ç¶“æŠŠ Max, MDL, Year éƒ½åˆªäº†ï¼Œ
            # é€™è£¡æŠ“åˆ°çš„ç¬¬ä¸€å€‹æ•¸å­—ï¼Œæ¥µå¤§æ©Ÿç‡å°±æ˜¯çœŸæ­£çš„æª¢æ¸¬çµæœ
            nums = re.findall(r"\b\d+(\.\d+)?\b", context)
            
            if nums:
                # nums å›å‚³ list of tuplesï¼Œå–ç¬¬ä¸€å€‹åŒ¹é…åˆ°çš„æ•¸å­—å­—ä¸²
                found_value = nums[0][0] 
                
                # æœ€å¾Œä¸€é“é˜²ç·šï¼šé›–ç„¶å‰é¢å·²ç¶“åˆªäº†å¹´ä»½ï¼Œä½†ä»¥é˜²è¬ä¸€å†æ“‹ä¸€æ¬¡
                try:
                    val_float = float(found_value)
                    # å¦‚æœæŠ“åˆ° 2025 é€™ç¨®æ•´æ•¸ï¼Œä¸”çœ‹èµ·ä¾†åƒå¹´ä»½ï¼Œå°±å¿½ç•¥
                    if 1990 <= val_float <= 2030 and val_float.is_integer():
                        continue 
                    return found_value
                except:
                    pass

    return ""


def extract_pfas(text):
    [cite_start]return "REPORT" if re.search(r"\bPFAS\b", text, re.IGNORECASE) else "" [cite: 6]


def extract_date(first_page_text):
    match = re.search(
        r"(REPORTED DATE|TEST REPORT REPORTED DATE)\s*[:\-]?\s*([^\n]+)",
        first_page_text,
        re.IGNORECASE
    )
    [cite_start]return match.group(2).strip() if match else "" [cite: 6]


def normalize_date(date_text):
    if not date_text:
        return ""
    try:
        dt = parser.parse(date_text, dayfirst=True)
        return dt.strftime("%Y/%m/%d")
    except:
        [cite_start]return "" [cite: 7]


def merge_results(values):
    """
    å½™ç¸½é‚è¼¯ï¼šåŒæ‰¹æ¬¡å–æœ€å¤§å€¼ï¼Œè‹¥æœ‰ N.D. å‰‡å„ªå…ˆç´šä½æ–¼æ•¸å€¼
    """
    nums = []
    has_nd = False
    has_neg = False

    for v in values:
        if not v:
            continue
        v_upper = str(v).upper()
        
        if "N.D." in v_upper:
            has_nd = True
        elif "NEGATIVE" in v_upper:
            has_neg = True
        else:
            try:
                nums.append(float(v))
            except:
                pass

    if nums:
        return str(max(nums))
    if has_neg:
        return "NEGATIVE"
    if has_nd:
        return "N.D."
    [cite_start]return "" [cite: 8, 9, 10]


# =========================
# UI èˆ‡ä¸»æµç¨‹
# =========================
uploaded_files = st.file_uploader(
    "è«‹ä¸Šå‚³ SGS PDF Reportï¼ˆå¯ä¸€æ¬¡å¤šé¸ï¼‰",
    type="pdf",
    accept_multiple_files=True
[cite_start]) [cite: 10]

if uploaded_files:
    rows = []

    for file in uploaded_files:
        full_text, pages_text = extract_text_and_pages(file)

        record = {}

        # å„æª¢æ¸¬é …ç›®
        for item, keyword in ITEM_RULES.items():
            record[item] = extract_result(full_text, keyword)

        # PFASï¼ˆæ˜¯å¦æœ‰æ¸¬ï¼‰
        record["PFAS"] = extract_pfas(full_text)

        # DATEï¼ˆåªçœ‹ç¬¬ä¸€é ï¼‰
        raw_date = extract_date(pages_text[0]) if pages_text else ""
        record["DATE"] = normalize_date(raw_date)

        [cite_start]rows.append(record) [cite: 11]

    df_all = pd.DataFrame(rows)

    # ===== åŒæ‰¹ PDF å½™ç¸½ï¼ˆæœ€åš´æ ¼çµæœï¼‰=====
    merged = {}
    if not df_all.empty:
        for col in FINAL_COLUMNS:
            if col in ["DATE", "PFAS"]:
                continue
            # ç¢ºä¿æ¬„ä½å­˜åœ¨
            if col in df_all.columns:
                merged[col] = merge_results(df_all[col].tolist())
            else:
                merged[col] = ""

        # PFAS é‚è¼¯
        merged["PFAS"] = "REPORT" if "REPORT" in df_all["PFAS"].tolist() else ""
        
        # DATE é‚è¼¯ (å–æœ€æ–°)
        valid_dates = [d for d in df_all["DATE"] if d]
        merged["DATE"] = max(valid_dates) if valid_dates else ""

        [cite_start]df_final = pd.DataFrame([merged], columns=FINAL_COLUMNS) [cite: 12]

        # ===== é¡¯ç¤ºçµæœ =====
        st.subheader("ğŸ“Š å½™ç¸½çµæœï¼ˆåŒæ‰¹ SGS Reportï¼‰")
        st.dataframe(df_final, use_container_width=True)

        # ===== Excel åŒ¯å‡º =====
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df_final.to_excel(writer, sheet_name="SGS_Result", index=False)

        st.download_button(
            "â¬‡ï¸ ä¸‹è¼‰å…¬å¸åˆ¶å¼ Excel",
            output.getvalue(),
            file_name="SGS_Test_Result.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        [cite_start]) [cite: 13]
    else:
        st.warning("ç„¡æ³•è®€å–è³‡æ–™ï¼Œè«‹ç¢ºèª PDF å…§å®¹ã€‚")
