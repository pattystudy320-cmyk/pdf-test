import streamlit as st
import pdfplumber
import pandas as pd
import re
import math

# --- è¨­å®šé é¢ ---
st.set_page_config(page_title="é€šç”¨æª¢æ¸¬å ±å‘Šæ“·å–å·¥å…· (V6 æ——è‰¦ç‰ˆ)", layout="wide")
st.title("ğŸ§ª é€šç”¨å‹ç¬¬ä¸‰æ–¹æª¢æ¸¬å ±å‘Šæ•¸æ“šæ“·å–å·¥å…· (V6 æ——è‰¦ç‰ˆ)")
st.markdown("""
**V6 æ ¸å¿ƒå¼•æ“æŠ€è¡“ï¼š**
1.  **ğŸ§  æ¬Šé‡è©•åˆ†ç³»çµ±**ï¼šä¸åªçœ‹æ¨™é¡Œï¼Œé‚„åˆ†ææ¬„ä½å…§å®¹èˆ‡ã€Œå·¦å³é„°å±…ã€(å¦‚å³é‚Šæ˜¯ MDL å‰‡åŠ åˆ†)ï¼Œç²¾æº–é–å®šçµæœæ¬„ã€‚
2.  **ğŸ” è³‡æ–™æŒ‡ç´‹åˆ†æ**ï¼šè‡ªå‹•è­˜åˆ¥ä¸¦æ’é™¤ CAS ç·¨è™Ÿã€æ³•è¦å¹´ä»½ (2015)ã€é™å€¼ (1000) ç­‰é›œè¨Šã€‚
3.  **ğŸ›¡ï¸ èªç¾©é˜²ç¦¦æ©Ÿåˆ¶**ï¼šè§£æ±º Chlorine èª¤æŠ“ Polyvinyl Chloride (Negative) çš„å•é¡Œã€‚
4.  **ğŸ“… æ™ºèƒ½æ—¥æœŸé–å®š**ï¼šåƒ…é–å®šå ±å‘Šé¦–é ç°½ç™¼æ—¥æœŸï¼Œæ¨™æº–åŒ–ç‚º YYYY/MM/DDã€‚
""")

# --- 1. å®šç¾©ç›®æ¨™æ¬„ä½ ---
TARGET_FIELDS = {
    "Lead": {"name": "Pb", "keywords": [r"^Lead\b", r"^Pb\b", r"é“…", r"Lead \(Pb\)", r"Pb"]},
    "Cadmium": {"name": "Cd", "keywords": [r"^Cadmium\b", r"^Cd\b", r"é•‰", r"Cadmium \(Cd\)", r"Cd"]},
    "Mercury": {"name": "Hg", "keywords": [r"^Mercury\b", r"^Hg\b", r"æ±", r"Mercury \(Hg\)", r"Hg"]},
    "Hexavalent Chromium": {"name": "Cr(VI)", "keywords": [r"Hexavalent Chromium", r"Cr\(VI\)", r"Cr6\+", r"å…­ä»·é“¬", r"å…­åƒ¹é‰»"]},
    "DEHP": {"name": "DEHP", "keywords": [r"Bis\(2-ethylhexyl\) phthalate", r"DEHP", r"é‚»è‹¯äºŒç”²é…¸äºŒ\(2-ä¹™åŸºå·±åŸº\)é…¯"]},
    "BBP": {"name": "BBP", "keywords": [r"Butyl benzyl phthalate", r"BBP", r"é‚»è‹¯äºŒç”²é…¸ä¸åŸºè‹„åŸºé…¯"]},
    "DBP": {"name": "DBP", "keywords": [r"Dibutyl phthalate", r"DBP", r"é‚»è‹¯äºŒç”²é…¸äºŒä¸é…¯"]},
    "DIBP": {"name": "DIBP", "keywords": [r"Diisobutyl phthalate", r"DIBP", r"é‚»è‹¯äºŒç”²é…¸äºŒå¼‚ä¸é…¯"]},
    "Fluorine": {"name": "F", "keywords": [r"Fluorine", r"æ°Ÿ", r"Fluorine \(F\)"]},
    "Chlorine": {"name": "Cl", "keywords": [r"Chlorine", r"æ°¯", r"Chlorine \(Cl\)"]},
    "Bromine": {"name": "Br", "keywords": [r"Bromine", r"æº´", r"Bromine \(Br\)"]},
    "Iodine": {"name": "I", "keywords": [r"Iodine", r"ç¢˜", r"Iodine \(I\)"]},
    "PFOS": {"name": "PFOS", "keywords": [r"Perfluorooctane Sulfonates", r"PFOS", r"å…¨æ°Ÿè¾›ç£ºé…¸"]},
}

PBBS_KEYWORDS = [r"Monobromobiphenyl", r"Dibromobiphenyl", r"Tribromobiphenyl", r"Tetrabromobiphenyl", 
                 r"Pentabromobiphenyl", r"Hexabromobiphenyl", r"Heptabromobiphenyl", r"Octabromobiphenyl", 
                 r"Nonabromobiphenyl", r"Decabromobiphenyl", r"ä¸€æº´è”è‹¯", r"åæº´è”è‹¯", r"ä¸€æº´è¯è‹¯"]
PBDES_KEYWORDS = [r"Monobromodiphenyl ether", r"Dibromodiphenyl ether", r"Tribromodiphenyl ether", 
                  r"Tetrabromodiphenyl ether", r"Pentabromodiphenyl ether", r"Hexabromodiphenyl ether", 
                  r"Heptabromodiphenyl ether", r"Octabromodiphenyl ether", r"Nonabromodiphenyl ether", 
                  r"Decabromodiphenyl ether", r"ä¸€æº´äºŒè‹¯é†š", r"åæº´äºŒè‹¯é†š"]

# --- 2. è¼”åŠ©å‡½å¼ ---

def clean_text(text):
    if not text: return ""
    return re.sub(r'\s+', ' ', str(text)).strip()

def normalize_date(date_str):
    """æ—¥æœŸæ ¼å¼æ¨™æº–åŒ–"""
    if not date_str: return ""
    clean_date = re.sub(r"Date:|Issue Date:|Report Date:|æ—¥æœŸ[:ï¼š]?", "", date_str, flags=re.IGNORECASE).strip()
    try:
        # 2025.05.26 / 2025-05-26
        match_num = re.search(r"(\d{4})[-/. ](\d{1,2})[-/. ](\d{1,2})", clean_date)
        if match_num:
            return f"{match_num.group(1)}/{int(match_num.group(2)):02d}/{int(match_num.group(3)):02d}"
        
        # è‹±æ–‡æœˆä»½è™•ç†
        months = {"JAN": 1, "FEB": 2, "MAR": 3, "APR": 4, "MAY": 5, "JUN": 6, 
                  "JUL": 7, "AUG": 8, "SEP": 9, "OCT": 10, "NOV": 11, "DEC": 12}
        
        # 16-Jun-25
        match_dd_mon_yy = re.search(r"(\d{1,2})[-/\s]([A-Za-z]{3})[-/\s](\d{2,4})", clean_date, re.IGNORECASE)
        if match_dd_mon_yy:
            d, m_str, y = match_dd_mon_yy.groups()
            m = months.get(m_str.upper(), 0)
            if m > 0:
                if len(y) == 2: y = "20" + y
                return f"{y}/{m:02d}/{int(d):02d}"

        # Jan 08, 2025
        match_mon_dd_yyyy = re.search(r"([A-Za-z]{3})\.?\s+(\d{1,2}),?\s+(\d{4})", clean_date, re.IGNORECASE)
        if match_mon_dd_yyyy:
            m_str, d, y = match_mon_dd_yyyy.groups()
            m = months.get(m_str.upper(), 0)
            if m > 0:
                return f"{y}/{m:02d}/{int(d):02d}"
    except:
        pass
    return clean_date

def find_date_in_first_page(text):
    """åªåœ¨ç¬¬ä¸€é æŠ“å–æ—¥æœŸ"""
    lines = text.split('\n')
    for line in lines:
        if "RECEIVED" in line.upper() or "PERIOD" in line.upper() or "STARTED" in line.upper(): continue
        
        if re.search(r"(Date:|Issue Date|Report Date|æ—¥æœŸ[:ï¼š])", line, re.IGNORECASE):
            # å„ªå…ˆåŒ¹é…å®Œæ•´æ—¥æœŸæ ¼å¼
            m1 = re.search(r"(\d{4}[-/. ]\d{1,2}[-/. ]\d{1,2})", line)
            if m1: return normalize_date(m1.group(1))
            
            m2 = re.search(r"([A-Za-z]{3}\.?\s+\d{1,2},?\s+\d{4})", line)
            if m2: return normalize_date(m2.group(1))
            
            m3 = re.search(r"(\d{1,2}-[A-Za-z]{3}-\d{2,4})", line)
            if m3: return normalize_date(m3.group(1))
    return ""

# --- 3. æ ¸å¿ƒé‚è¼¯ï¼šæ¬Šé‡è©•åˆ†ç³»çµ± ---

def get_column_score(header_cells, table_data=None):
    """
    å°æ¯ä¸€æ¬„é€²è¡Œè©•åˆ†ï¼Œæ‰¾å‡ºæœ€å¯èƒ½æ˜¯ Result çš„æ¬„ä½ç´¢å¼•ã€‚
    è€ƒé‡ï¼šæ¨™é¡Œé—œéµå­—ã€å·¦å³é„°å±…ã€æ¬„ä½å…§å®¹æŒ‡ç´‹ã€‚
    """
    scores = {} # col_idx -> score
    num_cols = len(header_cells)
    
    # é—œéµå­—å®šç¾©
    exclude_kw = ["ITEM", "METHOD", "UNIT", "MDL", "LOQ", "LIMIT", "REQUIREMENT", "é¡¹ç›®", "æ–¹æ³•", "å•ä½", "é™å€¼", "RL", "CAS", "NO."]
    result_kw = ["RESULT", "ç»“æœ", "SAMPLE", "ID", "001", "002", "A1", "DATA", "å«é‡"]
    mdl_kw = ["MDL", "LOQ", "RL", "LIMIT", "é™å€¼"]
    
    for i, cell in enumerate(header_cells):
        if not cell: continue
        txt = clean_text(str(cell)).upper()
        
        score = 0
        
        # 1. è‡ªèº«ç‰¹å¾µ
        if any(ex in txt for ex in exclude_kw): score -= 100
        if any(res in txt for res in result_kw): score += 50
        if "CAS" in txt: score -= 200 # CAS çµ•å°æ’é™¤
        
        # 2. é„°å±…ç‰¹å¾µ (æ‹“æ¨¸é—œä¿‚)
        # æª¢æŸ¥å³é‚Š (i+1) æ˜¯å¦ç‚º MDL/Limit (SGS å¸¸è¦‹)
        if i + 1 < num_cols:
            right_txt = clean_text(str(header_cells[i+1])).upper()
            if any(k in right_txt for k in mdl_kw): score += 30
            
        # æª¢æŸ¥å·¦é‚Š (i-1) æ˜¯å¦ç‚º Item (CTI å¸¸è¦‹)
        if i - 1 >= 0:
            left_txt = clean_text(str(header_cells[i-1])).upper()
            if "ITEM" in left_txt or "é¡¹ç›®" in left_txt: score += 20
            
        scores[i] = score

    # 3. æ•¸æ“šæŒ‡ç´‹é©—è­‰ (Data Fingerprinting) - å·çœ‹å‰å¹¾è¡Œå…§å®¹
    if table_data and len(table_data) > 3:
        for i in range(num_cols):
            if i not in scores: continue
            
            # æª¢æŸ¥è©²æ¬„ä½åœ¨å‰å¹¾è¡Œçš„å…§å®¹
            sample_vals = []
            for row in table_data[1:5]: # å–å‰5è¡Œæ•¸æ“š
                if i < len(row): sample_vals.append(clean_text(str(row[i])).upper())
            
            # åˆ¤æ–·ç‰¹å¾µ
            is_numeric_or_nd = 0
            is_cas = 0
            is_method = 0
            
            for val in sample_vals:
                if "N.D." in val or "NEGATIVE" in val or re.search(r"^\d+(\.\d+)?$", val):
                    is_numeric_or_nd += 1
                if re.search(r"\d{2,7}-\d{2}-\d", val): # CAS æ ¼å¼
                    is_cas += 1
                if "IEC" in val or "EPA" in val:
                    is_method += 1
            
            if is_cas > 0: scores[i] -= 200
            if is_method > 0: scores[i] -= 100
            if is_numeric_or_nd > 0: scores[i] += 20 # å…§å®¹åƒæ•¸æ“šï¼ŒåŠ åˆ†

    # æ‰¾å‡ºæœ€é«˜åˆ†
    if not scores: return -1
    best_col = max(scores, key=scores.get)
    
    # é–€æª»å€¼ï¼šå¦‚æœæœ€é«˜åˆ†ä»å¾ˆä½ (ä¾‹å¦‚éƒ½æ˜¯ Method)ï¼Œå‰‡ä¸å›å‚³
    if scores[best_col] < -50: return -1
    
    return best_col

def extract_value_logic(val_str, mdl_val=None, limit_val=None):
    """
    æ•¸å€¼æå–èˆ‡é˜²å‘†æ©Ÿåˆ¶
    """
    if not val_str: return 0, "N.D."
    
    val_upper = str(val_str).upper().replace(" ", "")
    
    # 1. CAS é˜²ç«ç‰†
    if re.search(r"\b\d{2,7}-\d{2}-\d\b", val_str): return 0, "N.D."

    # 2. æ–‡å­—ç‹€æ…‹
    if "N.D." in val_upper or "ND" in val_upper or "<" in val_upper: return 0, "N.D."
    if "NEGATIVE" in val_upper or "é˜´æ€§" in val_upper: return 0.0001, "NEGATIVE"
    if "POSITIVE" in val_upper or "é˜³æ€§" in val_upper: return 999999, "POSITIVE"
    
    # 3. æ•¸å­—æå–
    val_clean = re.sub(r"(mg/kg|ppm|%|Âµg/cmÂ²|ug/cm2)", "", val_str, flags=re.IGNORECASE)
    match = re.search(r"(\d+(\.\d+)?)", val_clean)
    
    if match:
        num = float(match.group(1))
        
        # 4. é˜²å‘†æ©Ÿåˆ¶ (Sanity Check)
        # æ’é™¤å¹´ä»½ (2011, 2015, 2025)
        if 2010 <= num <= 2030: return 0, "N.D." # å‡è¨­æª¢æ¸¬å€¼æ¥µå°‘å‰›å¥½è½åœ¨é€™å€é–“ä¸”ç‚ºæ•´æ•¸
        
        # æ’é™¤ Limit / MDL (å¦‚æœå‰›å¥½æŠ“åˆ° 1000 æˆ– 100)
        if num in [100, 1000] and "ND" not in val_upper:
             # å¦‚æœé€™å€‹æ•¸å­—è·Ÿ MDL æˆ– Limit ä¸€æ¨£ï¼Œå¯èƒ½æ˜¯æŠ“éŒ¯æ¬„ä½
             pass 
             
        return num, match.group(1)
    
    return 0, "N.D."

def process_file(uploaded_file):
    filename = uploaded_file.name
    results = {k: {"val": 0, "display": ""} for k in TARGET_FIELDS.keys()}
    results["PBBs"] = {"val": 0, "display": "", "sum_val": 0}
    results["PBDEs"] = {"val": 0, "display": "", "sum_val": 0}
    results["PFAS"] = ""
    results["Date"] = ""
    
    is_scanned = True
    full_text_content = ""
    
    with pdfplumber.open(uploaded_file) as pdf:
        # A. å…¨æ–‡æƒæ & æ—¥æœŸ
        for i, page in enumerate(pdf.pages):
            text = page.extract_text()
            if text and len(text) > 50:
                is_scanned = False
                full_text_content += text + "\n"
                if i == 0: results["Date"] = find_date_in_first_page(text)

        if is_scanned: return None, filename

        if "PFAS" in full_text_content.upper() or "PER- AND POLYFLUOROALKYL" in full_text_content.upper():
            results["PFAS"] = "REPORT"

        # B. è¡¨æ ¼æ•¸æ“šæå– (å„ªå…ˆ)
        for page in pdf.pages:
            tables = page.extract_tables()
            if tables:
                for table in tables:
                    if not table or len(table) < 2: continue
                    
                    df = pd.DataFrame(table)
                    header_row_idx = -1
                    result_col_idx = -1
                    
                    # å°‹æ‰¾è¡¨é ­ (åŒ…å«å‚ç›´åˆä½µè™•ç†)
                    for r_idx, row in enumerate(table[:6]):
                        row_str = " ".join([str(c).upper() for c in row if c])
                        if ("ITEM" in row_str or "é¡¹ç›®" in row_str):
                            header_row_idx = r_idx
                            result_col_idx = get_column_score(row, table) # è©•åˆ†ç³»çµ±
                            
                            # CTI å·¢ç‹€è¡¨é ­è™•ç†: å¦‚æœè©•åˆ†å¤±æ•—ï¼Œå˜—è©¦ä¸‹ä¸€è¡Œ
                            if result_col_idx == -1 and r_idx + 1 < len(table):
                                result_col_idx = get_column_score(table[r_idx+1], table)
                            break
                    
                    if result_col_idx != -1:
                        for r_idx in range(header_row_idx + 1, len(table)):
                            row = table[r_idx]
                            if len(row) <= result_col_idx: continue
                            
                            item_name = clean_text(row[0])
                            if len(row) > 1: item_name += " " + clean_text(row[1])
                            val_text = clean_text(row[result_col_idx])
                            
                            update_results(results, item_name, val_text)

            # C. æ–‡å­—æµæ¨¡å¼ (Fallback for invisible tables)
            # ä½¿ç”¨ extract_words åšç°¡æ˜“è¡Œå°é½Š
            words = page.extract_words(keep_blank_chars=True)
            rows = {}
            for w in words:
                y = round(w['top'] / 5) * 5
                if y not in rows: rows[y] = []
                rows[y].append(w)
            
            for y, row_words in rows.items():
                line_text = " ".join([w['text'] for w in row_words])
                
                for field, config in TARGET_FIELDS.items():
                    for kw in config["keywords"]:
                        if re.search(kw, line_text, re.IGNORECASE):
                            # èªç¾©é˜²ç¦¦: æ’é™¤ Polyvinyl Chloride èª¤åˆ¤ç‚º Chlorine
                            if field == "Chlorine" and "POLYVINYL" in line_text.upper():
                                continue
                                
                            parts = line_text.split()
                            valid_parts = [p for p in parts if not re.search(r"\d{2,7}-\d{2}-\d", p)]
                            for part in reversed(valid_parts): # å¾å³é‚Šæ‰¾
                                val, disp = extract_value_logic(part)
                                # æ’é™¤å¹´ä»½èˆ‡Limit (æ–‡å­—æ¨¡å¼è¼ƒå¯¬é¬†ï¼Œéœ€åš´æ ¼æª¢æŸ¥)
                                if val not in [100, 1000, 2011, 2015] and (val > 0 or disp in ["N.D.", "NEGATIVE"]):
                                    update_results(results, field, disp, is_text_mode=True)
                                    break
                
                # PBBs/PBDEs åŠ ç¸½
                for pbb_kw in PBBS_KEYWORDS + PBDES_KEYWORDS:
                    if re.search(pbb_kw, line_text, re.IGNORECASE):
                        parts = line_text.split()
                        for part in reversed(parts):
                            val, disp = extract_value_logic(part)
                            if val > 0 and val not in [1000, 5, 25]:
                                cat = "PBBs" if any(k in pbb_kw for k in PBBS_KEYWORDS) else "PBDEs"
                                results[cat]["sum_val"] += val
                                break

    finalize_results(results)
    
    final_output = {
        "File Name": filename,
        "Pb": results["Lead"]["display"],
        "Cd": results["Cadmium"]["display"],
        "Hg": results["Mercury"]["display"],
        "Cr(VI)": results["Hexavalent Chromium"]["display"],
        "PBBs": results["PBBs"]["display"],
        "PBDEs": results["PBDEs"]["display"],
        "DEHP": results["DEHP"]["display"],
        "BBP": results["BBP"]["display"],
        "DBP": results["DBP"]["display"],
        "DIBP": results["DIBP"]["display"],
        "F": results["Fluorine"]["display"],
        "Cl": results["Chlorine"]["display"],
        "Br": results["Bromine"]["display"],
        "I": results["Iodine"]["display"],
        "PFOS": results["PFOS"]["display"],
        "PFAS": results["PFAS"],
        "Date": results["Date"],
        "_sort_pb": results["Lead"]["val"],
        "_sort_max": max([v["val"] for k, v in results.items() if isinstance(v, dict) and "val" in v])
    }
    
    return final_output, None

def update_results(results, item_name, val_text, is_text_mode=False):
    item_upper = str(item_name).upper()
    
    # èªç¾©é˜²ç¦¦: é˜²æ­¢ Chlorine æŠ“åˆ° Polyvinyl Chloride
    if "CHLORINE" in item_upper and "POLYVINYL" in item_upper: return

    val_num, val_disp = extract_value_logic(val_text)
    
    for field_key, config in TARGET_FIELDS.items():
        for kw in config["keywords"]:
            if re.search(kw, item_upper, re.IGNORECASE):
                if is_text_mode and results[field_key]["val"] > 0: return
                
                if val_num > results[field_key]["val"]:
                    results[field_key]["val"] = val_num
                    results[field_key]["display"] = val_disp
                elif val_num == 0 and results[field_key]["val"] == 0:
                    if val_disp == "NEGATIVE": results[field_key]["display"] = "NEGATIVE"
                    elif not results[field_key]["display"]: results[field_key]["display"] = "N.D."
                return

    for pbb_kw in PBBS_KEYWORDS:
        if re.search(pbb_kw, item_upper, re.IGNORECASE):
            if is_text_mode: return
            results["PBBs"]["sum_val"] += val_num
            return

    for pbde_kw in PBDES_KEYWORDS:
        if re.search(pbde_kw, item_upper, re.IGNORECASE):
            if is_text_mode: return
            results["PBDEs"]["sum_val"] += val_num
            return

def finalize_results(results):
    if results["PBBs"]["sum_val"] > 0:
        results["PBBs"]["display"] = str(round(results["PBBs"]["sum_val"], 2))
        results["PBBs"]["val"] = results["PBBs"]["sum_val"]
    elif not results["PBBs"]["display"]: results["PBBs"]["display"] = "N.D."

    if results["PBDEs"]["sum_val"] > 0:
        results["PBDEs"]["display"] = str(round(results["PBDEs"]["sum_val"], 2))
        results["PBDEs"]["val"] = results["PBDEs"]["sum_val"]
    elif not results["PBDEs"]["display"]: results["PBDEs"]["display"] = "N.D."

# --- ä¸»ä»‹é¢ ---

uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ PDF æª¢æ¸¬å ±å‘Š (æ”¯æ´ SGS, CTI, Intertek ç­‰)", type="pdf", accept_multiple_files=True)

if uploaded_files:
    all_data = []
    scanned_files = []

    with st.spinner('æ­£åœ¨ä½¿ç”¨ V6 å¼•æ“åˆ†æ (æ¬Šé‡è©•åˆ† + èªç¾©é˜²ç¦¦ + è³‡æ–™æŒ‡ç´‹)...'):
        for pdf_file in uploaded_files:
            data, scanned_name = process_file(pdf_file)
            if scanned_name:
                scanned_files.append(scanned_name)
            else:
                all_data.append(data)

    if all_data:
        df = pd.DataFrame(all_data)
        df = df.sort_values(by=["_sort_pb", "_sort_max"], ascending=[False, False])
        display_df = df.drop(columns=["_sort_pb", "_sort_max"])
        
        st.success(f"âœ… æˆåŠŸæ“·å– {len(all_data)} ä»½å ±å‘Šï¼(V6 æ ¸å¿ƒ)")
        st.dataframe(display_df, use_container_width=True)
        
        csv = display_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel/CSV å ±è¡¨",
            data=csv,
            file_name="rohs_report_v6.csv",
            mime="text/csv",
        )

    if scanned_files:
        st.error("âš ï¸ ä»¥ä¸‹æª”æ¡ˆç‚ºæƒæåœ–ç‰‡ (ç„¡æ³•æ“·å–æ–‡å­—)ï¼š")
        for f in scanned_files:
            st.write(f"- {f}")

else:
    st.info("è«‹ä¸Šå‚³ PDF æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚")
