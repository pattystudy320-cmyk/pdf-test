import streamlit as st
import pdfplumber
import pandas as pd
import re
import io
from dateutil import parser

# ==========================================
# 0. å¼·åˆ¶æ¸…é™¤å¿«å–
# ==========================================
try:
    if hasattr(st, 'cache_data'):
        st.cache_data.clear()
    elif hasattr(st, 'experimental_memo'):
        st.experimental_memo.clear()
    elif hasattr(st, 'cache'):
        st.cache_resource.clear()
except:
    pass

# ==========================================
# 1. å…¨å±€é…ç½®èˆ‡å­—å…¸
# ==========================================
TARGET_ITEMS = [
    "Pb", "Cd", "Hg", "Cr6+", "PBBs", "PBDEs",
    "DEHP", "DBP", "BBP", "DIBP",
    "F", "Cl", "Br", "I",
    "PFOS", "PFAS", "DATE", "FILENAME"
]

# --- SGS å°ˆç”¨å­—å…¸ (å«ä¸­æ–‡èˆ‡è‹±æ–‡) ---
SGS_OPTIMIZED_MAP = {
    'Pb': ['Lead', 'Pb', 'é‰›', 'é“…'],
    'Cd': ['Cadmium', 'Cd', 'é˜', 'é•‰'],
    'Hg': ['Mercury', 'Hg', 'æ±'],
    'Cr6+': ['Hexavalent Chromium', 'Cr(VI)', 'å…­åƒ¹é‰»', 'å…­ä»·é“¬', 'Hexavalent', 'Cr6+'],
    'PBBs': ['Polybrominated biphenyls', 'PBB', 'å¤šæº´è¯è‹¯', 'å¤šæº´è”è‹¯', 'Sum of PBBs'],
    'PBDEs': ['Polybrominated diphenyl ethers', 'PBDE', 'å¤šæº´äºŒè‹¯é†š', 'Sum of PBDEs'],
    'DEHP': ['Bis(2-ethylhexyl) phthalate', 'DEHP', 'é„°è‹¯äºŒç”²é…¸äºŒ(2-ä¹™åŸºå·±åŸº)é…¯', 'Di(2-ethylhexyl) phthalate'],
    'DBP': ['Dibutyl phthalate', 'DBP', 'é„°è‹¯äºŒç”²é…¸äºŒä¸é…¯'],
    'BBP': ['Butyl benzyl phthalate', 'BBP', 'é„°è‹¯äºŒç”²é…¸ä¸è‹„é…¯'],
    'DIBP': ['Diisobutyl phthalate', 'DIBP', 'é„°è‹¯äºŒç”²é…¸äºŒç•°ä¸é…¯'],
    'F': ['Fluorine', 'æ°Ÿ', 'Halogen-Fluorine'],
    'Cl': ['Chlorine', 'æ°¯', 'Halogen-Chlorine'],
    'Br': ['Bromine', 'æº´', 'Halogen-Bromine'],
    'I': ['Iodine', 'ç¢˜', 'Halogen-Iodine'],
    'PFOS': ['Perfluorooctane sulfonic acid', 'PFOS', 'å…¨æ°Ÿè¾›çƒ·ç£ºé…¸', 'Perfluorooctane Sulfonates'],
    'PFAS': ['PFAS']
}

# --- CTI/Intertek é€šç”¨å­—å…¸ ---
UNIFIED_REGEX_MAP = {
    r"(?i)\b(Lead|Pb|é“…)\b": "Pb",
    r"(?i)\b(Cadmium|Cd|é•‰)\b": "Cd",
    r"(?i)\b(Mercury|Hg|æ±)\b": "Hg",
    r"(?i)\b(Hexavalent Chromium|Cr\(?VI\)?|å…­ä»·é“¬)\b": "Cr6+",
    r"(?i)\b(DEHP|Di\(2-ethylhexyl\)\s*phthalate)\b": "DEHP",
    r"(?i)\b(DBP|Dibutyl\s*phthalate)\b": "DBP",
    r"(?i)\b(BBP|Butyl\s*benzyl\s*phthalate)\b": "BBP",
    r"(?i)\b(DIBP|Diisobutyl\s*phthalate)\b": "DIBP",
    r"(?i)(Fluorine|æ°Ÿ).*\((F|F-)\)": "F",
    r"(?i)(Chlorine|æ°¯|æ°£).*\((Cl|Cl-)\)": "Cl",
    r"(?i)(Bromine|æº´).*\((Br|Br-)\)": "Br",
    r"(?i)(Iodine|ç¢˜).*\((I|I-)\)": "I",
    r"(?i)(Perfluorooctane\s*sulfonic\s*acid\s*\(PFOS\)|PFOS.*(salts|åŠå…¶ç›)|å…¨æ°Ÿè¾›çƒ·ç£ºé…¸)": "PFOS"
}

PBB_SUBITEMS = r"(?i)(Monobromobiphenyl|Dibromobiphenyl|Tribromobiphenyl|Tetrabromobiphenyl|Pentabromobiphenyl|Hexabromobiphenyl|Heptabromobiphenyl|Octabromobiphenyl|Nonabromobiphenyl|Decabromobiphenyl|ä¸€æº´è”è‹¯|äºŒæº´è”è‹¯|ä¸‰æº´è”è‹¯|å››æº´è”è‹¯|äº”æº´è”è‹¯|å…­æº´è”è‹¯|ä¸ƒæº´è”è‹¯|å…«æº´è”è‹¯|ä¹æº´è”è‹¯|åæº´è”è‹¯)"
PBDE_SUBITEMS = r"(?i)(Monobromodiphenyl ether|Dibromodiphenyl ether|Tribromodiphenyl ether|Tetrabromodiphenyl ether|Pentabromodiphenyl ether|Hexabromodiphenyl ether|Heptabromodiphenyl ether|Octabromodiphenyl ether|Nonabromodiphenyl ether|Decabromodiphenyl ether|ä¸€æº´äºŒè‹¯é†š|äºŒæº´äºŒè‹¯é†š|ä¸‰æº´äºŒè‹¯é†š|å››æº´äºŒè‹¯é†š|äº”æº´äºŒè‹¯é†š|å…­æº´äºŒè‹¯é†š|ä¸ƒæº´äºŒè‹¯é†š|å…«æº´äºŒè‹¯é†š|ä¹æº´äºŒè‹¯é†š|åæº´äºŒè‹¯é†š)"

# è‹±æ–‡æœˆä»½å°ç…§è¡¨ (å«å…¨åèˆ‡ç¸®å¯«)
MONTH_MAP = {
    "January": "01", "February": "02", "March": "03", "April": "04", "May": "05", "June": "06",
    "July": "07", "August": "08", "September": "09", "October": "10", "November": "11", "December": "12",
    "Jan": "01", "Feb": "02", "Mar": "03", "Apr": "04", "Jun": "06",
    "Jul": "07", "Aug": "08", "Sep": "09", "Oct": "10", "Nov": "11", "Dec": "12"
}

# ==========================================
# 2. å·¥å…·å‡½æ•¸
# ==========================================
def clean_date_str(date_str):
    if not date_str: return "1900/01/01"
    clean_str = str(date_str).strip()
    # è‹±æ–‡æœˆä»½è½‰æ›
    for mon, digit in MONTH_MAP.items():
        if re.search(r"(?i)\b" + mon + r"\b", clean_str):
            clean_str = re.sub(r"(?i)\b" + mon + r"\b", digit, clean_str)
            break
    clean_str = clean_str.replace("å¹´", "/").replace("æœˆ", "/").replace("æ—¥", "").replace("-", "/")
    clean_str = re.split(r"(Page|é )", clean_str, flags=re.IGNORECASE)
    try:
        dt = parser.parse(clean_str, fuzzy=True)
        return dt.strftime("%Y/%m/%d")
    except:
        return "1900/01/01"

def clean_value(val_str):
    if not val_str: return None
    val_str = str(val_str).strip()
    if val_str.lower() in ["mdl", "limit", "unit", "result", "loq", "requirement", "max"]:
        return None
    if re.search(r"(?i)(N\.?D\.?|Not Detected|<|Negative)", val_str):
        return "N.D."
    if re.search(r"(?i)(Positive)", val_str):
        return "POSITIVE"
    nums = re.findall(r"\d+\.?\d*", val_str)
    if nums:
        try:
            return float(nums)
        except:
            pass
    return None

def get_value_priority(val):
    if isinstance(val, (int, float)): return (3, val)
    if val in ["NEGATIVE", "POSITIVE"]: return (2, 0)
    if val == "N.D.": return (1, 0)
    return (0, 0)

# ==========================================
# 3. SGS é¦¬ä¾†è¥¿äºå°ˆç”¨æ¨¡çµ„ (NEW)
# ==========================================
def parse_sgs_malaysia(pdf_obj, full_text, first_page_text):
    result = {k: None for k in SGS_OPTIMIZED_MAP.keys()}
    result['PFAS'] = ""
    result['DATE'] = ""

    # 1. é¦¬ä¾†è¥¿äºæ—¥æœŸæŠ“å– (æ”¯æ´ January å…¨å)
    # æ ¼å¼: 23-January-2025, 23 Jan 2025
    lines = first_page_text.split('\n')
    for line in lines[:30]:
        if re.search(r"(?i)(Date|æ—¥æœŸ)", line):
            # æŠ“å– 23-January-2025 æˆ– 23 Jan 2025
            match = re.search(r"(\d{1,2}[-.\s]+[A-Za-z]+[-.\s]+\d{4})", line)
            if match:
                result['DATE'] = clean_date_str(match.group(1))
                break

    # 2. æ•¸æ“šæŠ“å– (åš´æ ¼ä¾è³´ Result æ¬„ä½ç´¢å¼•)
    pbb_sum = 0; pbde_sum = 0; pbb_found = False; pbde_found = False
    
    with pdfplumber.open(pdf_obj) as pdf:
        for page in pdf.pages:
            tables = page.extract_tables()
            for table in tables:
                if not table: continue
                
                header_row_idx = -1
                result_col_idx = -1
                
                # å°‹æ‰¾è¡¨é ­
                for r_idx, row in enumerate(table[:5]):
                    row_text = " ".join([str(cell).lower() for cell in row if cell])
                    # å¿…é ˆåŒ…å« Test Parameter æˆ– Test Itemï¼Œä¸”åŒ…å« Result
                    if ("test parameter" in row_text or "test item" in row_text) and "result" in row_text:
                        header_row_idx = r_idx
                        # æ‰¾å‡º Result æ‰€åœ¨çš„ç¢ºåˆ‡æ¬„ä½ç´¢å¼•
                        for c_idx, cell in enumerate(row):
                            if cell and re.search(r"(?i)(Result)", str(cell)):
                                result_col_idx = c_idx
                                break
                        break
                
                # å¦‚æœæ‰¾ä¸åˆ°æ˜ç¢ºçš„ Result æ¬„ä½ï¼Œä½†è¡¨é ­å­˜åœ¨ï¼Œå˜—è©¦ç”¨é‚è¼¯åˆ¤æ–·
                # é¦¬ä¾†è¥¿äºå ±å‘Š Result é€šå¸¸åœ¨ç¬¬ 2 æ¬„ (Index 1) æˆ– ç¬¬ 4 æ¬„ (Index 3)
                # çµ•å°ä¸èƒ½ç”¨ã€Œæœ€å³é‚Šã€ï¼Œå› ç‚ºæœ€å³é‚Šæ˜¯ Limit/MDL
                if header_row_idx != -1 and result_col_idx == -1:
                     # å˜—è©¦æ‰¾å°‹éç©ºã€é Unitã€é MDLã€é Limit çš„ä¸­é–“æ¬„ä½
                     pass 

                if header_row_idx == -1: continue

                # éæ­·æ•¸æ“š
                for row in table[header_row_idx + 1:]:
                    if not row: continue
                    row_clean = [str(c) for c in row if c]
                    row_str = " ".join(row_clean).replace("\n", " ")
                    
                    if re.search(r"(?i)(PFOA|Perfluorooctanoic\s*Acid)", row_str) and "PFOA" not in SGS_OPTIMIZED_MAP: continue
                    if "PFAS" in row_str and not result['PFAS']: result['PFAS'] = "REPORT"

                    # è­˜åˆ¥æ¸¬é …
                    matched_key = None
                    for key, keywords in SGS_OPTIMIZED_MAP.items():
                        if any(kw.lower() in row_str.lower() for kw in keywords):
                            if key == "PFOS" and re.search(r"(?i)(Total|PFOSF|Derivative)", row_str): continue
                            if key in ['F', 'Cl', 'Br', 'I'] and not re.search(r"\((F|Cl|Br|I)-?\)", row_str): continue
                            matched_key = key
                            break
                    
                    is_pbb = re.search(PBB_SUBITEMS, row_str)
                    is_pbde = re.search(PBDE_SUBITEMS, row_str)
                    
                    if not matched_key and not is_pbb and not is_pbde: continue

                    # æŠ“å–æ•¸å€¼
                    target_val = None
                    
                    # ç­–ç•¥ A: å¦‚æœæœ‰æ‰¾åˆ° Result æ¬„ä½ç´¢å¼•ï¼Œç›´æ¥å–å€¼
                    if result_col_idx != -1 and result_col_idx < len(row):
                        target_val = str(row[result_col_idx])
                    
                    # ç­–ç•¥ B: å¦‚æœ PDF è¡¨æ ¼é»é€£ (Result æ¬„ä½å…§å®¹è·‘åˆ° Item æ¬„ä½å­—ä¸²è£¡ï¼Œä¾‹å¦‚ "N.D.Fluorine")
                    # é¦¬ä¾†è¥¿äºå ±å‘Šå¸¸ç™¼ç”Ÿé€™ç¨®æƒ…æ³ï¼Œéœ€è¦ç”¨ Regex åœ¨æ•´è¡Œå­—ä¸²ä¸­æ‰¾ N.D.
                    if (not target_val or target_val.strip() == ""):
                        # åœ¨æ•´è¡Œä¸­å°‹æ‰¾ N.D. ä¸”è©² N.D. ä¸æ˜¯ Item çš„ä¸€éƒ¨åˆ†
                        if "N.D." in row_str:
                             target_val = "N.D."
                        else:
                             # æ‰¾æ•¸å­— (æ’é™¤ Item åç¨±ä¸­çš„æ•¸å­—)
                             nums = re.findall(r"\b\d+\.?\d*\b", row_str)
                             # é€™è£¡å¾ˆå±éšªï¼Œå› ç‚º Limit å’Œ MDL ä¹Ÿæ˜¯æ•¸å­—
                             # é€šå¸¸çµæœå¦‚æœæ˜¯æ•¸å­—ï¼Œæœƒå‡ºç¾åœ¨ Unit ä¹‹å‰ã€‚
                             # ä½†ç°¡å–®èµ·è¦‹ï¼Œå¦‚æœ Strategy A å¤±æ•—ï¼Œé€™è£¡å…ˆä¿å®ˆè™•ç†
                             pass

                    cleaned_val = clean_value(target_val)
                    
                    # å­˜å…¥çµæœ
                    if matched_key:
                        current_val = result.get(matched_key)
                        if get_value_priority(cleaned_val) > get_value_priority(current_val):
                            result[matched_key] = cleaned_val
                    elif is_pbb and isinstance(cleaned_val, (int, float)):
                        pbb_found = True; pbb_sum += cleaned_val
                    elif is_pbde and isinstance(cleaned_val, (int, float)):
                        pbde_found = True; pbde_sum += cleaned_val

    if "PFAS" in first_page_text: result["PFAS"] = "REPORT"
    result["PBBs"] = pbb_sum if pbb_found and pbb_sum > 0 else "N.D."
    result["PBDEs"] = pbde_sum if pbde_found and pbde_sum > 0 else "N.D."
    return result

# ==========================================
# 4. æ¨™æº– SGS è§£ææ¨¡çµ„ (ä¿ç•™åŸæœ¬é‡å°å°ç£/ä¸­åœ‹å„ªåŒ–çš„ç‰ˆæœ¬)
# ==========================================
def parse_sgs_standard(pdf_obj, full_text, first_page_text):
    # é€™æ˜¯æ‚¨ä¹‹å‰ v6.5 çš„ä»£ç¢¼ï¼Œç”¨æ–¼è™•ç†å°ç£å’Œä¸­åœ‹å ±å‘Š (Limit åœ¨ä¸­é–“ï¼ŒResult åœ¨æœ€å³é‚Š A1/001)
    result = {k: None for k in SGS_OPTIMIZED_MAP.keys()}
    result['PFAS'] = ""
    result['DATE'] = ""

    lines = first_page_text.split('\n')
    for line in lines[:25]:
        if re.search(r"(?i)(Date|æ—¥æœŸ)", line) and not re.search(r"(?i)(Received|Testing|Period)", line):
            match_en = re.search(r"(?i)(?:Date|æ—¥æœŸ)\s*[:ï¼š]?\s*([A-Za-z]{3}\s+\d{1,2},?\s*\d{4}|\d{1,2}[-.\s][A-Za-z]{3}[-.\s]\d{4})", line)
            match_num = re.search(r"(?:Date|æ—¥æœŸ)\s*[:ï¼š]?\s*(\d{4}[-./å¹´]\s?\d{1,2}[-./æœˆ]\s?\d{1,2})", line)
            if match_en: result['DATE'] = clean_date_str(match_en.group(1)); break
            elif match_num: result['DATE'] = clean_date_str(match_num.group(1)); break

    pbb_sum = 0; pbde_sum = 0; pbb_found = False; pbde_found = False
    
    with pdfplumber.open(pdf_obj) as pdf:
        for page in pdf.pages:
            tables = page.extract_tables()
            for table in tables:
                if not table: continue
                header_row_idx = -1; result_col_idx = -1; limit_col_idx = -1; mdl_col_idx = -1
                
                for r_idx, row in enumerate(table[:5]): 
                    row_str_lower = " ".join([str(cell).lower() for cell in row if cell])
                    if any(x in row_str_lower for x in ['test item', 'unit', 'mdl', 'limit', 'æ¸¬è©¦é …ç›®']):
                        header_row_idx = r_idx
                        for c_idx, cell in enumerate(row):
                            cell_str = str(cell).strip()
                            if re.search(r"(?i)(Limit|é™å€¼)", cell_str): limit_col_idx = c_idx
                            elif re.search(r"(?i)(MDL|Method Det)", cell_str): mdl_col_idx = c_idx
                            elif re.search(r"(?i)(Result|No\.|çµæœ|00\d|A\d|Sample)", cell_str): result_col_idx = c_idx
                        
                        if result_col_idx == -1:
                            for c_idx in range(len(row)-1, -1, -1):
                                if c_idx != limit_col_idx and c_idx != mdl_col_idx and row[c_idx]:
                                    result_col_idx = c_idx; break
                        break
                
                start_row = header_row_idx + 1 if header_row_idx != -1 else 0
                for row in table[start_row:]:
                    row_clean = [str(c) for c in row if c]
                    row_str = " ".join(row_clean).replace("\n", " ")
                    
                    if re.search(r"(?i)(Perfluorooctanoic\s*Acid)", row_str) and "PFOA" not in SGS_OPTIMIZED_MAP: continue
                    if "PFAS" in row_str and not result['PFAS']: result['PFAS'] = "REPORT"

                    matched_key = None
                    for key, keywords in SGS_OPTIMIZED_MAP.items():
                        if any(kw.lower() in row_str.lower() for kw in keywords):
                            if key == "PFOS" and re.search(r"(?i)(Total|PFOSF|Derivative)", row_str): continue
                            if key in ['F', 'Cl', 'Br', 'I'] and not re.search(r"\((F|Cl|Br|I)-?\)", row_str): continue
                            matched_key = key; break
                    
                    is_pbb = re.search(PBB_SUBITEMS, row_str); is_pbde = re.search(PBDE_SUBITEMS, row_str)
                    if not matched_key and not is_pbb and not is_pbde: continue

                    target_val_str = ""
                    if result_col_idx != -1 and result_col_idx < len(row): target_val_str = str(row[result_col_idx])
                    else:
                        for c_idx in range(len(row)-1, -1, -1):
                            if c_idx == limit_col_idx or c_idx == mdl_col_idx: continue
                            if row[c_idx]:
                                cell_s = str(row[c_idx]).strip()
                                if cell_s.lower() in ["mg/kg", "ppm", "%"]: continue
                                target_val_str = cell_s; break
                    
                    cleaned_val = clean_value(target_val_str)
                    if matched_key:
                        current_val = result.get(matched_key)
                        if get_value_priority(cleaned_val) > get_value_priority(current_val): result[matched_key] = cleaned_val
                    elif is_pbb and isinstance(cleaned_val, (int, float)): pbb_found = True; pbb_sum += cleaned_val
                    elif is_pbde and isinstance(cleaned_val, (int, float)): pbde_found = True; pbde_sum += cleaned_val

    if "PFAS" in first_page_text: result["PFAS"] = "REPORT"
    result["PBBs"] = pbb_sum if pbb_found and pbb_sum > 0 else "N.D."
    result["PBDEs"] = pbde_sum if pbde_found and pbde_sum > 0 else "N.D."
    return result

# ==========================================
# 5. CTI èˆ‡ INTERTEK æ¨¡çµ„ (ç¶­æŒåŸæ¨£)
# ==========================================
def parse_cti(pdf_obj, full_text, first_page_text):
    result = {k: None for k in TARGET_ITEMS if k not in ['FILENAME', 'DATE']}
    result['PFAS'] = ""
    date_match = re.search(r"(?i)(?:Date|æ—¥æœŸ)\s*[:ï¼š]?\s*(\d{4}[-./å¹´]\s?\d{1,2}[-./æœˆ]\s?\d{1,2}|\w{3}\.\s*\d{1,2},\s*\d{4})", first_page_text)
    result['DATE'] = clean_date_str(date_match.group(1)) if date_match else ""
    pbb_sum = 0; pbde_sum = 0; pbb_found = False; pbde_found = False
    with pdfplumber.open(pdf_obj) as pdf:
        for page in pdf.pages:
            tables = page.extract_tables()
            for table in tables:
                if not table: continue
                res_idx = -1
                for i, col in enumerate(table): # Check first row
                    if col and re.search(r"(?i)(Result|ç»“æœ)", str(col)): res_idx = i; break
                if res_idx == -1: # Fallback
                     for i, col in enumerate(table):
                        if col and re.search(r"(?i)(MDL|LOQ|Limit)", str(col)): res_idx = i - 1 if i > 0 else i + 1; break
                if res_idx == -1: continue
                for row in table[1:]:
                    if len(row) <= res_idx: continue
                    row_str = " ".join([str(c) for c in row if c])
                    if re.search(r"(?i)(PFOA|Perfluorooctanoic)", row_str): continue
                    if "PFAS" in row_str and not result['PFAS']: result['PFAS'] = "REPORT"
                    val = clean_value(row[res_idx])
                    for pat, key in UNIFIED_REGEX_MAP.items():
                        if re.search(pat, row_str):
                            if key == "PFOS" and re.search(r"(?i)(Total|PFOSF)", row_str): continue
                            if val is not None:
                                cur = result.get(key)
                                if cur is None or cur == "N.D.": result[key] = val
                                elif isinstance(val, (int,float)) and isinstance(cur, (int,float)): result[key] = max(val, cur)
                            break
                    if re.search(PBB_SUBITEMS, row_str): pbb_found = True; pbb_sum += val if isinstance(val, (int,float)) else 0
                    if re.search(PBDE_SUBITEMS, row_str): pbde_found = True; pbde_sum += val if isinstance(val, (int,float)) else 0
    if "PFAS" in first_page_text: result["PFAS"] = "REPORT"
    result["PBBs"] = pbb_sum if pbb_found and pbb_sum > 0 else "N.D."
    result["PBDEs"] = pbde_sum if pbde_found and pbde_sum > 0 else "N.D."
    return result

def parse_intertek(pdf_obj, full_text, first_page_text):
    result = {k: None for k in TARGET_ITEMS if k not in ['FILENAME', 'DATE']}
    result['PFAS'] = ""; result['DATE'] = ""
    lines = first_page_text.split('\n')
    for line in lines[:25]:
        match = re.search(r"(?i)(?:Date|Issue Date)\s*[:ï¼š]?\s*([A-Za-z]{3}\s+\d{1,2},?\s*\d{4}|\d{4}[.\s]+\d{1,2}[.\s]+\d{1,2})", line)
        if match: result['DATE'] = clean_date_str(match.group(1)); break
    pbb_sum = 0; pbde_sum = 0; pbb_found = False; pbde_found = False
    with pdfplumber.open(pdf_obj) as pdf:
        for page in pdf.pages:
            tables = page.extract_tables()
            for table in tables:
                if not table: continue
                mdl_idx = -1
                for i, col in enumerate(table):
                    if col and re.search(r"(?i)(MDL|LOQ|Detection)", str(col)): mdl_idx = i; break
                if mdl_idx == -1: continue
                res_idx = -1
                if len(table) > 1: # Guess result based on MDL position
                     if mdl_idx + 1 < len(table) and re.search(r"(?i)Result", str(table[mdl_idx+1])): res_idx = mdl_idx + 1
                     elif mdl_idx - 1 >= 0: res_idx = mdl_idx - 1
                if res_idx == -1: continue
                for row in table[1:]:
                    if len(row) <= res_idx: continue
                    row_str = " ".join([str(c) for c in row if c])
                    val = clean_value(row[res_idx])
                    if re.search(r"(?i)(PFOA|Perfluorooctanoic)", row_str): continue
                    if "PFAS" in row_str and not result['PFAS']: result['PFAS'] = "REPORT"
                    for pat, key in UNIFIED_REGEX_MAP.items():
                        if re.search(pat, row_str):
                            if key == "PFOS" and re.search(r"(?i)(Total|PFOSF)", row_str): continue
                            if val is not None:
                                cur = result.get(key)
                                if cur is None or cur == "N.D.": result[key] = val
                                elif isinstance(val, (int,float)) and isinstance(cur, (int,float)): result[key] = max(val, cur)
                            break
                    if re.search(PBB_SUBITEMS, row_str): pbb_found = True; pbb_sum += val if isinstance(val, (int,float)) else 0
                    if re.search(PBDE_SUBITEMS, row_str): pbde_found = True; pbde_sum += val if isinstance(val, (int,float)) else 0
    if "PFAS" in first_page_text: result["PFAS"] = "REPORT"
    result["PBBs"] = pbb_sum if pbb_found and pbb_sum > 0 else "N.D."
    result["PBDEs"] = pbde_sum if pbde_found and pbde_sum > 0 else "N.D."
    return result

# ==========================================
# 6. ä¸»ç¨‹å¼ (è­˜åˆ¥å» å•†é‚è¼¯æ›´æ–°)
# ==========================================
def identify_vendor(first_page_text):
    text = first_page_text.lower()
    if "intertek" in text: return "INTERTEK"
    if "cti" in text or "åæµ‹" in text: return "CTI"
    if "sgs" in text:
        # æ–°å¢åˆ¤æ–·ï¼šSGS é¦¬ä¾†è¥¿äº
        if "malaysia" in text: return "SGS_MALAYSIA"
        return "SGS"
    return "UNKNOWN"

def main():
    st.set_page_config(page_title="åŒ–å­¸å ±å‘Šè‡ªå‹•å½™æ•´ç³»çµ± v7.0 (Malaysia Support)", layout="wide")
    st.title("ğŸ§ª åŒ–å­¸æ¸¬è©¦å ±å‘Šè‡ªå‹•å½™æ•´ç³»çµ± v7.0")
    
    st.markdown("""
    **ç‰ˆæœ¬æ›´æ–° v7.0ï¼š**
    - **æ–°å¢ SGS é¦¬ä¾†è¥¿äºç‰ˆæ”¯æ´ï¼š** é‡å° Result æ¬„ä½åœ¨ä¸­é–“åŠæ—¥æœŸæ ¼å¼ (January) é€²è¡Œå„ªåŒ–ã€‚
    - **SGS æ¨™æº–ç‰ˆ/CTI/Intertekï¼š** é‚è¼¯ç¶­æŒä¸è®Šã€‚
    """)

    uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ PDF å ±å‘Š (æ”¯æ´å¤šæª”)", type="pdf", accept_multiple_files=True)

    if uploaded_files:
        if st.button("é–‹å§‹åˆ†æ"):
            valid_results = []
            bucket_unknown = []
            bucket_error = []
            
            progress_bar = st.progress(0)
            status_text = st.empty()

            for i, file in enumerate(uploaded_files):
                status_text.text(f"æ­£åœ¨è™•ç†: {file.name}...")
                try:
                    with pdfplumber.open(file) as pdf:
                        if len(pdf.pages) == 0: bucket_error.append(file.name); continue
                        
                        # [é—œéµä¿®æ­£] è®€å–ç¬¬ä¸€é 
                        first_page_text = pdf.pages.extract_text()
                        if not first_page_text: bucket_error.append(f"{file.name} (ç„¡æ³•è®€å–)"); continue
                        
                        full_text = ""
                        for page in pdf.pages:
                            txt = page.extract_text()
                            if txt: full_text += txt + "\n"
                        
                        vendor = identify_vendor(first_page_text)
                        data = None
                        
                        # åˆ†æµè™•ç†
                        if vendor == "SGS_MALAYSIA":
                            data = parse_sgs_malaysia(file, full_text, first_page_text)
                        elif vendor == "SGS":
                            data = parse_sgs_standard(file, full_text, first_page_text)
                        elif vendor == "CTI":
                            data = parse_cti(file, full_text, first_page_text)
                        elif vendor == "INTERTEK":
                            data = parse_intertek(file, full_text, first_page_text)
                        else:
                            bucket_unknown.append(file.name)
                            continue
                        
                        if data:
                            data['FILENAME'] = file.name
                            valid_results.append(data)
                        else:
                            bucket_error.append(f"{file.name} (è§£æå¤±æ•—)")

                except Exception as e:
                    bucket_error.append(f"{file.name} (éŒ¯èª¤: {str(e)})")
                
                progress_bar.progress((i + 1) / len(uploaded_files))

            status_text.text("åˆ†æå®Œæˆï¼")

            if valid_results:
                df_final = pd.DataFrame(valid_results)
                cols = ["FILENAME", "DATE"] + [c for c in TARGET_ITEMS if c not in ["FILENAME", "DATE"]]
                avail_cols = [c for c in cols if c in df_final.columns]
                df_final = df_final[avail_cols]

                st.success(f"âœ… æˆåŠŸè™•ç† {len(valid_results)} ä»½å ±å‘Šï¼š")
                st.dataframe(df_final)

                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df_final.to_excel(writer, index=False, sheet_name='Summary')
                output.seek(0)

                st.download_button(
                    label="ğŸ“¥ ä¸‹è¼‰ Excel",
                    data=output,
                    file_name=f"Report_Summary_{pd.Timestamp.now().strftime('%Y%m%d')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.warning("æœªæå–åˆ°æœ‰æ•ˆæ•¸æ“šã€‚")

            if bucket_unknown or bucket_error:
                st.divider()
                st.subheader("âš ï¸ ç•°å¸¸å ±å‘Š")
                if bucket_unknown:
                    for name in bucket_unknown: st.write(f"- ğŸ§ª æœªè­˜åˆ¥å» å•†: {name}")
                if bucket_error:
                    for name in bucket_error: st.write(f"- ğŸ”´ éŒ¯èª¤: {name}")

if __name__ == "__main__":
    main()
