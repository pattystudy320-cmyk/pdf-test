import streamlit as st
import pdfplumber
import pandas as pd
import re
import math

# --- è¨­å®šé é¢ ---
st.set_page_config(page_title="é€šç”¨æª¢æ¸¬å ±å‘Šæ“·å–å·¥å…· (V4 æœ€çµ‚ç‰ˆ)", layout="wide")
st.title("ğŸ§ª é€šç”¨å‹ç¬¬ä¸‰æ–¹æª¢æ¸¬å ±å‘Šæ•¸æ“šæ“·å–å·¥å…· (V4 æœ€çµ‚ç‰ˆ)")
st.markdown("""
**V4 é‡å¤§å‡ç´šï¼š**
1. **åå­—åº§æ¨™é–å®š**ï¼šè§£æ±ºã€Œéš±å½¢è¡¨æ ¼ã€èˆ‡ã€Œç„¡æ¡†ç·šã€æ’ç‰ˆå•é¡Œã€‚
2. **æ™ºæ…§æ’é™¤æ³•**ï¼šç²¾æº–é¿é–‹ MDLã€Limit èˆ‡æ¸¬è©¦æ–¹æ³•ç·¨è™Ÿã€‚
3. **ä¸­è‹±æ–‡é›™èªæ”¯æ´**ï¼šå®Œç¾ç›¸å®¹ä¸­æ–‡å ±å‘Šèˆ‡è‹±æ–‡å ±å‘Šã€‚
4. **æ—¥æœŸç²¾æº–é–å®š**ï¼šåªæŠ“å–é¦–é å ±å‘Šæ—¥æœŸï¼Œæ’é™¤å¹²æ“¾ã€‚
""")

# --- 1. å®šç¾©ç›®æ¨™æ¬„ä½èˆ‡é—œéµå­—è¯é›† (ä¸­è‹±æ–‡) ---
TARGET_FIELDS = {
    "Lead": {"name": "Pb", "keywords": [r"^Lead\b", r"^Pb\b", r"é“…", r"Lead \(Pb\)", r"Pb"]},
    "Cadmium": {"name": "Cd", "keywords": [r"^Cadmium\b", r"^Cd\b", r"é•‰", r"Cadmium \(Cd\)", r"Cd"]},
    "Mercury": {"name": "Hg", "keywords": [r"^Mercury\b", r"^Hg\b", r"æ±", r"Mercury \(Hg\)", r"Hg"]},
    "Hexavalent Chromium": {"name": "Cr(VI)", "keywords": [r"Hexavalent Chromium", r"Cr\(VI\)", r"Cr6\+", r"å…­ä»·é“¬", r"å…­åƒ¹é‰»"]},
    "DEHP": {"name": "DEHP", "keywords": [r"Bis\(2-ethylhexyl\) phthalate", r"DEHP", r"é‚»è‹¯äºŒç”²é…¸äºŒ\(2-ä¹™åŸºå·±åŸº\)é…¯"]},
    "BBP": {"name": "BBP", "keywords": [r"Butyl benzyl phthalate", r"BBP", r"é‚»è‹¯äºŒç”²é…¸ä¸åŸºè‹„åŸºé…¯"]},
    "DBP": {"name": "DBP", "keywords": [r"Dibutyl phthalate", r"DBP", r"é‚»è‹¯äºŒç”²é…¸äºŒä¸é…¯"]},
    "DIBP": {"name": "DIBP", "keywords": [r"Diisobutyl phthalate", r"DIBP", r"é‚»è‹¯äºŒç”²é…¸äºŒå¼‚ä¸é…¯"]},
    "Fluorine": {"name": "F", "keywords": [r"Fluorine", r"æ°Ÿ", r"Fluorine \(F\)"]},
    "Chlorine": {"name": "Cl", "keywords": [r"Chlorine", r"æ°¯", r"Chlorine \(Cl\)"]},
    "Bromine": {"name": "Br", "keywords": [r"Bromine", r"æº´", r"Bromine \(Br\)"]},
    "Iodine": {"name": "I", "keywords": [r"Iodine", r"ç¢˜", r"Iodine \(I\)"]},
    "PFOS": {"name": "PFOS", "keywords": [r"Perfluorooctane Sulfonates", r"PFOS", r"å…¨æ°Ÿè¾›ç£ºé…¸"]},
}

# PBBs/PBDEs å­é …ç›®é—œéµå­—
PBBS_KEYWORDS = [r"Monobromobiphenyl", r"Dibromobiphenyl", r"Tribromobiphenyl", r"Tetrabromobiphenyl", 
                 r"Pentabromobiphenyl", r"Hexabromobiphenyl", r"Heptabromobiphenyl", r"Octabromobiphenyl", 
                 r"Nonabromobiphenyl", r"Decabromobiphenyl", r"ä¸€æº´è”è‹¯", r"åæº´è”è‹¯", r"ä¸€æº´è¯è‹¯"]
PBDES_KEYWORDS = [r"Monobromodiphenyl ether", r"Dibromodiphenyl ether", r"Tribromodiphenyl ether", 
                  r"Tetrabromodiphenyl ether", r"Pentabromodiphenyl ether", r"Hexabromodiphenyl ether", 
                  r"Heptabromodiphenyl ether", r"Octabromodiphenyl ether", r"Nonabromodiphenyl ether", 
                  r"Decabromodiphenyl ether", r"ä¸€æº´äºŒè‹¯é†š", r"åæº´äºŒè‹¯é†š"]

# --- 2. è¼”åŠ©å‡½å¼å€ ---

def clean_text(text):
    """æ¸…ç†æ–‡å­—ï¼Œç§»é™¤å¤šé¤˜ç©ºç™½èˆ‡æ›è¡Œ"""
    if not text: return ""
    return re.sub(r'\s+', ' ', str(text)).strip()

def extract_value_logic(val_str):
    """æ•¸å€¼æå–èˆ‡å„ªå…ˆç´šé‚è¼¯"""
    if not val_str: return 0, "N.D."
    
    val_upper = str(val_str).upper().replace(" ", "")
    
    if "N.D." in val_upper or "ND" in val_upper or "<" in val_upper:
        return 0, "N.D."
    if "NEGATIVE" in val_upper or "é˜´æ€§" in val_upper:
        return 0.0001, "NEGATIVE"
    if "POSITIVE" in val_upper or "é˜³æ€§" in val_upper:
        return 999999, "POSITIVE"
    
    # ç§»é™¤å¯èƒ½çš„å–®ä½å¹²æ“¾ (mg/kg, ppm) å†æŠ“æ•¸å­—
    val_clean = re.sub(r"(mg/kg|ppm|%)", "", val_str, flags=re.IGNORECASE)
    match = re.search(r"(\d+(\.\d+)?)", val_clean)
    
    if match:
        num = float(match.group(1))
        # ç°¡å–®éæ¿¾ï¼šæ’é™¤å¯èƒ½æ˜¯ MDL/Limit çš„å¸¸è¦‹æ•´æ•¸ (åƒ…ä½œè¼”åŠ©ï¼Œä¸»è¦é æ¬„ä½é–å®š)
        return num, match.group(1)
    
    return 0, "N.D."

def find_date_in_first_page(text):
    """åªåœ¨ç¬¬ä¸€é æ–‡å­—ä¸­æŠ“å–æ—¥æœŸ"""
    # æ ¼å¼ï¼šJan 08, 2025 | 2025/01/08 | 2025.01.08
    date_patterns = [
        r"(?:Issue Date|Report Date|Date|Testing Period|æ—¥æœŸ)\s*[:ï¼š\n]?\s*([A-Za-z]{3,9}\.?\s+\d{1,2},?\s+\d{4})",
        r"(?:Issue Date|Report Date|Date|Testing Period|æ—¥æœŸ)\s*[:ï¼š\n]?\s*(\d{4}[-/. ]\d{1,2}[-/. ]\d{1,2})",
        # é‡å°ç„¡æ¨™é¡Œçš„æ—¥æœŸè¡Œ (é¢¨éšªè¼ƒé«˜ï¼Œæ”¾æœ€å¾Œ)
        r"^\s*([A-Za-z]{3,9}\.?\s+\d{1,2},?\s+\d{4})\s*$"
    ]
    
    for pattern in date_patterns:
        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
        if match:
            return match.group(1).replace("\n", " ").strip()
    return ""

def get_column_strategy(header_cells):
    """
    åå­—åº§æ¨™é–å®šæ ¸å¿ƒï¼šåˆ†æè¡¨é ­ï¼Œæ±ºå®šå“ªä¸€æ¬„æ˜¯ Result
    å›å‚³ï¼š(çµæœæ¬„ç´¢å¼•, æ˜¯å¦æœ‰æ•ˆ)
    """
    # æ’é™¤é—œéµå­— (ä¸­è‹±æ–‡)
    exclude_keywords = ["ITEM", "METHOD", "UNIT", "MDL", "LOQ", "LIMIT", "REQUIREMENT", 
                        "é¡¹ç›®", "æ–¹æ³•", "å•ä½", "é™å€¼", "RL"]
    
    # ç›®æ¨™é—œéµå­— (æ‰¾åˆ°é€™äº›é€šå¸¸å°±æ˜¯çµæœæ¬„)
    target_keywords = ["RESULT", "ç»“æœ", "SAMPLE", "NO.", "ID", "001", "002", "A1", "DATA"]
    
    best_col_idx = -1
    max_score = -1
    
    for i, cell in enumerate(header_cells):
        if not cell: continue
        txt = clean_text(cell).upper()
        
        # 1. å¦‚æœåŒ…å«æ’é™¤å­—ï¼Œåˆ†æ•¸è¨­ç‚ºæ¥µä½
        if any(ex in txt for ex in exclude_keywords):
            continue
            
        # 2. å¦‚æœåŒ…å«ç›®æ¨™å­—ï¼Œåˆ†æ•¸æ¥µé«˜
        score = 0
        if any(tg in txt for tg in target_keywords):
            score += 10
        
        # 3. å•Ÿç™¼å¼è¦å‰‡ï¼šçµæœæ¬„é€šå¸¸åœ¨ä¸­é–“æˆ–é å³ï¼Œä½†ä¸æœƒæ˜¯æœ€å³é‚Šçš„ Limit
        # é€™è£¡ç°¡å–®è™•ç†ï¼šåªè¦ä¸æ˜¯æ’é™¤æ¬„ä½ï¼Œä¸”åˆ†æ•¸æœ€é«˜è€…å¾—æ¨™
        if score > max_score:
            max_score = score
            best_col_idx = i
            
    # å¦‚æœæ²’æ‰¾åˆ°æ˜ç¢ºçš„ Resultï¼Œä½†æœ‰æ’é™¤æ‰ Method/Unitï¼Œä¸”å‰©ä¸‹æ¬„ä½ > 0ï¼Œå–æœ€å¾Œä¸€å€‹éæ’é™¤æ¬„ä½
    if best_col_idx == -1:
        valid_indices = [i for i, c in enumerate(header_cells) if c and not any(ex in clean_text(c).upper() for ex in exclude_keywords)]
        if valid_indices:
            best_col_idx = valid_indices[0] # å–ç¬¬ä¸€å€‹ã€Œéæ’é™¤ã€æ¬„ä½é€šå¸¸æ¯”è¼ƒä¿éšª (é¿å…å–åˆ°æœ€å³é‚Šçš„ Note)
            
    return best_col_idx

# --- 3. æ ¸å¿ƒè™•ç†é‚è¼¯ (æ”¯æ´éš±å½¢è¡¨æ ¼) ---

def process_file(uploaded_file):
    filename = uploaded_file.name
    results = {k: {"val": 0, "display": ""} for k in TARGET_FIELDS.keys()}
    results["PBBs"] = {"val": 0, "display": "", "sum_val": 0}
    results["PBDEs"] = {"val": 0, "display": "", "sum_val": 0}
    results["PFAS"] = ""
    results["Date"] = ""
    
    is_scanned = True
    full_text_content = ""
    
    with pdfplumber.open(uploaded_file) as pdf:
        # --- A. å…¨æ–‡æƒæ (PFAS & æƒææª”æª¢æŸ¥) ---
        for i, page in enumerate(pdf.pages):
            text = page.extract_text()
            if text and len(text) > 50:
                is_scanned = False
                full_text_content += text + "\n"
                # åªåœ¨ç¬¬ä¸€é æ‰¾æ—¥æœŸ
                if i == 0:
                    results["Date"] = find_date_in_first_page(text)

        if is_scanned:
            return None, filename

        # PFAS åˆ¤æ–·
        if "PFAS" in full_text_content.upper() or "PER- AND POLYFLUOROALKYL" in full_text_content.upper():
            results["PFAS"] = "REPORT"

        # --- B. æ•¸æ“šæ“·å– (é›™æ¨¡å¼ï¼šè¡¨æ ¼æ¨¡å¼ + æ–‡å­—æµæ¨¡å¼) ---
        for page in pdf.pages:
            # æ¨¡å¼ 1ï¼šæ¨™æº–è¡¨æ ¼æå–
            extracted_tables = page.extract_tables()
            
            # å¦‚æœé€™é å®Œå…¨æ²’æŠ“åˆ°è¡¨æ ¼ï¼Œæˆ–è€…è¡¨æ ¼å¤ªç ´ç¢ï¼Œæˆ‘å€‘åˆ‡æ›åˆ°ã€Œæ–‡å­—æµæ¨¡å¼ã€
            # é€™è£¡ç°¡åŒ–è™•ç†ï¼šå…ˆè·‘è¡¨æ ¼æ¨¡å¼ï¼Œè‹¥è¡¨æ ¼å…§æœ‰æ•¸æ“šå°±æŠ“
            
            if extracted_tables:
                for table in extracted_tables:
                    if not table or len(table) < 2: continue
                    
                    # å°‹æ‰¾è¡¨é ­
                    header_row_idx = -1
                    result_col_idx = -1
                    
                    # æƒæå‰å¹¾è¡Œæ‰¾è¡¨é ­
                    for r_idx, row in enumerate(table[:5]):
                        # åˆ¤æ–·æ˜¯å¦ç‚ºè¡¨é ­ï¼šå«æœ‰ Item/Method/Unit ç­‰å­—çœ¼
                        row_text = " ".join([str(c).upper() for c in row if c])
                        if ("ITEM" in row_text or "é¡¹ç›®" in row_text) and ("UNIT" in row_text or "å•ä½" in row_text or "MDL" in row_text):
                            header_row_idx = r_idx
                            result_col_idx = get_column_strategy(row)
                            break
                    
                    if result_col_idx != -1:
                        # æœ‰æ•ˆè¡¨æ ¼ï¼Œé–‹å§‹æŠ“æ•¸æ“š
                        for r_idx in range(header_row_idx + 1, len(table)):
                            row = table[r_idx]
                            if len(row) <= result_col_idx: continue
                            
                            # çµ„åˆç¬¬ä¸€æ¬„èˆ‡ç¬¬äºŒæ¬„ä½œç‚ºé …ç›®åç¨± (è™•ç†è·¨æ¬„)
                            item_name = clean_text(row[0])
                            if len(row) > 1: item_name += " " + clean_text(row[1])
                            
                            val_text = clean_text(row[result_col_idx])
                            update_results(results, item_name, val_text)
                            
            # æ¨¡å¼ 2ï¼šéš±å½¢è¡¨æ ¼/æ–‡å­—æµ (ç•¶è¡¨æ ¼æ¨¡å¼å¯èƒ½æ¼æ‰æ™‚çš„è£œå¼·ï¼Œæˆ–é‡å°ç„¡æ¡†ç·šå ±å‘Š)
            # pdfplumber çš„ extract_text(layout=True) å¯ä»¥ä¿ç•™è¦–è¦ºç›¸å°ä½ç½®
            # ä½†ç‚ºäº†ç°¡å–®ä¸”é«˜æ•ˆï¼Œæˆ‘å€‘é€™è£¡ä½¿ç”¨ extract_words ä¾†åšç°¡æ˜“çš„ã€Œè¡Œå°é½Šã€åˆ†æ
            # é€™è£¡é‡å°ã€Œéš±å½¢è¡¨æ ¼ã€çš„é‚è¼¯ï¼š
            # 1. æ‰¾åˆ°é—œéµå­— (å¦‚ "Lead") çš„ Y è»¸
            # 2. æ‰¾åˆ°åŒä¸€ Y è»¸ä¸Šï¼Œæœ€é å³å´ (ä½†ä¸æ˜¯ Limit) çš„æ–‡å­—
            
            words = page.extract_words(keep_blank_chars=True)
            # å°‡æ–‡å­—æŒ‰è¡Œåˆ†çµ„ (Tolerance 3)
            rows = {}
            for w in words:
                y = round(w['top'] / 3) * 3 # æ¨¡ç³Š Y è»¸
                if y not in rows: rows[y] = []
                rows[y].append(w)
            
            # éæ­·æ¯ä¸€è¡Œæ–‡å­—
            for y, row_words in rows.items():
                # å°‡é€™ä¸€è¡Œçš„æ–‡å­—çµ„åˆæˆå­—ä¸²
                line_text = " ".join([w['text'] for w in row_words])
                
                # ç°¡å–®çš„å•Ÿç™¼å¼ï¼šå¦‚æœé€™ä¸€è¡ŒåŒ…å«æˆ‘å€‘çš„é—œéµå­—
                # å˜—è©¦å¾é€™ä¸€è¡Œæ‰¾å‡ºæ•¸å­—æˆ– N.D.
                # é€™è£¡çš„é¢¨éšªæ˜¯å¯èƒ½æœƒæŠ“åˆ° MDLï¼Œæ‰€ä»¥æˆ‘å€‘éœ€è¦æª¢æŸ¥åŒä¸€è¡Œæœ‰æ²’æœ‰å¤šå€‹æ•¸å­—
                
                # é‡å°ä¸€èˆ¬é …ç›®
                for field, config in TARGET_FIELDS.items():
                    for kw in config["keywords"]:
                        if re.search(kw, line_text, re.IGNORECASE):
                            # åœ¨é€™ä¸€è¡Œä¸­å°‹æ‰¾ ND æˆ– æ•¸å­—
                            # æ’é™¤æ‰ Item Name æœ¬èº«
                            # ç­–ç•¥ï¼šç”±å³å‘å·¦æ‰¾ (é€šå¸¸çµæœåœ¨å³é‚Š)ï¼Œä¸”è·³é Limit (é€šå¸¸æœ€å¤§)
                            
                            # æ‰¾å‡ºæ‰€æœ‰å€™é¸å€¼
                            candidates = []
                            # ç°¡å–®åˆ‡åˆ†
                            parts = line_text.split()
                            for part in parts:
                                val, disp = extract_value_logic(part)
                                # æ’é™¤æ˜é¡¯çš„ Limit (å¦‚ 1000) å’Œ MDL (å¦‚ 2, 5, 10) 
                                # é€™æ˜¯ä¸€å€‹ç´”æ–‡å­—æ¨¡å¼ä¸‹çš„å¦¥å”ï¼šè‹¥æœ‰è¡¨æ ¼æ¨¡å¼å„ªå…ˆä¿¡è¡¨æ ¼
                                if val in [100, 1000, 2, 5, 8, 10, 25, 50] and disp != "N.D.":
                                    continue
                                if disp == "N.D." or val > 0:
                                    candidates.append((val, disp))
                            
                            if candidates:
                                # å„ªå…ˆå– N.D.ï¼Œæˆ–æ˜¯é MDL çš„æ•¸å€¼
                                # é€™è£¡å‡è¨­ï¼šå¦‚æœæœ‰å¤šå€‹å€™é¸ï¼Œå–æœ€å¾Œä¸€å€‹ (é€šå¸¸çµæœåœ¨å³é‚Š) 
                                # æˆ–è€…å– N.D. (æœ€å¸¸è¦‹)
                                best_val, best_disp = candidates[-1] # å–æœ€å³é‚Š
                                update_results(results, field, best_disp, is_text_mode=True)

                # é‡å° PBBs/PBDEs (åŒæ¨£é‚è¼¯)
                for pbb_kw in PBBS_KEYWORDS + PBDES_KEYWORDS:
                    if re.search(pbb_kw, line_text, re.IGNORECASE):
                         parts = line_text.split()
                         for part in parts:
                             val, disp = extract_value_logic(part)
                             if val in [1000, 5, 25] and disp != "N.D.": continue # æ’é™¤ Limit/MDL
                             if val > 0: # åªæœ‰æŠ“åˆ°æ•¸å€¼æ‰åŠ ç¸½ (N.D. ç‚º 0)
                                 # åˆ¤æ–·æ˜¯ PBB é‚„æ˜¯ PBDE
                                 cat = "PBBs" if any(k in pbb_kw for k in PBBS_KEYWORDS) else "PBDEs"
                                 results[cat]["sum_val"] += val
                                 break

    # --- C. æœ€çµ‚æ•¸å€¼çµç®— ---
    finalize_results(results)
    
    # --- D. è¼¸å‡ºæ ¼å¼åŒ– ---
    final_output = {
        "File Name": filename,
        "Pb": results["Lead"]["display"],
        "Cd": results["Cadmium"]["display"],
        "Hg": results["Mercury"]["display"],
        "Cr(VI)": results["Hexavalent Chromium"]["display"],
        "PBBs": results["PBBs"]["display"],
        "PBDEs": results["PBDEs"]["display"],
        "DEHP": results["DEHP"]["display"],
        "BBP": results["BBP"]["display"],
        "DBP": results["DBP"]["display"],
        "DIBP": results["DIBP"]["display"],
        "F": results["Fluorine"]["display"],
        "Cl": results["Chlorine"]["display"],
        "Br": results["Bromine"]["display"],
        "I": results["Iodine"]["display"],
        "PFOS": results["PFOS"]["display"],
        "PFAS": results["PFAS"],
        "Date": results["Date"],
        # æ’åºç”¨éš±è—æ¬„ä½
        "_sort_pb": results["Lead"]["val"],
        "_sort_max": max([v["val"] for k, v in results.items() if isinstance(v, dict) and "val" in v])
    }
    
    return final_output, None

def update_results(results, item_name, val_text, is_text_mode=False):
    """
    çµ±ä¸€æ›´æ–°çµæœçš„é‚è¼¯ï¼ŒåŒ…å«æ¯”è¼ƒå¤§å° (è‹¥åŒä¸€æª”æ¡ˆå¤šå€‹æ•¸æ“š)
    item_name: é …ç›®åç¨± (å¦‚ "Lead")
    val_text: æŠ“åˆ°çš„æ•¸å€¼æ–‡å­— (å¦‚ "N.D." æˆ– "8")
    """
    item_upper = str(item_name).upper()
    val_num, val_disp = extract_value_logic(val_text)
    
    # 1. ä¸€èˆ¬é …ç›®åŒ¹é…
    for field_key, config in TARGET_FIELDS.items():
        for kw in config["keywords"]:
            if re.search(kw, item_upper, re.IGNORECASE):
                # å¦‚æœæ˜¯æ–‡å­—æ¨¡å¼ä¸”è©²æ¬„ä½å·²æœ‰å€¼ (ä¾†è‡ªè¡¨æ ¼æ¨¡å¼)ï¼Œå‰‡è·³é (è¡¨æ ¼æ¨¡å¼è¼ƒæº–)
                if is_text_mode and results[field_key]["val"] > 0:
                    return

                if val_num > results[field_key]["val"]:
                    results[field_key]["val"] = val_num
                    results[field_key]["display"] = val_disp
                elif val_num == 0 and results[field_key]["val"] == 0:
                    if val_disp == "NEGATIVE": results[field_key]["display"] = "NEGATIVE"
                    elif not results[field_key]["display"]: results[field_key]["display"] = "N.D."
                return

    # 2. PBBs/PBDEs åŠ ç¸½
    for pbb_kw in PBBS_KEYWORDS:
        if re.search(pbb_kw, item_upper, re.IGNORECASE):
            # æ’é™¤æ–‡å­—æ¨¡å¼ä¸‹çš„é‡è¤‡åŠ ç¸½é¢¨éšª (ç°¡å–®åšï¼šåªä¿¡è¡¨æ ¼æ¨¡å¼çš„åŠ ç¸½ï¼Œæˆ–æ˜¯éå¸¸ç¢ºå®šæ‰åŠ )
            if is_text_mode: return 
            results["PBBs"]["sum_val"] += val_num
            return

    for pbde_kw in PBDES_KEYWORDS:
        if re.search(pbde_kw, item_upper, re.IGNORECASE):
            if is_text_mode: return
            results["PBDEs"]["sum_val"] += val_num
            return

def finalize_results(results):
    """è¨ˆç®—æœ€çµ‚é¡¯ç¤º (PBBs/PBDEs)"""
    if results["PBBs"]["sum_val"] > 0:
        results["PBBs"]["display"] = str(round(results["PBBs"]["sum_val"], 2))
        results["PBBs"]["val"] = results["PBBs"]["sum_val"]
    elif not results["PBBs"]["display"]:
        results["PBBs"]["display"] = "N.D."

    if results["PBDEs"]["sum_val"] > 0:
        results["PBDEs"]["display"] = str(round(results["PBDEs"]["sum_val"], 2))
        results["PBDEs"]["val"] = results["PBDEs"]["sum_val"]
    elif not results["PBDEs"]["display"]:
        results["PBDEs"]["display"] = "N.D."

# --- ä¸»ä»‹é¢ ---

uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ PDF æª¢æ¸¬å ±å‘Š (æ”¯æ´ SGS, CTI, Intertek ç­‰)", type="pdf", accept_multiple_files=True)

if uploaded_files:
    all_data = []
    scanned_files = []

    with st.spinner('æ­£åœ¨é€²è¡Œ V4 å¼•æ“åˆ†æ (åå­—é–å®š + é›™æ¨¡å¼æƒæ)...'):
        for pdf_file in uploaded_files:
            data, scanned_name = process_file(pdf_file)
            if scanned_name:
                scanned_files.append(scanned_name)
            else:
                all_data.append(data)

    if all_data:
        df = pd.DataFrame(all_data)
        # æ’åºï¼šPb å„ªå…ˆï¼Œå…¶ä»–æœ€å¤§å€¼æ¬¡ä¹‹
        df = df.sort_values(by=["_sort_pb", "_sort_max"], ascending=[False, False])
        display_df = df.drop(columns=["_sort_pb", "_sort_max"])
        
        st.success(f"âœ… æˆåŠŸæ“·å– {len(all_data)} ä»½å ±å‘Šï¼")
        st.dataframe(display_df, use_container_width=True)
        
        csv = display_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel/CSV å ±è¡¨",
            data=csv,
            file_name="rohs_report_v4.csv",
            mime="text/csv",
        )

    if scanned_files:
        st.error("âš ï¸ ä»¥ä¸‹æª”æ¡ˆç‚ºæƒæåœ–ç‰‡ (ç„¡æ³•æ“·å–æ–‡å­—)ï¼š")
        for f in scanned_files:
            st.write(f"- {f}")

else:
    st.info("è«‹ä¸Šå‚³ PDF æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚")
