import streamlit as st
import pdfplumber
import pandas as pd
import re
from datetime import datetime
import io

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="RoHS/REACH å ±å‘Šå½™æ•´å·¥å…·", layout="wide")
st.title("ğŸ“„ åŒ–å­¸æª¢æ¸¬å ±å‘Šæ•¸æ“šè‡ªå‹•å½™æ•´å·¥å…·")
st.markdown("""
æœ¬å·¥å…·æ”¯æ´ SGS èˆ‡ CTI æ ¼å¼å ±å‘Šã€‚
**é‚è¼¯èªªæ˜ï¼š**
1. **æ•¸å€¼å–æ¨£ï¼š** å¤šä»½å ±å‘Šä¸­å–æœ€å¤§å€¼ (æ•¸å­— > N.D.)ã€‚
2. **PFAS åˆ¤æ–·ï¼š** åƒ…ç•¶ã€ŒTest Requested/æª¢æ¸¬è¦æ±‚ã€æ¬„ä½æ˜ç¢ºå‡ºç¾ "PFAS" å­—ä¸²æ™‚é¡¯ç¤º "REPORT"ã€‚
3. **FILE NAMEï¼š** é¡¯ç¤ºé‰› (Pb) æ•¸å€¼æœ€é«˜çš„ä¾†æºæª”åã€‚
""")

# --- æ ¸å¿ƒé—œéµå­—æ˜ å°„ ---
# æ ¹æ“šä¸Šå‚³çš„æ–‡ä»¶å…§å®¹å„ªåŒ–é—œéµå­—
KEYWORDS_MAP = {
    'Pb': ['Lead', 'Pb', 'é“…'],
    'Cd': ['Cadmium', 'Cd', 'é•‰'],
    'Hg': ['Mercury', 'Hg', 'æ±'],
    'Cr6+': ['Hexavalent Chromium', 'Cr(VI)', 'Cr6+', 'å…­ä»·é“¬'],
    'PBB': ['PBBs', 'Polybrominated biphenyls', 'Sum of PBBs', 'å¤šæº´è”è‹¯'],
    'PBDE': ['PBDEs', 'Polybrominated diphenyl ethers', 'Sum of PBDEs', 'å¤šæº´äºŒè‹¯é†š'],
    'DEHP': ['DEHP', 'Bis(2-ethylhexyl) phthalate', 'é‚»è‹¯äºŒç”²é…¸äºŒ(2-ä¹™åŸºå·±åŸº)é…¯'],
    'DBP':  ['DBP', 'Dibutyl phthalate', 'é‚»è‹¯äºŒç”²é…¸äºŒä¸é…¯'],
    'BBP':  ['BBP', 'Butyl benzyl phthalate', 'é‚»è‹¯äºŒç”²é…¸ä¸è‹„é…¯'],
    'DIBP': ['DIBP', 'Diisobutyl phthalate', 'é‚»è‹¯äºŒç”²é…¸äºŒå¼‚ä¸é…¯'],
    'F':    ['Fluorine', 'Halogen-Fluorine', 'æ°Ÿ', 'Fluorine (F)'],
    'CL':   ['Chlorine', 'Halogen-Chlorine', 'æ°¯', 'Chlorine (Cl)'],
    'BR':   ['Bromine', 'Halogen-Bromine', 'æº´', 'Bromine (Br)'],
    'PFOS': ['Perfluorooctane sulfonates', 'PFOS', 'å…¨æ°Ÿè¾›çƒ·ç£ºé…¸'],
}

# --- è¼”åŠ©å‡½å¼ï¼šæ—¥æœŸè§£æ ---
def parse_date(date_str):
    """
    è§£æå¤šç¨®æ—¥æœŸæ ¼å¼ï¼Œçµ±ä¸€å›å‚³ datetime ç‰©ä»¶
    æ”¯æ´æ ¼å¼: 
    - Feb 27, 2025 (SGS)
    - 2025.06.16 (CTI)
    - 27-Feb-2025 (CTI)
    """
    if not date_str:
        return None
    
    date_str = date_str.strip()
    # å®šç¾©å¸¸è¦‹æ—¥æœŸæ ¼å¼
    formats = [
        "%b %d, %Y",      # Feb 27, 2025
        "%Y.%m.%d",       # 2025.06.16
        "%d-%b-%Y",       # 27-Feb-2025
        "%Y/%m/%d",
        "%Y-%m-%d",
        "%Yå¹´%mæœˆ%dæ—¥"
    ]
    
    for fmt in formats:
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            continue
    return None

# --- æ ¸å¿ƒå‡½å¼ï¼šå–®ä¸€ PDF è§£æ ---
def extract_pdf_data(file_obj, filename):
    data = {key: "N.D." for key in KEYWORDS_MAP.keys()}
    data['PFAS'] = ""
    data['DATE'] = None
    data['Filename'] = filename
    
    full_text = ""
    header_text = "" # ç”¨æ–¼æœå°‹ Test Requested å’Œæ—¥æœŸ

    try:
        with pdfplumber.open(file_obj) as pdf:
            # 1. è®€å–é é¢å…§å®¹
            for i, page in enumerate(pdf.pages):
                text = page.extract_text()
                if text:
                    full_text += text + "\n"
                    if i < 3: # é€šå¸¸é—œéµè³‡è¨Šåœ¨å‰ 3 é 
                        header_text += text + "\n"

            # 2. æå–æ—¥æœŸ (Date)
            # Regex é‡å° SGS å’Œ CTI æ ¼å¼é€²è¡ŒåŒ¹é…
            date_patterns = [
                r"Date:\s*([A-Z][a-z]{2}\s\d{1,2},\s\d{4})",  # SGS: Date: Feb 27, 2025
                r"Date:\s*(\d{4}\.\d{2}\.\d{2})",             # CTI: Date: 2025.06.16
                r"Date:\s*(\d{2}-[A-Z][a-z]{2}-\d{4})",       # CTI: Date: 27-Feb-2025
                r"æ—¥æœŸï¼š\s*(\d{4}\s*å¹´\s*\d{1,2}\s*æœˆ\s*\d{1,2}\s*æ—¥)"
            ]
            
            for pat in date_patterns:
                match = re.search(pat, header_text)
                if match:
                    dt = parse_date(match.group(1))
                    if dt:
                        data['DATE'] = dt
                        break

            # 3. æå–åŒ–å­¸ç‰©è³ªæ•¸å€¼
            # é€è¡Œæƒæï¼Œå°‹æ‰¾ "é—œéµå­— ... æ•¸å€¼" çš„æ¨¡å¼
            lines = full_text.split('\n')
            for line in lines:
                for key, keywords in KEYWORDS_MAP.items():
                    # å„ªåŒ–ï¼šF, Cl, Br å®¹æ˜“èª¤åˆ¤ï¼Œéœ€å¢åŠ é‚Šç•Œæª¢æŸ¥æˆ–ç¢ºä¿ä¸æ˜¯å–®å­—çš„ä¸€éƒ¨åˆ†
                    for kw in keywords:
                        if kw in line:
                            # å°‹æ‰¾è¡Œå°¾çš„æ•¸å€¼æˆ– N.D.
                            # é‚è¼¯ï¼šæŠ“å– "N.D." æˆ– "ND" æˆ– æ•¸å­— (æ’é™¤å¹´ä»½ 20xx)
                            # Regex èªªæ˜: 
                            # (N\.D\.|ND) -> æŠ“å–æœªæª¢å‡º
                            # (\d+(?:\.\d+)?) -> æŠ“å–æ•¸å­—
                            # æ’é™¤æ‰å‰é¢æœ‰ "ISO" æˆ– "IEC" çš„æ•¸å­— (æ–¹æ³•ç·¨è™Ÿ)
                            if "ISO" in line or "IEC" in line or "EPA" in line:
                                continue

                            # å°‹æ‰¾æ¸¬è©¦çµæœ
                            # é€™è£¡å‡è¨­çµæœé€šå¸¸åœ¨è¡Œçš„å¾Œæ®µ
                            result_match = re.search(r"(N\.D\.|ND|Negative|<[\d\.]+|\d+(?:\.\d+)?)", line.split(kw)[-1])
                            
                            if result_match:
                                val_str = result_match.group(1)
                                
                                # åˆ¤æ–·æ˜¯å¦ç‚ºæœ‰æ•ˆæ•¸å€¼
                                if re.match(r"^\d", val_str): # æ˜¯æ•¸å­—
                                    try:
                                        val_num = float(val_str)
                                        # éæ¿¾å¹´ä»½ (ä¾‹å¦‚ 2025) æˆ–æ³•è¦ç·¨è™Ÿ
                                        if val_num > 1980 and val_num < 2100 and key not in ['BR', 'CL', 'F']:
                                            continue
                                        
                                        # æ¯”è¼ƒå¤§å°ï¼Œä¿ç•™æœ€å¤§å€¼ (è™•ç†åŒä»½å ±å‘Šå¤šå€‹æ¸¬è©¦é»çš„æƒ…æ³)
                                        current_val = data[key]
                                        if current_val == "N.D." or current_val == "Negative":
                                            data[key] = val_num
                                        elif isinstance(current_val, (int, float)):
                                            if val_num > current_val:
                                                data[key] = val_num
                                    except:
                                        pass
                                elif "Negative" in val_str:
                                     # Negative è¦–ç‚º N.D.ï¼Œé™¤éå·²æœ‰æ•¸å­—
                                     pass 

            # 4. åˆ¤æ–· PFAS
            # é‚è¼¯ï¼šæª¢æŸ¥ "Test Requested" æˆ– "æ£€æµ‹è¦æ±‚" å€å¡Šæ˜¯å¦åŒ…å« "PFAS" å­—ä¸²
            # å…ˆæ‰¾åˆ° Header å€å¡Š
            req_match = re.search(r"(Test Requested|æ£€æµ‹è¦æ±‚|Test Conducted)([\s\S]{1,500})", header_text, re.IGNORECASE)
            if req_match:
                content = req_match.group(0)
                if "PFAS" in content:
                    data['PFAS'] = "REPORT"
            # è‹¥ç„¡ PFAS å­—ä¸²ï¼Œä¿æŒç©ºç™½

    except Exception as e:
        st.error(f"è§£ææª”æ¡ˆ {filename} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None
        
    return data

# --- æ ¸å¿ƒå‡½å¼ï¼šæ•¸æ“šåŠ ç¸½èˆ‡å½™æ•´ ---
def aggregate_reports(extracted_list):
    if not extracted_list:
        return None

    # åˆå§‹åŒ–çµæœ Row
    final_data = {key: "N.D." for key in KEYWORDS_MAP.keys()}
    final_data['PFAS'] = ""
    final_data['DATE'] = None
    final_data['FILE NAME'] = ""

    max_pb = -1.0 # ç”¨æ–¼è¿½è¹¤æœ€å¤§é‰›å«é‡
    latest_date = datetime.min

    for item in extracted_list:
        fname = item['Filename']
        
        # 1. æ—¥æœŸå–æœ€æ–°
        if item['DATE'] and item['DATE'] > latest_date:
            latest_date = item['DATE']
            
        # 2. PFAS åˆ¤æ–· (è¯é›†ï¼šåªè¦æœ‰ä¸€ä»½æ˜¯ REPORT å°±é¡¯ç¤º)
        if item['PFAS'] == "REPORT":
            final_data['PFAS'] = "REPORT"

        # 3. æ•¸å€¼å–æœ€å¤§ (æ•¸å­— > N.D.)
        # ç‰¹åˆ¥è™•ç† Pb ä»¥æ±ºå®š FILE NAME
        pb_val = item['Pb']
        current_pb_num = 0.0
        
        if isinstance(pb_val, (int, float)):
            current_pb_num = pb_val
        
        # æ›´æ–° Pb æœ€å¤§å€¼èˆ‡å°æ‡‰æª”å
        if current_pb_num > max_pb:
            max_pb = current_pb_num
            final_data['FILE NAME'] = fname
        elif current_pb_num == max_pb and final_data['FILE NAME'] == "":
            final_data['FILE NAME'] = fname # è™•ç†éƒ½æ˜¯ N.D. çš„æƒ…æ³ï¼Œå–ç¬¬ä¸€ä»½

        # è™•ç†æ‰€æœ‰åŒ–å­¸ç‰©è³ª
        for key in KEYWORDS_MAP.keys():
            val = item[key]
            # å¦‚æœæ–°å€¼æ˜¯æ•¸å­—
            if isinstance(val, (int, float)):
                # å¦‚æœèˆŠå€¼ä¹Ÿæ˜¯æ•¸å­—ï¼Œå–å¤§è€…
                if isinstance(final_data[key], (int, float)):
                    if val > final_data[key]:
                        final_data[key] = val
                # å¦‚æœèˆŠå€¼æ˜¯ N.D.ï¼Œç›´æ¥è¦†è“‹
                else:
                    final_data[key] = val
            # å¦‚æœæ–°å€¼æ˜¯ N.D.ï¼Œä¸å‹•ä½œ (ä¿ç•™å¯èƒ½çš„èˆŠæ•¸å­—)

    # 4. æ ¼å¼åŒ–æ—¥æœŸ
    if latest_date != datetime.min:
        final_data['DATE'] = latest_date.strftime("%Y/%m/%d")
    else:
        final_data['DATE'] = ""

    return final_data

# --- Streamlit UI ä¸»ç¨‹å¼ ---
uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ PDF æ¸¬è©¦å ±å‘Š (SGS/CTI)", type="pdf", accept_multiple_files=True)

if uploaded_files:
    if st.button("é–‹å§‹åˆ†æèˆ‡å½™æ•´"):
        all_data = []
        progress_bar = st.progress(0)
        
        for idx, file in enumerate(uploaded_files):
            # è§£æ
            result = extract_pdf_data(file, file.name)
            if result:
                all_data.append(result)
            progress_bar.progress((idx + 1) / len(uploaded_files))
            
        if all_data:
            # åŠ ç¸½
            summary_row = aggregate_reports(all_data)
            
            # è½‰ç‚º DataFrame
            df = pd.DataFrame([summary_row])
            
            # èª¿æ•´æ¬„ä½é †åº
            cols = ['FILE NAME', 'Pb', 'Cd', 'Hg', 'Cr6+', 'PBB', 'PBDE', 
                    'DEHP', 'DBP', 'BBP', 'DIBP', 
                    'F', 'CL', 'BR', 'PFOS', 'PFAS', 'DATE']
            df = df[cols]
            
            st.success("å½™æ•´å®Œæˆï¼")
            st.dataframe(df)
            
            # ä¸‹è¼‰ CSV
            csv = df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰ Excel/CSV å ±è¡¨",
                data=csv,
                file_name="Summary_Report.csv",
                mime="text/csv"
            )
        else:
            st.warning("ç„¡æ³•æå–æ•¸æ“šï¼Œè«‹ç¢ºèª PDF æ ¼å¼ã€‚")
