import streamlit as st
import pdfplumber
import pandas as pd
import re
from datetime import datetime

# --- è¨­å®šé é¢ ---
st.set_page_config(page_title="é€šç”¨æª¢æ¸¬å ±å‘Šæ“·å–å·¥å…· (V16 æ——è‰¦ç‰ˆ)", layout="wide")
st.title("ğŸ§ª é€šç”¨å‹ç¬¬ä¸‰æ–¹æª¢æ¸¬å ±å‘Šæ•¸æ“šæ“·å–å·¥å…· (V16 æ——è‰¦ç‰ˆ)")
st.markdown("""
**V16 ç‰ˆæœ¬æ ¸å¿ƒç‰¹å¾µï¼šä¸Šä¸‹æ–‡æ„ŸçŸ¥èˆ‡é›™è»Œæå–**
1.  **ğŸ” æ¨£å“ç·¨è™Ÿé è®€**ï¼šè‡ªå‹•åµæ¸¬ "A1", "A2", "001" ç­‰ç·¨è™Ÿï¼Œç ´è§£æœªçŸ¥è¡¨é ­ã€‚
2.  **ğŸ“„ PBBs/PBDEs ç´”æ–‡å­—æƒæ (V7)**ï¼šç„¡è¦–è¡¨æ ¼çµæ§‹ï¼Œç›´æ¥å¾æ–‡å­—æµæŠ“å–æ•¸å€¼ï¼Œè§£æ±ºç©ºå€¼å•é¡Œã€‚
3.  **ğŸ“… æ™ºèƒ½æ—¥æœŸ V2**ï¼šä¸­è‹±é›™èªæ”¯æ´ + é»‘åå–®éæ¿¾ + æœ€æ™šæ—¥æœŸæ³•å‰‡ã€‚
4.  **ğŸ›¡ï¸ ç¶œåˆé˜²ç¦¦**ï¼šCTI PVC æ’é™¤ã€SGS éš±å½¢è¡¨æ ¼å°ç­–ã€PFOS å–®é …é–å®šã€‚
""")

# --- 1. é—œéµå­—å®šç¾© (ä¸­è‹±é›™èªåº«) ---
TARGET_FIELDS = {
    "Lead": {"name": "Pb", "keywords": [r"^Lead\b", r"^Pb\b", r"é“…", r"Lead \(Pb\)", r"Pb"]},
    "Cadmium": {"name": "Cd", "keywords": [r"^Cadmium\b", r"^Cd\b", r"é•‰", r"Cadmium \(Cd\)", r"Cd"]},
    "Mercury": {"name": "Hg", "keywords": [r"^Mercury\b", r"^Hg\b", r"æ±", r"Mercury \(Hg\)", r"Hg"]},
    "Hexavalent Chromium": {"name": "Cr(VI)", "keywords": [r"Hexavalent Chromium", r"Cr\(VI\)", r"Cr6\+", r"å…­ä»·é“¬", r"å…­åƒ¹é‰»"]},
    "DEHP": {"name": "DEHP", "keywords": [r"Bis\(2-ethylhexyl\) phthalate", r"DEHP", r"é‚»è‹¯äºŒç”²é…¸äºŒ\(2-ä¹™åŸºå·±åŸº\)é…¯"]},
    "BBP": {"name": "BBP", "keywords": [r"Butyl benzyl phthalate", r"BBP", r"é‚»è‹¯äºŒç”²é…¸ä¸åŸºè‹„åŸºé…¯", r"é‚»è‹¯äºŒç”²é…¸ä¸è‹„é…¯"]},
    "DBP": {"name": "DBP", "keywords": [r"Dibutyl phthalate", r"DBP", r"é‚»è‹¯äºŒç”²é…¸äºŒä¸é…¯"]},
    "DIBP": {"name": "DIBP", "keywords": [r"Diisobutyl phthalate", r"DIBP", r"é‚»è‹¯äºŒç”²é…¸äºŒå¼‚ä¸é…¯"]},
    "Fluorine": {"name": "F", "keywords": [r"Fluorine", r"æ°Ÿ", r"Fluorine \(F\)"]},
    "Chlorine": {"name": "Cl", "keywords": [r"Chlorine", r"æ°¯", r"Chlorine \(Cl\)"]},
    "Bromine": {"name": "Br", "keywords": [r"Bromine", r"æº´", r"Bromine \(Br\)"]},
    "Iodine": {"name": "I", "keywords": [r"Iodine", r"ç¢˜", r"Iodine \(I\)"]},
    "PFOS": {"name": "PFOS", "keywords": [r"Perfluorooctane Sulfonates", r"PFOS", r"å…¨æ°Ÿè¾›çƒ·ç£ºé…¸"]},
}

# PBBs/PBDEs é—œéµå­— (V7 é‚è¼¯ç”¨)
PBBS_KEYWORDS = [r"Monobromobiphenyl", r"Dibromobiphenyl", r"Tribromobiphenyl", r"Tetrabromobiphenyl", 
                 r"Pentabromobiphenyl", r"Hexabromobiphenyl", r"Heptabromobiphenyl", r"Octabromobiphenyl", 
                 r"Nonabromobiphenyl", r"Decabromobiphenyl", 
                 r"ä¸€æº´è”è‹¯", r"äºŒæº´è”è‹¯", r"ä¸‰æº´è”è‹¯", r"å››æº´è”è‹¯", r"äº”æº´è”è‹¯", 
                 r"å…­æº´è”è‹¯", r"ä¸ƒæº´è”è‹¯", r"å…«æº´è”è‹¯", r"ä¹æº´è”è‹¯", r"åæº´è”è‹¯"]

PBDES_KEYWORDS = [r"Monobromodiphenyl ether", r"Dibromodiphenyl ether", r"Tribromodiphenyl ether", 
                  r"Tetrabromodiphenyl ether", r"Pentabromodiphenyl ether", r"Hexabromodiphenyl ether", 
                  r"Heptabromodiphenyl ether", r"Octabromodiphenyl ether", r"Nonabromodiphenyl ether", 
                  r"Decabromodiphenyl ether", 
                  r"ä¸€æº´äºŒè‹¯é†š", r"äºŒæº´äºŒè‹¯é†š", r"ä¸‰æº´äºŒè‹¯é†š", r"å››æº´äºŒè‹¯é†š", r"äº”æº´äºŒè‹¯é†š", 
                  r"å…­æº´äºŒè‹¯é†š", r"ä¸ƒæº´äºŒè‹¯é†š", r"å…«æº´äºŒè‹¯é†š", r"ä¹æº´äºŒè‹¯é†š", r"åæº´äºŒè‹¯é†š"]

# --- 2. è¼”åŠ©å‡½å¼ ---

def clean_text(text):
    if not text: return ""
    return re.sub(r'\s+', ' ', str(text)).strip()

def extract_value_logic(val_str, strict_numeric=False):
    """
    é€šç”¨æ•¸å€¼æå–ï¼š
    strict_numeric=True æ™‚ (ç”¨æ–¼ Cl, PFOS)ï¼Œæ‹’çµ• Negative/Positiveï¼Œåªæ¥å—æ•¸å­—ã€‚
    """
    if not val_str: return None, ""
    
    val_upper = str(val_str).upper().replace(" ", "")
    
    # 1. CAS No. é˜²ç«ç‰† (å¸¸è¦‹çš„èª¤åˆ¤ä¾†æº)
    if re.search(r"\b\d{2,7}-\d{2}-\d\b", val_str): return None, ""

    # 2. æ–‡å­—ç‹€æ…‹è™•ç†
    if "N.D." in val_upper or "ND" in val_upper or "<" in val_upper: return 0, "N.D."
    
    if "NEGATIVE" in val_upper or "é˜´æ€§" in val_upper: 
        if strict_numeric: return None, "" # å°æ–¼å®šé‡é …ç›®ï¼ŒNegative æ˜¯ç„¡æ•ˆå€¼ (å¯èƒ½æ˜¯ PVC)
        return 0.0001, "NEGATIVE"
        
    if "POSITIVE" in val_upper or "é˜³æ€§" in val_upper: 
        if strict_numeric: return None, ""
        return 999999, "POSITIVE"
    
    # 3. ç´”æ•¸å­—æå–
    # ç§»é™¤å–®ä½å¹²æ“¾
    val_clean = re.sub(r"(mg/kg|ppm|%|Âµg/cmÂ²|ug/cm2)", "", val_str, flags=re.IGNORECASE)
    match = re.search(r"(\d+(\.\d+)?)", val_clean)
    
    if match:
        num = float(match.group(1))
        # å¹´ä»½éæ¿¾ (2010-2030 è¦–ç‚ºå¹´ä»½è€Œéçµæœ)
        if 2010 <= num <= 2030: return None, ""
        return num, match.group(1)
    
    return None, ""

# --- 3. æ ¸å¿ƒåŠŸèƒ½æ¨¡çµ„ ---

def find_sample_ids(full_text_pages_1_2):
    """
    [V16 æ–°åŠŸèƒ½] é è®€æ¨£å“ç·¨è™Ÿ
    æƒæå‰å…©é ï¼Œæ‰¾å‡º Sample No. å¾Œé¢çš„ä»£è™Ÿ (å¦‚ A1, A2, 001)
    """
    ids = []
    # å¸¸è¦‹æ¨£å“ç·¨è™Ÿæ¨™ç±¤
    patterns = [
        r"(?:Sample|Specimen)\s*(?:No\.|ID|Ref\.?)\s*[:ï¼š]?\s*([A-Za-z0-9\-]+)",
        r"(?:SN\s*ID)\s*[:ï¼š]?\s*([A-Za-z0-9\-]+)",
        r"(?:æ ·å“|æ¨£å“)\s*(?:ç¼–å·|åºå·|ID)\s*[:ï¼š]?\s*([A-Za-z0-9\-]+)"
    ]
    
    for line in full_text_pages_1_2.split('\n'):
        for pat in patterns:
            m = re.search(pat, line, re.IGNORECASE)
            if m:
                found_id = m.group(1).strip()
                if len(found_id) < 10: # é¿å…æŠ“åˆ°å¤ªé•·çš„é›œè¨Š
                    ids.append(found_id.upper())
    
    return list(set(ids)) # å»é‡

def find_issue_date(full_text_page_1):
    """
    [V16 æ—¥æœŸé–å®š] é»‘åå–® + æœ€æ™šæ—¥æœŸæ³•å‰‡
    """
    lines = full_text_page_1.split('\n')
    candidates = []
    
    # é»‘åå–®ï¼šå‡ºç¾é€™äº›å­—çš„è¡Œï¼Œæ—¥æœŸé€šå¸¸æ˜¯éç¨‹è€Œéçµæœ
    blacklist = ["RECEIVED", "PERIOD", "STARTED", "SUBMITTED", "COMPLETED", "TESTING", "æ”¶ä»¶", "æ¥æ”¶", "å‘¨æœŸ", "æœŸé—´"]
    
    for line in lines:
        upper_line = line.upper()
        if any(bad in upper_line for bad in blacklist):
            continue
            
        # æŠ“å–å„ç¨®æ—¥æœŸæ ¼å¼
        # 1. 2025/06/16, 2025.06.16, 2025-06-16, 2025å¹´06æœˆ16æ—¥
        m1 = re.search(r"(\d{4})[-/. å¹´](\d{1,2})[-/. æœˆ](\d{1,2})", line)
        if m1:
            try:
                dt = datetime(int(m1.group(1)), int(m1.group(2)), int(m1.group(3)))
                if 2015 <= dt.year <= 2030: candidates.append(dt)
            except: pass
            
        # 2. 16-Jun-2025, 16 Jan 2025
        m2 = re.search(r"(\d{1,2})[-/\s]([A-Za-z]{3})[-/\s,.]+(\d{4})", line)
        if m2:
            try:
                dt = datetime.strptime(f"{m2.group(1)}-{m2.group(2)}-{m2.group(3)}", "%d-%b-%Y")
                if 2015 <= dt.year <= 2030: candidates.append(dt)
            except: pass

        # 3. Jun 16, 2025
        m3 = re.search(r"([A-Za-z]{3})\.?\s+(\d{1,2})[,\s]+(\d{4})", line)
        if m3:
            try:
                dt = datetime.strptime(f"{m3.group(2)}-{m3.group(1)}-{m3.group(3)}", "%d-%b-%Y")
                if 2015 <= dt.year <= 2030: candidates.append(dt)
            except: pass

    if candidates:
        # ç™¼è¡Œæ—¥æœŸæ°¸é æ˜¯æ™‚é–“è»¸ä¸Šæœ€æ™šçš„
        latest = max(candidates)
        return latest.strftime("%Y/%m/%d")
    
    return ""

def check_pfas_in_section(full_text):
    """PFAS å€å¡Šé™å®šï¼šåªåœ¨ Test Requested å€åŸŸæœå°‹"""
    start_keywords = ["TEST REQUESTED", "æµ‹è¯•éœ€æ±‚", "æ£€æµ‹è¦æ±‚", "TEST REQUEST"]
    end_keywords = ["TEST METHOD", "TEST RESULTS", "CONCLUSION", "æµ‹è¯•ç»“æœ", "ç»“è®º", "æ£€æµ‹æ–¹æ³•"]
    
    upper = full_text.upper()
    start_idx = -1
    for kw in start_keywords:
        idx = upper.find(kw)
        if idx != -1:
            start_idx = idx
            break
            
    if start_idx == -1: return ""
    
    end_idx = len(upper)
    for kw in end_keywords:
        idx = upper.find(kw, start_idx)
        if idx != -1:
            end_idx = idx
            break
            
    target_text = upper[start_idx:end_idx]
    if "PFAS" in target_text or "PER- AND POLYFLUOROALKYL" in target_text:
        return "REPORT"
    return ""

# --- 4. æ•¸æ“šæå–å¼•æ“ ---

def process_file(uploaded_file):
    filename = uploaded_file.name
    results = {k: {"val": None, "display": ""} for k in TARGET_FIELDS.keys()}
    results["PBBs"] = {"val": None, "display": "", "sum_val": 0}
    results["PBDEs"] = {"val": None, "display": "", "sum_val": 0}
    results["PFAS"] = ""
    results["Date"] = ""
    
    full_text_content = ""
    first_page_text = ""
    
    with pdfplumber.open(uploaded_file) as pdf:
        # --- Phase 1: é æƒæ (Pre-scan) ---
        for i, page in enumerate(pdf.pages):
            text = page.extract_text()
            if text:
                full_text_content += text + "\n"
                if i == 0: first_page_text = text
                if i < 2: # åªæƒå‰å…©é æ‰¾ Sample ID
                    pass # å¯¦éš›é‚è¼¯åœ¨ä¸‹é¢
        
        # 1. æŠ“æ—¥æœŸ
        results["Date"] = find_issue_date(first_page_text)
        
        # 2. æŠ“ Sample IDs (A1, A2, 001...)
        sample_ids = find_sample_ids(full_text_content[:3000]) # é™åˆ¶é•·åº¦é¿å…è·‘å¤ªä¹…
        
        # 3. æŠ“ PFAS ç‹€æ…‹
        results["PFAS"] = check_pfas_in_section(full_text_content)

        # --- Phase 2: é›™è»Œæ•¸æ“šæå– ---
        
        # è»Œé“ A: [ç´”æ–‡å­—æµ] å°ˆæŠ“ PBBs / PBDEs (V7 é‚è¼¯)
        # å› ç‚º SGS çš„æœ‰æ©Ÿç‰©è¡¨æ ¼å¸¸éš±å½¢ï¼Œç”¨æ–‡å­—æŠ“æœ€ç©©
        text_lines = full_text_content.split('\n')
        for line in text_lines:
            line_upper = line.upper()
            
            # å®šç¾©åŠ ç¸½è™•ç†å‡½å¼
            def process_text_sum(keywords, cat_key):
                if any(k.upper() in line_upper for k in keywords):
                    # åœ¨é€™ä¸€è¡Œæ–‡å­—ä¸­æ‰¾æ‰€æœ‰æ•¸å­—
                    # æ’é™¤å¸¸è¦‹å¹²æ“¾: 1000(Limit), 5/10/25(MDL), CAS No.
                    potential_vals = []
                    # åˆ†å‰²å­—ä¸²ä¾†åˆ†æ
                    parts = line.split()
                    for part in parts:
                        v, d = extract_value_logic(part)
                        if v is not None:
                            # æ™ºæ…§éæ¿¾: è‹¥æ˜¯ MDL/Limit å¸¸è¦‹å€¼ä¸”ä¸æ˜¯ N.D.ï¼Œè·³é
                            if v in [5, 10, 25, 50, 100, 1000] and d != "N.D.":
                                continue
                            potential_vals.append(v)
                    
                    if potential_vals:
                        val = potential_vals[-1] # å–æœ€å¾Œä¸€å€‹æœ‰æ•ˆå€¼
                        if val > 0:
                            results[cat_key]["sum_val"] += val
                            results[cat_key]["val"] = 1

            process_text_sum(PBBS_KEYWORDS, "PBBs")
            process_text_sum(PBDES_KEYWORDS, "PBDEs")

        # è»Œé“ B: [è¡¨æ ¼å®šä½] å°ˆæŠ“ Pb, Cd, Cl, PFOS (V15 é‚è¼¯)
        for page in pdf.pages:
            tables = page.extract_tables()
            if not tables: continue
            
            for table in tables:
                if not table or len(table) < 2: continue
                
                # å°‹æ‰¾è¡¨é ­ (Header)
                header_row_idx = -1
                result_col_idx = -1
                
                for r_idx, row in enumerate(table[:6]):
                    row_str = " ".join([str(c).upper() for c in row if c])
                    
                    # åˆ¤æ–·æ˜¯å¦ç‚ºæª¢æ¸¬æ•¸æ“šè¡¨
                    if ("ITEM" in row_str or "é¡¹ç›®" in row_str or "TEST" in row_str):
                        header_row_idx = r_idx
                        
                        # å˜—è©¦å®šä½ Result æ¬„ä½
                        # å„ªå…ˆç´š 1: æ˜ç¢ºé—œéµå­—
                        for c_idx, cell in enumerate(row):
                            txt = clean_text(str(cell)).upper()
                            if "RESULT" in txt or "ç»“æœ" in txt or "DATA" in txt:
                                result_col_idx = c_idx
                                break
                        
                        # å„ªå…ˆç´š 2: æ¨£å“ç·¨è™ŸåŒ¹é… (A1, A2...)
                        if result_col_idx == -1:
                            for c_idx, cell in enumerate(row):
                                txt = clean_text(str(cell)).upper()
                                if txt in sample_ids: # å‘½ä¸­ Sample ID!
                                    result_col_idx = c_idx
                                    break
                                    
                        # å„ªå…ˆç´š 3: æ¶ˆå»æ³• (æ’é™¤ Unit, MDL, Limit)
                        if result_col_idx == -1:
                            scores = {}
                            for c_idx, cell in enumerate(row):
                                txt = clean_text(str(cell)).upper()
                                if any(x in txt for x in ["UNIT", "MDL", "LIMIT", "LOQ", "å•ä½", "é™å€¼", "æ–¹æ³•", "CAS"]):
                                    scores[c_idx] = -100
                                else:
                                    scores[c_idx] = 50 # å¯èƒ½æ˜¯çµæœ
                            
                            if scores:
                                best = max(scores, key=scores.get)
                                if scores[best] > 0:
                                    result_col_idx = best
                        
                        break # æ‰¾åˆ°è¡¨é ­å°±åœæ­¢
                
                if header_row_idx == -1: continue # é€™å¼µè¡¨ä¸æ˜¯æ•¸æ“šè¡¨
                
                # éæ­·æ•¸æ“šè¡Œ
                for r_idx in range(header_row_idx + 1, len(table)):
                    row = table[r_idx]
                    if not row: continue
                    
                    # çµ„åˆé …ç›®åç¨± (é˜²è·¨æ¬„)
                    item_name = clean_text(row[0])
                    if len(row) > 1: item_name += " " + clean_text(row[1])
                    item_upper = item_name.upper()
                    
                    # åªè™•ç†é PBBs/PBDEs çš„é …ç›® (æœ‰æ©Ÿç‰©å·²åœ¨è»Œé“ A è™•ç†)
                    for field, config in TARGET_FIELDS.items():
                        for kw in config["keywords"]:
                            if re.search(kw, item_upper, re.IGNORECASE):
                                
                                # ç‰¹æ®Šé˜²è­·: Cl (æ°¯) æ’é™¤ PVC
                                if field == "Chlorine" and ("POLYVINYL" in item_upper or "PVC" in item_upper):
                                    continue
                                
                                # æ±ºå®šå¾å“ªè£¡æŠ“å€¼
                                val_text = ""
                                if result_col_idx != -1 and len(row) > result_col_idx:
                                    val_text = clean_text(row[result_col_idx])
                                else:
                                    # å¦‚æœå®šä½å¤±æ•—ï¼Œå˜—è©¦æŠ“æœ€å¾Œä¸€æ¬„
                                    val_text = clean_text(row[-1])
                                
                                # æ•¸å€¼è§£æ
                                is_strict = (field in ["Chlorine", "Bromine", "PFOS"]) # é€™äº›ä¸æ¥å— Negative
                                v_num, v_disp = extract_value_logic(val_text, strict_numeric=is_strict)
                                
                                if v_num is not None:
                                    # æ›´æ–°çµæœ (å–æœ€å¤§å€¼)
                                    curr = results[field]["val"]
                                    if curr is None or v_num > curr:
                                        results[field]["val"] = v_num
                                        results[field]["display"] = v_disp
                                    elif v_num == 0 and (curr is None or curr == 0):
                                        if v_disp == "NEGATIVE": results[field]["display"] = "NEGATIVE"
                                        elif not results[field]["display"]: results[field]["display"] = "N.D."
                                        results[field]["val"] = 0

    # --- æœ€çµ‚æ•´ç† ---
    if results["PBBs"]["sum_val"] > 0:
        results["PBBs"]["display"] = str(round(results["PBBs"]["sum_val"], 2))
    elif results["PBBs"]["val"] is None:
        results["PBBs"]["display"] = "" # æ²’æŠ“åˆ°é¡¯ç¤ºç©ºç™½
    else:
        results["PBBs"]["display"] = "N.D." # æŠ“åˆ°ä½†éƒ½æ˜¯ 0

    if results["PBDEs"]["sum_val"] > 0:
        results["PBDEs"]["display"] = str(round(results["PBDEs"]["sum_val"], 2))
    elif results["PBDEs"]["val"] is None:
        results["PBDEs"]["display"] = ""
    else:
        results["PBDEs"]["display"] = "N.D."

    final_output = {
        "File Name": filename,
        "Pb": results["Lead"]["display"],
        "Cd": results["Cadmium"]["display"],
        "Hg": results["Mercury"]["display"],
        "Cr(VI)": results["Hexavalent Chromium"]["display"],
        "PBBs": results["PBBs"]["display"],
        "PBDEs": results["PBDEs"]["display"],
        "DEHP": results["DEHP"]["display"],
        "BBP": results["BBP"]["display"],
        "DBP": results["DBP"]["display"],
        "DIBP": results["DIBP"]["display"],
        "F": results["Fluorine"]["display"],
        "Cl": results["Chlorine"]["display"],
        "Br": results["Bromine"]["display"],
        "I": results["Iodine"]["display"],
        "PFOS": results["PFOS"]["display"],
        "PFAS": results["PFAS"],
        "Date": results["Date"],
        "_sort_pb": results["Lead"]["val"],
        "_sort_max": max([v["val"] for k, v in results.items() if isinstance(v, dict) and v["val"] is not None])
    }
    
    return final_output, None

# --- ä¸»ä»‹é¢ ---
uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ PDF æª¢æ¸¬å ±å‘Š (æ”¯æ´ SGS, CTI, Intertek ç­‰)", type="pdf", accept_multiple_files=True)

if uploaded_files:
    all_data = []
    scanned_files = []

    with st.spinner('æ­£åœ¨é€²è¡Œ V16 æ——è‰¦å¼•æ“åˆ†æ (é›™è»Œæå– + ä¸Šä¸‹æ–‡æ„ŸçŸ¥)...'):
        for pdf_file in uploaded_files:
            data, scanned_name = process_file(pdf_file)
            if scanned_name:
                scanned_files.append(scanned_name)
            else:
                all_data.append(data)

    if all_data:
        df = pd.DataFrame(all_data)
        # æ’åº
        if "_sort_pb" in df.columns:
            df = df.sort_values(by=["_sort_pb", "_sort_max"], ascending=[False, False])
            display_df = df.drop(columns=["_sort_pb", "_sort_max"])
        else:
            display_df = df
        
        st.success(f"âœ… æˆåŠŸæ“·å– {len(all_data)} ä»½å ±å‘Šï¼(V16 æ ¸å¿ƒ)")
        st.dataframe(display_df, use_container_width=True)
        
        csv = display_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel/CSV å ±è¡¨",
            data=csv,
            file_name="rohs_report_v16_final.csv",
            mime="text/csv",
        )

    if scanned_files:
        st.error("âš ï¸ ä»¥ä¸‹æª”æ¡ˆç‚ºæƒæåœ–ç‰‡ (ç„¡æ³•æ“·å–æ–‡å­—)ï¼š")
        for f in scanned_files:
            st.write(f"- {f}")
else:
    st.info("è«‹ä¸Šå‚³ PDF æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚")
