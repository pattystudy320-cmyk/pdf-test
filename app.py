import streamlit as st
import pdfplumber
import pandas as pd
import re
from dateutil import parser
import io

st.set_page_config(page_title="SGS Report Parser", layout="wide")
st.title("ğŸ“„ SGS Report æª¢æ¸¬çµæœå½™ç¸½å·¥å…·")

# =========================
# æ¬„ä½å®šç¾©ï¼ˆé †åºå›ºå®šï¼‰
# =========================
ITEM_RULES = {
    "Pb": r"Lead\s*\(Pb\)",
    "Cd": r"Cadmium\s*\(Cd\)",
    "Hg": r"Mercury\s*\(Hg\)",
    "CrVI": r"Hexavalent Chromium",
    "PBBs": r"Sum of PBBs",
    "PBDEs": r"Sum of PBDEs",
    "DEHP": r"DEHP",
    "BBP": r"BBP",
    "DBP": r"DBP",
    "DIBP": r"DIBP",
    "F": r"Fluorine",
    "CL": r"Chlorine",
    "BR": r"Bromine",
    "I": r"Iodine",
    "PFOS": r"PFOS"
}

FINAL_COLUMNS = [
    "Pb","Cd","Hg","CrVI","PBBs","PBDEs",
    "DEHP","BBP","DBP","DIBP",
    "F","CL","BR","I",
    "PFOS","PFAS","DATE"
]

# =========================
# å·¥å…·å‡½å¼
# =========================
def extract_text_and_pages(pdf_file):
    full_text = ""
    pages_text = []
    with pdfplumber.open(pdf_file) as pdf:
        for page in pdf.pages:
            text = page.extract_text() or ""
            pages_text.append(text)
            full_text += text + "\n"
    return full_text, pages_text


def extract_result(text, keyword):
    lines = text.splitlines()

    for i, line in enumerate(lines):
        if re.search(keyword, line, re.IGNORECASE):
            context = " ".join(lines[i:i+3])

            # æ’é™¤ IEC 62321 æ–¹æ³•ç·¨è™Ÿ
            context = re.sub(r"IEC\s*62321[-\d:]*", "", context, flags=re.IGNORECASE)

            # 1ï¸âƒ£ æ•¸å€¼ï¼ˆåªæŠ“çµæœï¼‰
            num = re.search(r"\b(\d+(\.\d+)?)\b", context)
            if num:
                return num.group(1)

            # 2ï¸âƒ£ NEGATIVE
            if re.search(r"NEGATIVE", context, re.IGNORECASE):
                return "NEGATIVE"

            # 3ï¸âƒ£ N.D.
            if re.search(r"N\.D\.", context, re.IGNORECASE):
                return "N.D."

    return ""


def extract_pfas(text):
    return "REPORT" if re.search(r"\bPFAS\b", text, re.IGNORECASE) else ""


def extract_date(first_page_text):
    match = re.search(
        r"(REPORTED DATE|TEST REPORT REPORTED DATE)\s*[:\-]?\s*([^\n]+)",
        first_page_text,
        re.IGNORECASE
    )
    return match.group(2).strip() if match else ""


def normalize_date(date_text):
    if not date_text:
        return ""
    try:
        dt = parser.parse(date_text, dayfirst=True)
        return dt.strftime("%Y/%m/%d")
    except:
        return ""


def merge_results(values):
    nums = []
    for v in values:
        if not v:
            continue
        if v not in ["N.D.", "NEGATIVE"]:
            try:
                nums.append(float(v))
            except:
                pass

    if nums:
        return str(max(nums))
    if "NEGATIVE" in values:
        return "NEGATIVE"
    if "N.D." in values:
        return "N.D."
    return ""


# =========================
# UI
# =========================
uploaded_files = st.file_uploader(
    "è«‹ä¸Šå‚³ SGS PDF Reportï¼ˆå¯ä¸€æ¬¡å¤šé¸ï¼‰",
    type="pdf",
    accept_multiple_files=True
)

# =========================
# ä¸»æµç¨‹
# =========================
if uploaded_files:
    rows = []

    for file in uploaded_files:
        full_text, pages_text = extract_text_and_pages(file)

        record = {}

        # å„æª¢æ¸¬é …ç›®
        for item, keyword in ITEM_RULES.items():
            record[item] = extract_result(full_text, keyword)

        # PFASï¼ˆæ˜¯å¦æœ‰æ¸¬ï¼‰
        record["PFAS"] = extract_pfas(full_text)

        # DATEï¼ˆåªçœ‹ç¬¬ä¸€é ï¼‰
        raw_date = extract_date(pages_text[0])
        record["DATE"] = normalize_date(raw_date)

        rows.append(record)

    df_all = pd.DataFrame(rows)

    # ===== åŒæ‰¹ PDF å½™ç¸½ï¼ˆæœ€åš´æ ¼çµæœï¼‰=====
    merged = {}
    for col in FINAL_COLUMNS:
        if col in ["DATE", "PFAS"]:
            continue
        merged[col] = merge_results(df_all[col].tolist())

    merged["PFAS"] = "REPORT" if "REPORT" in df_all["PFAS"].tolist() else ""
    merged["DATE"] = max(df_all["DATE"])

    df_final = pd.DataFrame([merged], columns=FINAL_COLUMNS)

    # ===== é¡¯ç¤ºçµæœ =====
    st.subheader("ğŸ“Š å½™ç¸½çµæœï¼ˆåŒæ‰¹ SGS Reportï¼‰")
    st.dataframe(df_final, use_container_width=True)

    # ===== Excel åŒ¯å‡º =====
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df_final.to_excel(writer, sheet_name="SGS_Result", index=False)

    st.download_button(
        "â¬‡ï¸ ä¸‹è¼‰å…¬å¸åˆ¶å¼ Excel",
        output.getvalue(),
        file_name="SGS_Test_Result.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
