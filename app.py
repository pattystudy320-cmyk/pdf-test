import streamlit as st
import pdfplumber
import pandas as pd
import re
from datetime import datetime

# --- è¨­å®šé é¢ ---
st.set_page_config(page_title="é€šç”¨æª¢æ¸¬å ±å‘Šæ“·å–å·¥å…· (V5 æœ€çµ‚ç‰ˆ)", layout="wide")
st.title("ğŸ§ª é€šç”¨å‹ç¬¬ä¸‰æ–¹æª¢æ¸¬å ±å‘Šæ•¸æ“šæ“·å–å·¥å…· (V5 æœ€çµ‚ç‰ˆ)")
st.markdown("""
**V5 ç‰ˆæœ¬æ›´æ–°é‡é»ï¼š**
1. **ğŸ›¡ï¸ CAS é˜²ç«ç‰†**ï¼šè‡ªå‹•è­˜åˆ¥ä¸¦éæ¿¾ CAS No.ï¼Œè§£æ±ºèª¤æŠ“åŒ–å­¸ç·¨è™Ÿ (å¦‚ 1763, 85) çš„å•é¡Œã€‚
2. **ğŸ“… æ—¥æœŸæ¨™æº–åŒ–**ï¼šé–å®šé¦–é å ±å‘Šæ—¥æœŸï¼Œçµ±ä¸€è½‰ç‚º `YYYY/MM/DD`ï¼Œæ’é™¤æ¸¬è©¦é€±æœŸå¹²æ“¾ã€‚
3. **ğŸ¯ å‚ç›´è¡¨é ­ä¿®æ­£**ï¼šå„ªåŒ–å°å·¢ç‹€è¡¨é ­ (Result ä¸‹æ–¹æœ‰ Sample ID) çš„å®šä½èƒ½åŠ›ã€‚
""")

# --- 1. å®šç¾©ç›®æ¨™æ¬„ä½èˆ‡é—œéµå­—è¯é›† ---
TARGET_FIELDS = {
    "Lead": {"name": "Pb", "keywords": [r"^Lead\b", r"^Pb\b", r"é“…", r"Lead \(Pb\)", r"Pb"]},
    "Cadmium": {"name": "Cd", "keywords": [r"^Cadmium\b", r"^Cd\b", r"é•‰", r"Cadmium \(Cd\)", r"Cd"]},
    "Mercury": {"name": "Hg", "keywords": [r"^Mercury\b", r"^Hg\b", r"æ±", r"Mercury \(Hg\)", r"Hg"]},
    "Hexavalent Chromium": {"name": "Cr(VI)", "keywords": [r"Hexavalent Chromium", r"Cr\(VI\)", r"Cr6\+", r"å…­ä»·é“¬", r"å…­åƒ¹é‰»"]},
    "DEHP": {"name": "DEHP", "keywords": [r"Bis\(2-ethylhexyl\) phthalate", r"DEHP", r"é‚»è‹¯äºŒç”²é…¸äºŒ\(2-ä¹™åŸºå·±åŸº\)é…¯"]},
    "BBP": {"name": "BBP", "keywords": [r"Butyl benzyl phthalate", r"BBP", r"é‚»è‹¯äºŒç”²é…¸ä¸åŸºè‹„åŸºé…¯"]},
    "DBP": {"name": "DBP", "keywords": [r"Dibutyl phthalate", r"DBP", r"é‚»è‹¯äºŒç”²é…¸äºŒä¸é…¯"]},
    "DIBP": {"name": "DIBP", "keywords": [r"Diisobutyl phthalate", r"DIBP", r"é‚»è‹¯äºŒç”²é…¸äºŒå¼‚ä¸é…¯"]},
    "Fluorine": {"name": "F", "keywords": [r"Fluorine", r"æ°Ÿ", r"Fluorine \(F\)"]},
    "Chlorine": {"name": "Cl", "keywords": [r"Chlorine", r"æ°¯", r"Chlorine \(Cl\)"]},
    "Bromine": {"name": "Br", "keywords": [r"Bromine", r"æº´", r"Bromine \(Br\)"]},
    "Iodine": {"name": "I", "keywords": [r"Iodine", r"ç¢˜", r"Iodine \(I\)"]},
    "PFOS": {"name": "PFOS", "keywords": [r"Perfluorooctane Sulfonates", r"PFOS", r"å…¨æ°Ÿè¾›ç£ºé…¸"]},
}

PBBS_KEYWORDS = [r"Monobromobiphenyl", r"Dibromobiphenyl", r"Tribromobiphenyl", r"Tetrabromobiphenyl", 
                 r"Pentabromobiphenyl", r"Hexabromobiphenyl", r"Heptabromobiphenyl", r"Octabromobiphenyl", 
                 r"Nonabromobiphenyl", r"Decabromobiphenyl", r"ä¸€æº´è”è‹¯", r"åæº´è”è‹¯", r"ä¸€æº´è¯è‹¯"]
PBDES_KEYWORDS = [r"Monobromodiphenyl ether", r"Dibromodiphenyl ether", r"Tribromodiphenyl ether", 
                  r"Tetrabromodiphenyl ether", r"Pentabromodiphenyl ether", r"Hexabromodiphenyl ether", 
                  r"Heptabromodiphenyl ether", r"Octabromodiphenyl ether", r"Nonabromodiphenyl ether", 
                  r"Decabromodiphenyl ether", r"ä¸€æº´äºŒè‹¯é†š", r"åæº´äºŒè‹¯é†š"]

# --- 2. è¼”åŠ©å‡½å¼å€ ---

def clean_text(text):
    if not text: return ""
    return re.sub(r'\s+', ' ', str(text)).strip()

def normalize_date(date_str):
    """å°‡å„ç¨®æ—¥æœŸæ ¼å¼çµ±ä¸€è½‰ç‚º YYYY/MM/DD"""
    if not date_str: return ""
    
    # ç§»é™¤å¤šé¤˜é›œè¨Š
    clean_date = re.sub(r"Date:|Issue Date:|Report Date:|æ—¥æœŸ[:ï¼š]?", "", date_str, flags=re.IGNORECASE).strip()
    
    try:
        # å˜—è©¦è§£æå¸¸è¦‹æ ¼å¼
        # 1. 2025.05.26 or 2025/05/26 or 2025-05-26
        match_num = re.search(r"(\d{4})[-/. ](\d{1,2})[-/. ](\d{1,2})", clean_date)
        if match_num:
            return f"{match_num.group(1)}/{int(match_num.group(2)):02d}/{int(match_num.group(3)):02d}"
            
        # 2. Jan 08, 2025 or 16-Jun-25
        # é€™è£¡ç°¡å–®è™•ç†è‹±æ–‡æœˆä»½è½‰æ›
        months = {"JAN": 1, "FEB": 2, "MAR": 3, "APR": 4, "MAY": 5, "JUN": 6, 
                  "JUL": 7, "AUG": 8, "SEP": 9, "OCT": 10, "NOV": 11, "DEC": 12}
        
        # æ ¼å¼: 16-Jun-25 (DD-Mon-YY)
        match_dd_mon_yy = re.search(r"(\d{1,2})[-/\s]([A-Za-z]{3})[-/\s](\d{2,4})", clean_date, re.IGNORECASE)
        if match_dd_mon_yy:
            d, m_str, y = match_dd_mon_yy.groups()
            m = months.get(m_str.upper(), 0)
            if m > 0:
                if len(y) == 2: y = "20" + y
                return f"{y}/{m:02d}/{int(d):02d}"

        # æ ¼å¼: Jan 08, 2025 (Mon DD, YYYY)
        match_mon_dd_yyyy = re.search(r"([A-Za-z]{3})\.?\s+(\d{1,2}),?\s+(\d{4})", clean_date, re.IGNORECASE)
        if match_mon_dd_yyyy:
            m_str, d, y = match_mon_dd_yyyy.groups()
            m = months.get(m_str.upper(), 0)
            if m > 0:
                return f"{y}/{m:02d}/{int(d):02d}"
                
    except:
        pass
    
    return clean_date # å¦‚æœçœŸçš„è½‰ä¸äº†ï¼Œå›å‚³åŸå­—ä¸²

def extract_value_logic(val_str):
    """
    æ•¸å€¼æå–é‚è¼¯ (V5 å¢å¼·ç‰ˆï¼šCAS éæ¿¾)
    """
    if not val_str: return 0, "N.D."
    
    val_upper = str(val_str).upper().replace(" ", "")
    
    # 1. å„ªå…ˆè™•ç† CAS ç·¨è™Ÿ (V5 æ–°å¢é˜²ç«ç‰†)
    # æ ¼å¼å¦‚ 1763-23-1, 85-68-7
    if re.search(r"\b\d{2,7}-\d{2}-\d\b", val_str):
        return 0, "N.D." # é€™æ˜¯ CAS ç·¨è™Ÿï¼Œä¸æ˜¯çµæœï¼Œå¼·åˆ¶å›å‚³ N.D.

    # 2. è™•ç†æ–‡å­—ç‹€æ…‹
    if "N.D." in val_upper or "ND" in val_upper or "<" in val_upper:
        return 0, "N.D."
    if "NEGATIVE" in val_upper or "é˜´æ€§" in val_upper:
        return 0.0001, "NEGATIVE"
    if "POSITIVE" in val_upper or "é˜³æ€§" in val_upper:
        return 999999, "POSITIVE"
    
    # 3. è™•ç†æ•¸å­—
    val_clean = re.sub(r"(mg/kg|ppm|%)", "", val_str, flags=re.IGNORECASE)
    match = re.search(r"(\d+(\.\d+)?)", val_clean)
    
    if match:
        num = float(match.group(1))
        # ç°¡å–®éæ¿¾ Limit/MDL å¸¸è¦‹å€¼ (è¼”åŠ©)
        if num in [100, 1000, 2, 5, 8, 10, 25, 50] and "ND" not in val_upper:
             # é€™æ˜¯ä¸€å€‹é¢¨éšªåˆ¤æ–·ï¼Œä½†åœ¨è¡¨æ ¼é–å®šå¤±æ•ˆæ™‚å¾ˆæœ‰ç”¨
             pass 
        return num, match.group(1)
    
    return 0, "N.D."

def find_date_in_first_page(text):
    """
    åªåœ¨ç¬¬ä¸€é æŠ“æ—¥æœŸ (V5 å¢å¼·ç‰ˆï¼šæ’é™¤ Testing Period)
    """
    # é—œéµå­—ï¼šå¿…é ˆæ˜¯ Date, Issue Date, Report Date, æ—¥æœŸ
    # ä¸”å¾Œé¢ä¸èƒ½æ¥ "Received" (æ¥æ”¶æ—¥) æˆ– "Started" (é–‹å§‹æ—¥)
    
    lines = text.split('\n')
    for line in lines:
        # æ’é™¤ Sample Received Date, Testing Period
        if "RECEIVED" in line.upper() or "PERIOD" in line.upper() or "STARTED" in line.upper():
            continue
            
        if re.search(r"(Date:|Issue Date|Report Date|æ—¥æœŸ[:ï¼š])", line, re.IGNORECASE):
            # æ‰¾åˆ°æ—¥æœŸè¡Œï¼Œå˜—è©¦æå–æ—¥æœŸ
            # æ ¼å¼ 1: YYYY/MM/DD
            m1 = re.search(r"(\d{4}[-/. ]\d{1,2}[-/. ]\d{1,2})", line)
            if m1: return normalize_date(m1.group(1))
            
            # æ ¼å¼ 2: Jan 08, 2025
            m2 = re.search(r"([A-Za-z]{3}\.?\s+\d{1,2},?\s+\d{4})", line)
            if m2: return normalize_date(m2.group(1))
            
            # æ ¼å¼ 3: DD-Mon-YY
            m3 = re.search(r"(\d{1,2}-[A-Za-z]{3}-\d{2,4})", line)
            if m3: return normalize_date(m3.group(1))

    return ""

def get_column_strategy(header_cells):
    """
    åå­—åº§æ¨™é–å®š (V5 å¢å¼·ç‰ˆï¼šCAS æ’é™¤)
    """
    # æ’é™¤æ¸…å–®åŠ å…¥ CAS, CAS No.
    exclude_keywords = ["ITEM", "METHOD", "UNIT", "MDL", "LOQ", "LIMIT", "REQUIREMENT", 
                        "é¡¹ç›®", "æ–¹æ³•", "å•ä½", "é™å€¼", "RL", "CAS", "NO."]
    
    target_keywords = ["RESULT", "ç»“æœ", "SAMPLE", "ID", "001", "002", "A1", "DATA"]
    
    best_col_idx = -1
    max_score = -1
    
    for i, cell in enumerate(header_cells):
        if not cell: continue
        txt = clean_text(cell).upper()
        
        # å¼·åˆ¶æ’é™¤ CAS
        if "CAS" in txt: continue 
        
        if any(ex in txt for ex in exclude_keywords): continue
            
        score = 0
        if any(tg in txt for tg in target_keywords): score += 10
        
        # å„ªå…ˆé¸ä¸­é–“æˆ–é å¾Œçš„æ¬„ä½ (é€šå¸¸ Result ä¸æœƒæ˜¯ç¬¬ä¸€æ¬„)
        if i > 0: score += 1 

        if score > max_score:
            max_score = score
            best_col_idx = i
            
    # Fallback: å¦‚æœæ²’æ‰¾åˆ°æ˜ç¢º Resultï¼Œå–æœ€å¾Œä¸€å€‹éæ’é™¤æ¬„ä½
    if best_col_idx == -1:
        valid_indices = [i for i, c in enumerate(header_cells) if c and "CAS" not in str(c).upper() and not any(ex in clean_text(c).upper() for ex in exclude_keywords)]
        if valid_indices:
            best_col_idx = valid_indices[0] 
            
    return best_col_idx

# --- 3. æ ¸å¿ƒè™•ç†é‚è¼¯ ---

def process_file(uploaded_file):
    filename = uploaded_file.name
    results = {k: {"val": 0, "display": ""} for k in TARGET_FIELDS.keys()}
    results["PBBs"] = {"val": 0, "display": "", "sum_val": 0}
    results["PBDEs"] = {"val": 0, "display": "", "sum_val": 0}
    results["PFAS"] = ""
    results["Date"] = ""
    
    is_scanned = True
    full_text_content = ""
    
    with pdfplumber.open(uploaded_file) as pdf:
        # --- A. å…¨æ–‡æƒæ & é¦–é æ—¥æœŸ ---
        for i, page in enumerate(pdf.pages):
            text = page.extract_text()
            if text and len(text) > 50:
                is_scanned = False
                full_text_content += text + "\n"
                if i == 0:
                    results["Date"] = find_date_in_first_page(text)

        if is_scanned:
            return None, filename

        # PFAS
        if "PFAS" in full_text_content.upper() or "PER- AND POLYFLUOROALKYL" in full_text_content.upper():
            results["PFAS"] = "REPORT"

        # --- B. è¡¨æ ¼æ•¸æ“šæå– ---
        for page in pdf.pages:
            tables = page.extract_tables()
            
            # æ¨¡å¼ 1: çµæ§‹åŒ–è¡¨æ ¼
            if tables:
                for table in tables:
                    if not table or len(table) < 2: continue
                    
                    df = pd.DataFrame(table)
                    header_row_idx = -1
                    result_col_idx = -1
                    
                    # æƒæè¡¨é ­ (æ‰¾ Result, é¿é–‹ CAS/Method)
                    for r_idx, row in enumerate(table[:5]):
                        row_text = " ".join([str(c).upper() for c in row if c])
                        # åªè¦æœ‰ Item/é …ç›® ä¸”æœ‰ Unit/Result/MDL å°±ç®—è¡¨é ­
                        if ("ITEM" in row_text or "é¡¹ç›®" in row_text) and ("UNIT" in row_text or "MDL" in row_text or "RESULT" in row_text or "ç»“æœ" in row_text):
                            header_row_idx = r_idx
                            result_col_idx = get_column_strategy(row)
                            
                            # V5 æ–°å¢ï¼šå‚ç›´è¡¨é ­ä¿®æ­£ (å¦‚æœ Result é€™ä¸€æ ¼æ˜¯ç©ºçš„ï¼Œå¾€ä¸‹æ‰¾ Sample ID)
                            if result_col_idx == -1 and r_idx + 1 < len(table):
                                next_row = table[r_idx+1]
                                result_col_idx = get_column_strategy(next_row)
                            break
                    
                    if result_col_idx != -1:
                        # æŠ“å–æ•¸æ“š
                        for r_idx in range(header_row_idx + 1, len(table)):
                            row = table[r_idx]
                            if len(row) <= result_col_idx: continue
                            
                            item_name = clean_text(row[0])
                            if len(row) > 1: item_name += " " + clean_text(row[1]) # çµ„åˆå‰å…©æ¬„åç¨±
                            
                            val_text = clean_text(row[result_col_idx])
                            update_results(results, item_name, val_text)

            # æ¨¡å¼ 2: æ–‡å­—æµ (é‡å°éš±å½¢è¡¨æ ¼)
            # é€™è£¡ç°¡åŒ–ï¼šå¦‚æœè©²é æœ‰æ‰¾åˆ°è¡¨æ ¼å°±ä¸è·‘æ–‡å­—æµï¼Œé™¤éè¡¨æ ¼å¾ˆå°‘
            # ç‚ºäº†ä¿éšªï¼Œæˆ‘å€‘åªé‡å°ç‰¹å®šé—œéµå­—åšæ–‡å­—æµæƒæ
            
            words = page.extract_words(keep_blank_chars=True)
            rows = {}
            for w in words:
                y = round(w['top'] / 5) * 5 # æ¨¡ç³Š Y è»¸ (åŠ å¤§ Tolerance)
                if y not in rows: rows[y] = []
                rows[y].append(w)
            
            for y, row_words in rows.items():
                line_text = " ".join([w['text'] for w in row_words])
                
                # æƒæç›®æ¨™é …ç›®
                for field, config in TARGET_FIELDS.items():
                    for kw in config["keywords"]:
                        if re.search(kw, line_text, re.IGNORECASE):
                            # åœ¨æ­¤è¡Œå°‹æ‰¾æ•¸å€¼ï¼Œç”±å³å‘å·¦æ‰¾
                            parts = line_text.split()
                            # éæ¿¾æ‰ CAS æ ¼å¼ (xx-xx-x)
                            valid_parts = [p for p in parts if not re.search(r"\d{2,7}-\d{2}-\d", p)]
                            
                            # æ‰¾æœ€å¾Œä¸€å€‹æœ‰æ•ˆçš„
                            for part in reversed(valid_parts):
                                val, disp = extract_value_logic(part)
                                if val > 0 or disp == "N.D." or disp == "NEGATIVE":
                                    # å†æ¬¡æª¢æŸ¥æ˜¯å¦ç‚º Limit (1000)
                                    if val == 1000 and disp != "N.D.": continue
                                    update_results(results, field, disp, is_text_mode=True)
                                    break
                
                # PBBs/PBDEs åŠ ç¸½
                for pbb_kw in PBBS_KEYWORDS + PBDES_KEYWORDS:
                    if re.search(pbb_kw, line_text, re.IGNORECASE):
                        parts = line_text.split()
                        valid_parts = [p for p in parts if not re.search(r"\d{2,7}-\d{2}-\d", p)]
                        for part in reversed(valid_parts):
                            val, disp = extract_value_logic(part)
                            if val > 0 and val != 1000: # æ’é™¤ N.D. (0) å’Œ Limit
                                cat = "PBBs" if any(k in pbb_kw for k in PBBS_KEYWORDS) else "PBDEs"
                                results[cat]["sum_val"] += val
                                break

    finalize_results(results)
    
    final_output = {
        "File Name": filename,
        "Pb": results["Lead"]["display"],
        "Cd": results["Cadmium"]["display"],
        "Hg": results["Mercury"]["display"],
        "Cr(VI)": results["Hexavalent Chromium"]["display"],
        "PBBs": results["PBBs"]["display"],
        "PBDEs": results["PBDEs"]["display"],
        "DEHP": results["DEHP"]["display"],
        "BBP": results["BBP"]["display"],
        "DBP": results["DBP"]["display"],
        "DIBP": results["DIBP"]["display"],
        "F": results["Fluorine"]["display"],
        "Cl": results["Chlorine"]["display"],
        "Br": results["Bromine"]["display"],
        "I": results["Iodine"]["display"],
        "PFOS": results["PFOS"]["display"],
        "PFAS": results["PFAS"],
        "Date": results["Date"],
        "_sort_pb": results["Lead"]["val"],
        "_sort_max": max([v["val"] for k, v in results.items() if isinstance(v, dict) and "val" in v])
    }
    
    return final_output, None

def update_results(results, item_name, val_text, is_text_mode=False):
    item_upper = str(item_name).upper()
    val_num, val_disp = extract_value_logic(val_text)
    
    # 1. ä¸€èˆ¬é …ç›®
    for field_key, config in TARGET_FIELDS.items():
        for kw in config["keywords"]:
            if re.search(kw, item_upper, re.IGNORECASE):
                if is_text_mode and results[field_key]["val"] > 0: return # è¡¨æ ¼å„ªå…ˆ
                
                if val_num > results[field_key]["val"]:
                    results[field_key]["val"] = val_num
                    results[field_key]["display"] = val_disp
                elif val_num == 0 and results[field_key]["val"] == 0:
                    if val_disp == "NEGATIVE": results[field_key]["display"] = "NEGATIVE"
                    elif not results[field_key]["display"]: results[field_key]["display"] = "N.D."
                return

    # 2. PBBs/PBDEs åŠ ç¸½
    for pbb_kw in PBBS_KEYWORDS:
        if re.search(pbb_kw, item_upper, re.IGNORECASE):
            if is_text_mode: return
            results["PBBs"]["sum_val"] += val_num
            return

    for pbde_kw in PBDES_KEYWORDS:
        if re.search(pbde_kw, item_upper, re.IGNORECASE):
            if is_text_mode: return
            results["PBDEs"]["sum_val"] += val_num
            return

def finalize_results(results):
    if results["PBBs"]["sum_val"] > 0:
        results["PBBs"]["display"] = str(round(results["PBBs"]["sum_val"], 2))
        results["PBBs"]["val"] = results["PBBs"]["sum_val"]
    elif not results["PBBs"]["display"]: results["PBBs"]["display"] = "N.D."

    if results["PBDEs"]["sum_val"] > 0:
        results["PBDEs"]["display"] = str(round(results["PBDEs"]["sum_val"], 2))
        results["PBDEs"]["val"] = results["PBDEs"]["sum_val"]
    elif not results["PBDEs"]["display"]: results["PBDEs"]["display"] = "N.D."

# --- ä¸»ä»‹é¢ ---

uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ PDF æª¢æ¸¬å ±å‘Š (æ”¯æ´ SGS, CTI, Intertek ç­‰)", type="pdf", accept_multiple_files=True)

if uploaded_files:
    all_data = []
    scanned_files = []

    with st.spinner('æ­£åœ¨é€²è¡Œ V5 å¼•æ“åˆ†æ (CAS éæ¿¾ + æ™ºèƒ½é–å®š)...'):
        for pdf_file in uploaded_files:
            data, scanned_name = process_file(pdf_file)
            if scanned_name:
                scanned_files.append(scanned_name)
            else:
                all_data.append(data)

    if all_data:
        df = pd.DataFrame(all_data)
        df = df.sort_values(by=["_sort_pb", "_sort_max"], ascending=[False, False])
        display_df = df.drop(columns=["_sort_pb", "_sort_max"])
        
        st.success(f"âœ… æˆåŠŸæ“·å– {len(all_data)} ä»½å ±å‘Šï¼(V5 æ ¸å¿ƒ)")
        st.dataframe(display_df, use_container_width=True)
        
        csv = display_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel/CSV å ±è¡¨",
            data=csv,
            file_name="rohs_report_v5_final.csv",
            mime="text/csv",
        )

    if scanned_files:
        st.error("âš ï¸ ä»¥ä¸‹æª”æ¡ˆç‚ºæƒæåœ–ç‰‡ (ç„¡æ³•æ“·å–æ–‡å­—)ï¼š")
        for f in scanned_files:
            st.write(f"- {f}")

else:
    st.info("è«‹ä¸Šå‚³ PDF æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚")
