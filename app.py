import streamlit as st
import pdfplumber
import pandas as pd
import re
from datetime import datetime

# --- è¨­å®šé é¢ ---
st.set_page_config(page_title="é€šç”¨æª¢æ¸¬å ±å‘Šæ“·å–å·¥å…· (V17 è¦–è¦ºåº§æ¨™ç‰ˆ)", layout="wide")
st.title("ğŸ§ª é€šç”¨å‹ç¬¬ä¸‰æ–¹æª¢æ¸¬å ±å‘Šæ•¸æ“šæ“·å–å·¥å…· (V17 è¦–è¦ºåº§æ¨™ç‰ˆ)")
st.markdown("""
**V17 ç‰ˆæœ¬æ ¸å¿ƒç‰¹å¾µï¼šè¦–è¦ºåº§æ¨™å¼•æ“ + å¤šåœ‹èªè¨€å­—å…¸**
1.  **ğŸ‘ï¸ PBBs/PBDEs è¦–è¦ºæƒæ**ï¼šåˆ©ç”¨æ–‡å­—åº§æ¨™ (Y-Axis) é–å®šåŒä¸€è¡Œæ•¸å€¼ï¼Œç„¡è¦–æ’ç‰ˆéŒ¯ä½èˆ‡éš±å½¢è¡¨æ ¼ã€‚
2.  **ğŸŒ å¤šåœ‹èªè¨€å­—å…¸**ï¼šæ–°å¢ SGS å°ˆç”¨è¡“èªã€è‹±æ–‡ç¸®å¯« (MonoBB)ã€éŸ“æ–‡é—œéµå­— (ëª¨ë…¸ë¸Œë¡œëª¨)ã€‚
3.  **ğŸ“… éŸ“åœ‹æ—¥æœŸæ”¯æ´**ï¼šæ”¯æ´ `YYYY. MM. DD.` æ ¼å¼èˆ‡éŸ“æ–‡ç™¼è¡Œæ—¥æ¨™ç±¤ã€‚
4.  **ğŸ›¡ï¸ SGS çµ•å°é˜²ç¦¦**ï¼šè‹¥è¡¨æ ¼å®šä½å¤±æ•—ï¼Œå¼·åˆ¶é–å®šæœ€å³æ¬„ã€‚
""")

# --- 1. æ“´å……é—œéµå­—å®šç¾© (åŒ…å«å­—æ ¹ã€ç¸®å¯«ã€éŸ“æ–‡) ---
TARGET_FIELDS = {
    "Lead": {"name": "Pb", "keywords": [r"^Lead\b", r"^Pb\b", r"é“…", r"Lead \(Pb\)", r"Pb"]},
    "Cadmium": {"name": "Cd", "keywords": [r"^Cadmium\b", r"^Cd\b", r"é•‰", r"Cadmium \(Cd\)", r"Cd"]},
    "Mercury": {"name": "Hg", "keywords": [r"^Mercury\b", r"^Hg\b", r"æ±", r"Mercury \(Hg\)", r"Hg"]},
    "Hexavalent Chromium": {"name": "Cr(VI)", "keywords": [r"Hexavalent Chromium", r"Cr\(VI\)", r"Cr6\+", r"å…­ä»·é“¬", r"å…­åƒ¹é‰»"]},
    "DEHP": {"name": "DEHP", "keywords": [r"Bis\(2-ethylhexyl\) phthalate", r"DEHP", r"é‚»è‹¯äºŒç”²é…¸äºŒ\(2-ä¹™åŸºå·±åŸº\)é…¯"]},
    "BBP": {"name": "BBP", "keywords": [r"Butyl benzyl phthalate", r"BBP", r"é‚»è‹¯äºŒç”²é…¸ä¸åŸºè‹„åŸºé…¯", r"é‚»è‹¯äºŒç”²é…¸ä¸è‹„é…¯"]},
    "DBP": {"name": "DBP", "keywords": [r"Dibutyl phthalate", r"DBP", r"é‚»è‹¯äºŒç”²é…¸äºŒä¸é…¯"]},
    "DIBP": {"name": "DIBP", "keywords": [r"Diisobutyl phthalate", r"DIBP", r"é‚»è‹¯äºŒç”²é…¸äºŒå¼‚ä¸é…¯"]},
    "Fluorine": {"name": "F", "keywords": [r"Fluorine", r"æ°Ÿ", r"Fluorine \(F\)"]},
    "Chlorine": {"name": "Cl", "keywords": [r"Chlorine", r"æ°¯", r"Chlorine \(Cl\)"]},
    "Bromine": {"name": "Br", "keywords": [r"Bromine", r"æº´", r"Bromine \(Br\)"]},
    "Iodine": {"name": "I", "keywords": [r"Iodine", r"ç¢˜", r"Iodine \(I\)"]},
    "PFOS": {"name": "PFOS", "keywords": [r"Perfluorooctane Sulfonates", r"PFOS", r"å…¨æ°Ÿè¾›çƒ·ç£ºé…¸"]},
}

# æœ‰æ©Ÿç‰©é—œéµå­— (è¦–è¦ºæƒæç”¨ - å­—æ ¹åŒ¹é…)
# åŒ…å«ï¼šè‹±æ–‡å…¨ç¨±å­—æ ¹ã€ç¸®å¯«ã€ä¸­æ–‡ã€éŸ“æ–‡
PBBS_ROOTS = [
    "Monobromo", "Dibromo", "Tribromo", "Tetrabromo", "Pentabromo", "Hexabromo", "Heptabromo", "Octabromo", "Nonabromo", "Decabromo",
    "MonoBB", "DiBB", "TriBB", "TetraBB", "PentaBB", "HexaBB", "HeptaBB", "OctaBB", "NonaBB", "DecaBB",
    "ä¸€æº´è”è‹¯", "äºŒæº´è”è‹¯", "ä¸‰æº´è”è‹¯", "å››æº´è”è‹¯", "äº”æº´è”è‹¯", "å…­æº´è”è‹¯", "ä¸ƒæº´è”è‹¯", "å…«æº´è”è‹¯", "ä¹æº´è”è‹¯", "åæº´è”è‹¯",
    "ëª¨ë…¸ë¸Œë¡œëª¨", "ë‹¤ì´ë¸Œë¡œëª¨", "íŠ¸ë¼ì´ë¸Œë¡œëª¨", "í…ŒíŠ¸ë¼ë¸Œë¡œëª¨", "íœíƒ€ë¸Œë¡œëª¨", "í—¥ì‚¬ë¸Œë¡œëª¨", "í—µíƒ€ë¸Œë¡œëª¨", "ì˜¥íƒ€ë¸Œë¡œëª¨", "ë…¸ë‚˜ë¸Œë¡œëª¨", "ë°ì¹´ë¸Œë¡œëª¨"
]

PBDES_ROOTS = [
    "Monobromodiphenyl", "Dibromodiphenyl", "Tribromodiphenyl", "Tetrabromodiphenyl", "Pentabromodiphenyl", "Hexabromodiphenyl", 
    "Heptabromodiphenyl", "Octabromodiphenyl", "Nonabromodiphenyl", "Decabromodiphenyl",
    "MonoBDE", "DiBDE", "TriBDE", "TetraBDE", "PentaBDE", "HexaBDE", "HeptaBDE", "OctaBDE", "NonaBDE", "DecaBDE",
    "ä¸€æº´äºŒè‹¯é†š", "äºŒæº´äºŒè‹¯é†š", "ä¸‰æº´äºŒè‹¯é†š", "å››æº´äºŒè‹¯é†š", "äº”æº´äºŒè‹¯é†š", "å…­æº´äºŒè‹¯é†š", "ä¸ƒæº´äºŒè‹¯é†š", "å…«æº´äºŒè‹¯é†š", "ä¹æº´äºŒè‹¯é†š", "åæº´äºŒè‹¯é†š"
]

# --- 2. è¼”åŠ©å‡½å¼ ---

def clean_text(text):
    if not text: return ""
    return re.sub(r'\s+', ' ', str(text)).strip()

def parse_date_obj(date_str):
    """å¼·åŒ–çš„æ—¥æœŸè§£æï¼Œæ”¯æ´éŸ“æ–‡æ ¼å¼èˆ‡ç©ºæ ¼é»"""
    clean = re.sub(r"Date:|Issue Date:|Report Date:|æ—¥æœŸ|ë°œí–‰ì¼ì|ë°œí–‰\s*\(?Date\)?[:ï¼š]?", "", date_str, flags=re.IGNORECASE).strip()
    clean = clean.replace("/", "-").replace(" ", "-") # å…ˆæŠŠå¸¸è¦‹åˆ†éš”ç¬¦çµ±ä¸€
    
    # é‡å°éŸ“æ–‡/ç‰¹æ®Šæ ¼å¼ 2024. 10. 17. é€²è¡Œé è™•ç†
    # å°‡ "2024. 10. 17" è½‰ç‚º "2024-10-17"
    if "." in clean:
        clean = re.sub(r"\s+", "", clean) # ç§»é™¤æ‰€æœ‰ç©ºæ ¼
        clean = clean.rstrip(".") # ç§»é™¤çµå°¾çš„é»
        clean = clean.replace(".", "-")

    formats = ["%Y-%m-%d", "%d-%b-%Y", "%d-%B-%Y", "%b-%d-%Y", "%B-%d-%Y", "%d-%b-%y", "%d-%B-%y"]
    for fmt in formats:
        try: return datetime.strptime(clean, fmt)
        except: continue
            
    # Regex è£œå¼·
    try:
        # 2025-06-16
        m = re.search(r"(\d{4})[-/. ]*(\d{1,2})[-/. ]*(\d{1,2})", date_str)
        if m: return datetime(int(m.group(1)), int(m.group(2)), int(m.group(3)))
        
        # 16-Jun-2025
        m2 = re.search(r"(\d{1,2})[-/\s]([A-Za-z]{3})[-/\s,.]+(\d{4})", date_str, re.IGNORECASE)
        if m2: return datetime.strptime(f"{m2.group(1)}-{m2.group(2)}-{m2.group(3)}", "%d-%b-%Y")
    except: pass
    return None

def find_date_in_first_page(text):
    lines = text.split('\n')
    candidates = []
    # é»‘åå–®ï¼šåŠ å…¥éŸ“æ–‡ "ì‹œí—˜" (Test)
    blacklist = ["RECEIVED", "PERIOD", "STARTED", "SUBMITTED", "COMPLETED", "TESTING", "æ”¶ä»¶", "æ¥æ”¶", "å‘¨æœŸ", "æœŸé—´", "ì‹œí—˜"]
    
    for line in lines:
        upper_line = line.upper()
        if any(bad in upper_line for bad in blacklist): continue
            
        # æŠ“å– YYYY.MM.DD æˆ– DD-Mon-YYYY
        if re.search(r"\d{4}[-/. ]+\d{1,2}[-/. ]+\d{1,2}", line) or \
           (re.search(r"[A-Za-z]{3}", line) and re.search(r"\d{4}", line)):
            candidates.append(line)
            
    valid_dates = []
    for c in candidates:
        dt = parse_date_obj(c)
        if dt and 2015 <= dt.year <= 2030: valid_dates.append(dt)
    
    if valid_dates:
        return max(valid_dates).strftime("%Y/%m/%d")
    return ""

def extract_value_logic(val_str, strict_numeric=False):
    if not val_str: return None, ""
    val_upper = str(val_str).upper().replace(" ", "")
    
    if re.search(r"\b\d{2,7}-\d{2}-\d\b", val_str): return None, "" # CAS No.

    if "N.D." in val_upper or "ND" in val_upper or "<" in val_upper: return 0, "N.D."
    
    if "NEGATIVE" in val_upper or "é˜´æ€§" in val_upper: 
        if strict_numeric: return None, ""
        return 0.0001, "NEGATIVE"
        
    if "POSITIVE" in val_upper or "é˜³æ€§" in val_upper: 
        if strict_numeric: return None, ""
        return 999999, "POSITIVE"
    
    val_clean = re.sub(r"(mg/kg|ppm|%|Âµg/cmÂ²|ug/cm2)", "", val_str, flags=re.IGNORECASE)
    match = re.search(r"(\d+(\.\d+)?)", val_clean)
    
    if match:
        num = float(match.group(1))
        if 2010 <= num <= 2030: return None, "" 
        return num, match.group(1)
    
    return None, ""

# --- 3. æ ¸å¿ƒåŠŸèƒ½æ¨¡çµ„ ---

def find_sample_ids(full_text_pages_1_2):
    """é è®€æ¨£å“ç·¨è™Ÿ"""
    ids = []
    patterns = [
        r"(?:Sample|Specimen)\s*(?:No\.|ID|Ref\.?)\s*[:ï¼š]?\s*([A-Za-z0-9\-]+)",
        r"(?:SN\s*ID)\s*[:ï¼š]?\s*([A-Za-z0-9\-]+)",
        r"(?:æ ·å“|æ¨£å“)\s*(?:ç¼–å·|åºå·|ID)\s*[:ï¼š]?\s*([A-Za-z0-9\-]+)"
    ]
    for line in full_text_pages_1_2.split('\n'):
        for pat in patterns:
            m = re.search(pat, line, re.IGNORECASE)
            if m:
                found_id = m.group(1).strip()
                if len(found_id) < 15: ids.append(found_id.upper())
    return list(set(ids))

def extract_visual_row_values(page_words, keywords):
    """
    [V17 æ ¸å¿ƒ] è¦–è¦ºåº§æ¨™æƒæå¼•æ“
    page_words: pdfplumber.extract_words() çš„çµæœ
    keywords: è¦å°‹æ‰¾çš„é—œéµå­—åˆ—è¡¨ (å­—æ ¹)
    """
    found_values = []
    
    # 1. å°‹æ‰¾é—œéµå­—æ‰€åœ¨çš„ Word ç‰©ä»¶
    target_words = []
    for w in page_words:
        txt = w['text'].upper()
        # ä½¿ç”¨å­—æ ¹åŒ¹é… (åªè¦åŒ…å« Monobromo å°±ç®—)
        if any(k.upper() in txt for k in keywords):
            target_words.append(w)
    
    if not target_words:
        return []

    # 2. é‡å°æ¯å€‹æ‰¾åˆ°çš„é—œéµå­—ï¼Œæƒæã€ŒåŒä¸€é«˜åº¦ã€çš„æ‰€æœ‰æ–‡å­—
    for tw in target_words:
        # å®šç¾©æƒæå€åŸŸ (Yè»¸ä¸­å¿ƒé» +/- 3px)
        y_center = (tw['top'] + tw['bottom']) / 2
        tolerance = 5 
        
        # æ‰¾å‡ºæ‰€æœ‰åœ¨åŒä¸€è¡Œçš„æ–‡å­—
        row_words = [
            w for w in page_words 
            if abs((w['top'] + w['bottom']) / 2 - y_center) < tolerance
        ]
        
        # ä¾ X è»¸æ’åº (å¾å·¦åˆ°å³)
        row_words.sort(key=lambda x: x['x0'])
        
        # æå–æ•¸å€¼
        for w in row_words:
            v_num, v_disp = extract_value_logic(w['text'])
            if v_num is not None:
                # æ™ºæ…§éæ¿¾: æ’é™¤ MDL/Limit
                if v_num in [5, 10, 25, 50, 100, 1000] and v_disp != "N.D.": continue
                found_values.append(v_num)
    
    return found_values

def get_column_score(header_cells, sample_ids, is_sgs=False):
    """V17 è¡¨æ ¼å®šä½"""
    scores = {}
    num_cols = len(header_cells)
    
    result_kw = ["RESULT", "ç»“æœ", "SAMPLE", "ID", "001", "002", "A1", "A2", "DATA", "å«é‡"]
    known_cols_kw = ["ITEM", "METHOD", "UNIT", "MDL", "LOQ", "LIMIT", "REQUIREMENT", "é¡¹ç›®", "æ–¹æ³•", "å•ä½", "é™å€¼", "CAS"]
    
    for i, cell in enumerate(header_cells):
        if not cell: continue
        txt = clean_text(str(cell)).upper()
        score = 0
        
        if any(k in txt for k in known_cols_kw): score -= 500
        if any(res in txt for res in result_kw): score += 100
        if txt in sample_ids: score += 500 # å‘½ä¸­ Sample ID æ¬Šé‡æœ€é«˜
        
        if score == 0: score += 50 
        scores[i] = score

    if not scores: return -1
    best_col = max(scores, key=scores.get)
    
    # SGS å°ˆå±¬ï¼šè‹¥ç„¡æ˜ç¢ºçµæœæ¬„ï¼Œå„ªå…ˆä¿¡ä»»æœ€å³æ¬„
    if is_sgs and scores[best_col] <= 50: 
        return num_cols - 1
        
    if scores[best_col] < 0: return -1
    return best_col

def process_file(uploaded_file):
    filename = uploaded_file.name
    results = {k: {"val": None, "display": ""} for k in TARGET_FIELDS.keys()}
    results["PBBs"] = {"val": None, "display": "", "sum_val": 0}
    results["PBDEs"] = {"val": None, "display": "", "sum_val": 0}
    results["PFAS"] = ""
    results["Date"] = ""
    
    full_text_content = ""
    is_sgs = "SGS" in filename.upper()
    
    with pdfplumber.open(uploaded_file) as pdf:
        # A. å…¨æ–‡æƒæ & æ—¥æœŸ
        for i, page in enumerate(pdf.pages):
            text = page.extract_text()
            if text:
                full_text_content += text + "\n"
                if "SGS" in text.upper(): is_sgs = True
                if i == 0: results["Date"] = find_date_in_first_page(text)

        sample_ids = find_sample_ids(full_text_content[:3000])
        results["PFAS"] = check_pfas_in_section(full_text_content)

        # --- è»Œé“ A: PBBs/PBDEs è¦–è¦ºåº§æ¨™æƒæ (Visual Engine) ---
        # éæ­·æ¯ä¸€é ï¼Œä½¿ç”¨ extract_words ç²å–åº§æ¨™
        for page in pdf.pages:
            words = page.extract_words()
            
            # æƒæ PBBs
            pbb_vals = extract_visual_row_values(words, PBBS_ROOTS)
            if pbb_vals:
                val = pbb_vals[-1] # å–è©²è¡Œæœ€å¾Œä¸€å€‹æœ‰æ•ˆå€¼
                if val > 0:
                    results["PBBs"]["sum_val"] += val
                    results["PBBs"]["val"] = 1
            
            # æƒæ PBDEs
            pbde_vals = extract_visual_row_values(words, PBDES_ROOTS)
            if pbde_vals:
                val = pbde_vals[-1]
                if val > 0:
                    results["PBDEs"]["sum_val"] += val
                    results["PBDEs"]["val"] = 1

        # --- è»Œé“ B: é‡é‡‘å±¬/å–®é … è¡¨æ ¼å®šä½ (V17) ---
        for page in pdf.pages:
            tables = page.extract_tables()
            if not tables: continue
            
            for table in tables:
                if not table or len(table) < 2: continue
                
                header_row_idx = -1
                result_col_idx = -1
                
                for r_idx, row in enumerate(table[:6]):
                    row_str = " ".join([str(c).upper() for c in row if c])
                    if ("ITEM" in row_str or "é¡¹ç›®" in row_str or "TEST" in row_str) and \
                       ("UNIT" in row_str or "MDL" in row_str or "LIMIT" in row_str or "RESULT" in row_str):
                        header_row_idx = r_idx
                        result_col_idx = get_column_score(row, sample_ids, is_sgs)
                        break
                
                if header_row_idx == -1: continue
                
                for r_idx in range(header_row_idx + 1, len(table)):
                    row = table[r_idx]
                    if not row: continue
                    
                    item_name = clean_text(row[0])
                    if len(row) > 1: item_name += " " + clean_text(row[1])
                    item_upper = item_name.upper()
                    
                    for field, config in TARGET_FIELDS.items():
                        for kw in config["keywords"]:
                            if re.search(kw, item_upper, re.IGNORECASE):
                                if field == "Chlorine" and ("POLYVINYL" in item_upper or "PVC" in item_upper): continue
                                
                                val_text = ""
                                if result_col_idx != -1 and len(row) > result_col_idx:
                                    val_text = clean_text(row[result_col_idx])
                                else:
                                    val_text = clean_text(row[-1]) 
                                
                                is_strict = (field in ["Chlorine", "Bromine", "PFOS"])
                                v_num, v_disp = extract_value_logic(val_text, strict_numeric=is_strict)
                                
                                if v_num is not None:
                                    if v_num in [1000] and v_disp != "N.D.": continue
                                    
                                    curr = results[field]["val"]
                                    if curr is None or v_num > curr:
                                        results[field]["val"] = v_num
                                        results[field]["display"] = v_disp
                                    elif v_num == 0 and (curr is None or curr == 0):
                                        if v_disp == "NEGATIVE": results[field]["display"] = "NEGATIVE"
                                        elif not results[field]["display"]: results[field]["display"] = "N.D."
                                        results[field]["val"] = 0

    # --- æœ€çµ‚æ•´ç† ---
    if results["PBBs"]["sum_val"] > 0:
        results["PBBs"]["display"] = str(round(results["PBBs"]["sum_val"], 2))
    elif results["PBBs"]["val"] is None:
        results["PBBs"]["display"] = ""
    else:
        results["PBBs"]["display"] = "N.D."

    if results["PBDEs"]["sum_val"] > 0:
        results["PBDEs"]["display"] = str(round(results["PBDEs"]["sum_val"], 2))
    elif results["PBDEs"]["val"] is None:
        results["PBDEs"]["display"] = ""
    else:
        results["PBDEs"]["display"] = "N.D."

    # å®‰å…¨æ’åº (V17.1 Fix)
    valid_vals = [v["val"] for k, v in results.items() if isinstance(v, dict) and v["val"] is not None]
    sort_max = max(valid_vals) if valid_vals else 0

    final_output = {
        "File Name": filename,
        "Pb": results["Lead"]["display"],
        "Cd": results["Cadmium"]["display"],
        "Hg": results["Mercury"]["display"],
        "Cr(VI)": results["Hexavalent Chromium"]["display"],
        "PBBs": results["PBBs"]["display"],
        "PBDEs": results["PBDEs"]["display"],
        "DEHP": results["DEHP"]["display"],
        "BBP": results["BBP"]["display"],
        "DBP": results["DBP"]["display"],
        "DIBP": results["DIBP"]["display"],
        "F": results["Fluorine"]["display"],
        "Cl": results["Chlorine"]["display"],
        "Br": results["Bromine"]["display"],
        "I": results["Iodine"]["display"],
        "PFOS": results["PFOS"]["display"],
        "PFAS": results["PFAS"],
        "Date": results["Date"],
        "_sort_pb": results["Lead"]["val"] if results["Lead"]["val"] is not None else 0,
        "_sort_max": sort_max
    }
    
    return final_output, None

# --- ä¸»ä»‹é¢ ---
uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ PDF æª¢æ¸¬å ±å‘Š (æ”¯æ´ SGS, CTI, Intertek ç­‰)", type="pdf", accept_multiple_files=True)

if uploaded_files:
    all_data = []
    scanned_files = []

    with st.spinner('æ­£åœ¨é€²è¡Œ V17 è¦–è¦ºå¼•æ“åˆ†æ (è¦–è¦ºåº§æ¨™ + å­—å…¸æ“´å……)...'):
        for pdf_file in uploaded_files:
            data, scanned_name = process_file(pdf_file)
            if scanned_name:
                scanned_files.append(scanned_name)
            else:
                all_data.append(data)

    if all_data:
        df = pd.DataFrame(all_data)
        # æ’åº
        if "_sort_pb" in df.columns:
            df = df.sort_values(by=["_sort_pb", "_sort_max"], ascending=[False, False])
            display_df = df.drop(columns=["_sort_pb", "_sort_max"])
        else:
            display_df = df
        
        st.success(f"âœ… æˆåŠŸæ“·å– {len(all_data)} ä»½å ±å‘Šï¼(V17 æ ¸å¿ƒ)")
        st.dataframe(display_df, use_container_width=True)
        
        csv = display_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel/CSV å ±è¡¨",
            data=csv,
            file_name="rohs_report_v17_visual.csv",
            mime="text/csv",
        )

    if scanned_files:
        st.error("âš ï¸ ä»¥ä¸‹æª”æ¡ˆç‚ºæƒæåœ–ç‰‡ (ç„¡æ³•æ“·å–æ–‡å­—)ï¼š")
        for f in scanned_files:
            st.write(f"- {f}")
else:
    st.info("è«‹ä¸Šå‚³ PDF æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚")
