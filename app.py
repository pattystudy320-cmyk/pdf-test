import streamlit as st
import pdfplumber
import pandas as pd
import re
import io
from dateutil import parser

# ==========================================
# 0. å¼·åˆ¶æ¸…é™¤å¿«å– (è§£æ±ºçµæœå¡ä½å•é¡Œ)
# ==========================================
st.cache_data.clear()

# ==========================================
# 1. å…¨å±€é…ç½®
# ==========================================

# æœ€çµ‚è¼¸å‡ºæ¬„ä½
TARGET_ITEMS = [
    "Pb", "Cd", "Hg", "Cr6+", "PBBs", "PBDEs",
    "DEHP", "DBP", "BBP", "DIBP",
    "F", "Cl", "Br", "I",
    "PFOS", "PFAS", "DATE", "FILENAME"
]

# --- SGS å°ˆç”¨å„ªåŒ–å­—å…¸ (åŸºæ–¼æ‚¨æä¾›çš„ SGS.txt) ---
# åŒ…å«ä¸­æ–‡(ç¹/ç°¡)èˆ‡è‹±æ–‡é—œéµå­—
SGS_OPTIMIZED_MAP = {
    'Pb': ['Lead', 'Pb', 'é‰›', 'é“…'],
    'Cd': ['Cadmium', 'Cd', 'é˜', 'é•‰'],
    'Hg': ['Mercury', 'Hg', 'æ±'],
    'Cr6+': ['Hexavalent Chromium', 'Cr(VI)', 'å…­åƒ¹é‰»', 'å…­ä»·é“¬'],
    'PBBs': ['Polybrominated biphenyls', 'PBB', 'å¤šæº´è¯è‹¯', 'å¤šæº´è”è‹¯', 'Sum of PBBs'],
    'PBDEs': ['Polybrominated diphenyl ethers', 'PBDE', 'å¤šæº´äºŒè‹¯é†š', 'Sum of PBDEs'],
    'DEHP': ['Bis(2-ethylhexyl) phthalate', 'DEHP', 'é„°è‹¯äºŒç”²é…¸äºŒ(2-ä¹™åŸºå·±åŸº)é…¯', 'Di(2-ethylhexyl) phthalate'],
    'DBP': ['Dibutyl phthalate', 'DBP', 'é„°è‹¯äºŒç”²é…¸äºŒä¸é…¯'],
    'BBP': ['Butyl benzyl phthalate', 'BBP', 'é„°è‹¯äºŒç”²é…¸ä¸è‹„é…¯'],
    'DIBP': ['Diisobutyl phthalate', 'DIBP', 'é„°è‹¯äºŒç”²é…¸äºŒç•°ä¸é…¯'],
    'F': ['Fluorine', 'æ°Ÿ'],
    'Cl': ['Chlorine', 'æ°¯'],
    'Br': ['Bromine', 'æº´'],
    'I': ['Iodine', 'ç¢˜'],
    'PFOS': ['Perfluorooctane sulfonic acid', 'PFOS', 'å…¨æ°Ÿè¾›çƒ·ç£ºé…¸', 'Perfluorooctane Sulfonates'],
    # PFAS æ¨™è¨˜ç”¨
    'PFAS': ['PFAS'] 
}

# --- CTI/Intertek é€šç”¨å­—å…¸ (Regexç‰ˆï¼Œç¶­æŒåŸæ¨£) ---
UNIFIED_REGEX_MAP = {
    r"(?i)\b(Lead|Pb|é“…)\b": "Pb",
    r"(?i)\b(Cadmium|Cd|é•‰)\b": "Cd",
    r"(?i)\b(Mercury|Hg|æ±)\b": "Hg",
    r"(?i)\b(Hexavalent Chromium|Cr\(?VI\)?|å…­ä»·é“¬)\b": "Cr6+",
    r"(?i)\b(DEHP|Di\(2-ethylhexyl\)\s*phthalate)\b": "DEHP",
    r"(?i)\b(DBP|Dibutyl\s*phthalate)\b": "DBP",
    r"(?i)\b(BBP|Butyl\s*benzyl\s*phthalate)\b": "BBP",
    r"(?i)\b(DIBP|Diisobutyl\s*phthalate)\b": "DIBP",
    r"(?i)(Fluorine|æ°Ÿ).*\((F|F-)\)": "F",
    r"(?i)(Chlorine|æ°¯|æ°£).*\((Cl|Cl-)\)": "Cl",
    r"(?i)(Bromine|æº´).*\((Br|Br-)\)": "Br",
    r"(?i)(Iodine|ç¢˜).*\((I|I-)\)": "I",
    r"(?i)(Perfluorooctane\s*sulfonic\s*acid\s*\(PFOS\)|PFOS.*(salts|åŠå…¶ç›)|å…¨æ°Ÿè¾›çƒ·ç£ºé…¸)": "PFOS"
}
# PBBs/PBDEs åŠ ç¸½ Regex
PBB_SUBITEMS = r"(?i)(Monobromobiphenyl|Dibromobiphenyl|Tribromobiphenyl|Tetrabromobiphenyl|Pentabromobiphenyl|Hexabromobiphenyl|Heptabromobiphenyl|Octabromobiphenyl|Nonabromobiphenyl|Decabromobiphenyl|ä¸€æº´è”è‹¯|äºŒæº´è”è‹¯|ä¸‰æº´è”è‹¯|å››æº´è”è‹¯|äº”æº´è”è‹¯|å…­æº´è”è‹¯|ä¸ƒæº´è”è‹¯|å…«æº´è”è‹¯|ä¹æº´è”è‹¯|åæº´è”è‹¯)"
PBDE_SUBITEMS = r"(?i)(Monobromodiphenyl ether|Dibromodiphenyl ether|Tribromodiphenyl ether|Tetrabromodiphenyl ether|Pentabromodiphenyl ether|Hexabromodiphenyl ether|Heptabromodiphenyl ether|Octabromodiphenyl ether|Nonabromodiphenyl ether|Decabromodiphenyl ether|ä¸€æº´äºŒè‹¯é†š|äºŒæº´äºŒè‹¯é†š|ä¸‰æº´äºŒè‹¯é†š|å››æº´äºŒè‹¯é†š|äº”æº´äºŒè‹¯é†š|å…­æº´äºŒè‹¯é†š|ä¸ƒæº´äºŒè‹¯é†š|å…«æº´äºŒè‹¯é†š|ä¹æº´äºŒè‹¯é†š|åæº´äºŒè‹¯é†š)"

# --- SGS å°ˆç”¨ï¼šå®Œæ•´é»‘åå–® (å­—ä¸²æ¯”å°ç”¨) ---
# åŒ…å«å¸¸è¦‹çš„ Limit (1000, 100) èˆ‡ MDL (2, 5, 8, 10, 50)
SGS_IGNORE_LIST = ['2', '5', '8', '10', '50', '100', '1000']

# è‹±æ–‡æœˆä»½å°ç…§è¡¨
MONTH_MAP = {
    "Jan": "01", "Feb": "02", "Mar": "03", "Apr": "04", "May": "05", "Jun": "06",
    "Jul": "07", "Aug": "08", "Sep": "09", "Oct": "10", "Nov": "11", "Dec": "12",
    "JAN": "01", "FEB": "02", "MAR": "03", "APR": "04", "MAY": "05", "JUN": "06",
    "JUL": "07", "AUG": "08", "SEP": "09", "OCT": "10", "NOV": "11", "DEC": "12"
}

# ==========================================
# 2. å·¥å…·å‡½æ•¸
# ==========================================

def clean_date_str(date_str):
    """æ¸…æ´—æ—¥æœŸå­—ä¸²ï¼Œæ”¯æ´è‹±æ–‡æœˆä»½"""
    if not date_str: return "1900/01/01"
    clean_str = str(date_str).strip()
    
    # è‹±æ–‡æœˆä»½è½‰æ›
    for mon, digit in MONTH_MAP.items():
        if mon in clean_str:
            clean_str = clean_str.replace(mon, digit)
            break
            
    # å»é™¤ä¸­æ–‡å¹´/æœˆ/æ—¥ï¼Œæ”¹ç‚ºæ–œç·š
    clean_str = clean_str.replace("å¹´", "/").replace("æœˆ", "/").replace("æ—¥", "")
    # ç§»é™¤å¤šé¤˜ç¬¦è™Ÿ (å¦‚ Page 1 of 16)
    clean_str = re.split(r"(Page|é )", clean_str, flags=re.IGNORECASE)[0]
    
    try:
        dt = parser.parse(clean_str, fuzzy=True)
        return dt.strftime("%Y/%m/%d")
    except:
        return "1900/01/01"

def clean_value(val_str):
    """æ•¸æ“šæ¸…æ´—"""
    if not val_str: return None
    val_str = str(val_str).strip()
    
    # æ’é™¤ CAS No.
    if re.search(r"\b\d{2,}-\d{2,}-\d{2,}\b", val_str): return None 
    # æ’é™¤éé•·éçµæœå­—ä¸²
    if len(val_str) > 20 and not re.search(r"(negative|positive|n\.d\.)", val_str, re.I): return None

    if re.search(r"(?i)(n\.?d\.?|not detected|<)", val_str): return "N.D."
    if re.search(r"(?i)(negative|é˜´æ€§|é™°æ€§)", val_str): return "NEGATIVE"
    if re.search(r"(?i)(positive|é˜³æ€§|é™½æ€§)", val_str): return "POSITIVE"
    
    match = re.search(r"(\d+\.?\d*)", val_str)
    if match: return float(match.group(1))
    return None

def get_value_priority(val):
    if isinstance(val, (int, float)): return (3, val)
    if val in ["NEGATIVE", "POSITIVE"]: return (2, 0)
    if val == "N.D.": return (1, 0)
    return (0, 0)

# ==========================================
# 3. SGS è§£ææ¨¡çµ„ (é‡æ§‹ç‰ˆ)
# ==========================================

def parse_sgs(pdf_obj, full_text, first_page_text):
    # åˆå§‹åŒ–çµæœå­—å…¸
    result = {k: None for k in SGS_OPTIMIZED_MAP.keys()}
    result['PFAS'] = ""
    result['DATE'] = ""

    # --- 1. æ—¥æœŸæŠ“å– (çµ•å°ä½ç½®é–å®š) ---
    # åªçœ‹å‰ 10 è¡Œï¼Œåªæ‰¾ 'Date:'ï¼Œç›´æ¥è§£æ
    lines = first_page_text.split('\n')
    for line in lines[:15]: 
        # å°‹æ‰¾ Date é—œéµå­—ï¼Œåš´æ ¼æ’é™¤ Received, Testing, Period
        if re.search(r"(?i)(Date|æ—¥æœŸ)\s*[:ï¼š]", line) and not re.search(r"(?i)(Received|Receiving|Testing|Period|æ¥æ”¶|å‘¨æœŸ)", line):
            # æå–å†’è™Ÿå¾Œçš„å…§å®¹
            date_content = re.split(r"[:ï¼š]", line, 1)[1].strip()
            result['DATE'] = clean_date_str(date_content)
            if result['DATE'] != "1900/01/01":
                break
    
    # --- 2. æ•¸æ“šæŠ“å– (ä½¿ç”¨å„ªåŒ–å­—å…¸ + é»‘åå–®å­—ä¸²æ¯”å°) ---
    pbb_sum = 0; pbde_sum = 0; pbb_found = False; pbde_found = False
    
    with pdfplumber.open(pdf_obj) as pdf:
        for page in pdf.pages:
            tables = page.extract_tables()
            for table in tables:
                if not table: continue
                
                for row in table: 
                    # è½‰ç‚ºå­—ä¸²æ–¹ä¾¿æ¯”å°
                    row_str = " ".join([str(c) for c in row if c]).replace("\n", " ")
                    
                    # PFOA æ’é™¤
                    if re.search(r"(?i)(PFOA|Perfluorooctanoic\s*Acid|å…¨æ°Ÿè¾›é…¸)", row_str):
                        continue

                    if "PFAS" in row_str and not result['PFAS']:
                        result['PFAS'] = "REPORT"

                    # A. è­˜åˆ¥æ¸¬é … (ä½¿ç”¨ SGS å„ªåŒ–å­—å…¸)
                    matched_key = None
                    for key, keywords in SGS_OPTIMIZED_MAP.items():
                        # æª¢æŸ¥è©²è¡Œæ˜¯å¦åŒ…å«ä»»ä¸€é—œéµå­—
                        if any(kw.lower() in row_str.lower() for kw in keywords):
                            # PFOS ç‰¹æ®Šé˜²å‘† (é¿å…æŠ“åˆ° derivatives æ¨™é¡Œ)
                            if key == "PFOS" and re.search(r"(?i)(Total|PFOSF|Derivative|æ€»å’Œ|è¡ç”Ÿç‰©)", row_str):
                                continue
                            # é¹µç´ ç‰¹æ®Šé˜²å‘† (é¿å… Fluorine æŠ“åˆ° Halogen - Fluorine æ¨™é¡Œ)
                            if key in ['F', 'Cl', 'Br', 'I'] and not re.search(r"\((F|Cl|Br|I)-?\)", row_str):
                                # è‹¥æ²’æœ‰ (F) (Cl) ç­‰ç¬¦è™Ÿï¼Œå¯èƒ½æ˜¯æ¨™é¡Œè¡Œï¼Œè·³é
                                continue
                                
                            matched_key = key
                            break
                    
                    # å¦‚æœæ²’å°æ‡‰åˆ° SGS å­—å…¸ï¼Œæª¢æŸ¥æ˜¯å¦ç‚º PBB/PBDE ç´°é … (ç”¨æ–¼åŠ ç¸½)
                    is_pbb = re.search(PBB_SUBITEMS, row_str)
                    is_pbde = re.search(PBDE_SUBITEMS, row_str)

                    if not matched_key and not is_pbb and not is_pbde:
                        continue 

                    # B. æŠ“å–æ•¸å€¼ (å³å‘å·¦ + é»‘åå–®å­—ä¸²æ¯”å°)
                    # æŠ“å‡ºæ‰€æœ‰æ½›åœ¨æ•¸å€¼
                    value_candidates = re.findall(r"(?i)(N\.?D\.?|Negative|Positive|<\s*\d+\.?\d*|\b\d+\.?\d*\b)", row_str)
                    
                    found_val = None
                    
                    for raw_val in reversed(value_candidates):
                        # å­—ä¸²æ¯”å°é»‘åå–®
                        check_str = raw_val.strip()
                        if "<" in check_str: check_str = check_str.replace("<", "").strip()
                        
                        # æ ¸å¿ƒé‚è¼¯ï¼šå¦‚æœå­—ä¸²åœ¨å¿½ç•¥æ¸…å–®ä¸­ï¼Œç›´æ¥è·³é
                        if check_str in SGS_IGNORE_LIST:
                            continue 
                        
                        # é€šéé»‘åå–®ï¼Œé€²è¡Œæ¸…æ´—
                        cleaned = clean_value(raw_val)
                        if cleaned is None: continue
                        
                        # äºŒæ¬¡é˜²å‘†ï¼šé˜²æ­¢ '1000.0' é€™ç¨®æ¼ç¶²ä¹‹é­š
                        if isinstance(cleaned, (int, float)):
                            if int(cleaned) == cleaned and str(int(cleaned)) in SGS_IGNORE_LIST:
                                continue

                        # æ‰¾åˆ°æœ‰æ•ˆå€¼
                        found_val = cleaned
                        break 
                    
                    # C. å¡«å…¥çµæœ
                    if found_val is not None:
                        if matched_key:
                            current_val = result[matched_key]
                            if current_val is None or current_val == "N.D.":
                                result[matched_key] = found_val
                            elif isinstance(found_val, (int, float)) and isinstance(current_val, (int, float)):
                                result[matched_key] = max(found_val, current_val)
                        
                        if is_pbb:
                            pbb_found = True
                            if isinstance(found_val, (int, float)): pbb_sum += found_val
                        if is_pbde:
                            pbde_found = True
                            if isinstance(found_val, (int, float)): pbde_sum += found_val

    if "PFAS" in first_page_text: result["PFAS"] = "REPORT"
    result["PBBs"] = pbb_sum if pbb_found and pbb_sum > 0 else "N.D."
    result["PBDEs"] = pbde_sum if pbde_found and pbde_sum > 0 else "N.D."
    return result

# ==========================================
# 4. CTI/Intertek è§£ææ¨¡çµ„ (Regexç‰ˆ - ç¶­æŒåŸæ¨£)
# ==========================================

def parse_cti(pdf_obj, full_text, first_page_text):
    result = {k: None for k in TARGET_ITEMS if k not in ['FILENAME', 'DATE']} # ç°¡åŒ–åˆå§‹åŒ–
    result['PFAS'] = ""
    result['DATE'] = ""
    
    # Bottom-Up æ—¥æœŸ
    lines = first_page_text.split('\n')
    date_pat = re.compile(r"(20\d{2}[\.\-/]\d{2}[\.\-/]\d{2}|[A-Za-z]{3}\.?\s+\d{1,2},?\s+20\d{2})")
    for line in reversed(lines):
        if re.search(r"(?i)(Received|Testing|Period|Rev\.|Revis)", line): continue
        match = date_pat.search(line)
        if match:
            result['DATE'] = clean_date_str(match.group(0))
            break
            
    pbb_sum = 0; pbde_sum = 0; pbb_found = False; pbde_found = False
    with pdfplumber.open(pdf_obj) as pdf:
        for page in pdf.pages:
            tables = page.extract_tables()
            for table in tables:
                if not table: continue
                header = table[0]
                res_idx = -1
                for i, col in enumerate(header):
                    if col and re.search(r"(?i)(Result|ç»“æœ)", str(col)):
                        res_idx = i; break
                if res_idx == -1:
                    for i, col in enumerate(header):
                        if col and re.search(r"(?i)(MDL|LOQ|RL|Limit)", str(col)):
                            res_idx = i - 1 if i > 0 else i + 1; break
                if res_idx == -1: continue

                for row_idx, row in enumerate(table[1:]):
                    if len(row) <= res_idx: continue
                    row_str = " ".join([str(c) for c in row if c]).replace("\n", " ")
                    if re.search(r"(?i)(PFOA|Perfluorooctanoic\s*Acid|å…¨æ°Ÿè¾›é…¸)", row_str): continue
                    
                    raw_val = str(row[res_idx]).strip()
                    val = clean_value(raw_val)
                    if re.search(r"^0\d+$", raw_val) or (re.search(r"^\d{1,3}$", raw_val) and "mg/kg" not in raw_val):
                        if row_idx + 1 < len(table[1:]):
                            next_row = table[1:][row_idx+1]
                            if len(next_row) > res_idx: val = clean_value(next_row[res_idx])
                    
                    if "PFAS" in row_str and not result.get('PFAS'): result['PFAS'] = "REPORT"

                    for pat, key in UNIFIED_REGEX_MAP.items(): # ä½¿ç”¨ Regex å­—å…¸
                        if re.search(pat, row_str):
                            if key == "PFOS" and re.search(r"(?i)(Total|PFOSF|Derivative|æ€»å’Œ|è¡ç”Ÿç‰©)", row_str): continue
                            if val is not None:
                                current_val = result.get(key)
                                if current_val is None or current_val == "N.D.": result[key] = val
                                elif isinstance(val, (int, float)) and isinstance(current_val, (int, float)): result[key] = max(val, current_val)
                            break
                    if re.search(PBB_SUBITEMS, row_str):
                        pbb_found = True; pbb_sum += val if isinstance(val, (int, float)) else 0
                    if re.search(PBDE_SUBITEMS, row_str):
                        pbde_found = True; pbde_sum += val if isinstance(val, (int, float)) else 0

    if "PFAS" in first_page_text: result["PFAS"] = "REPORT"
    result["PBBs"] = pbb_sum if pbb_found and pbb_sum > 0 else "N.D."
    result["PBDEs"] = pbde_sum if pbde_found and pbde_sum > 0 else "N.D."
    return result

def parse_intertek(pdf_obj, full_text, first_page_text):
    result = {k: None for k in TARGET_ITEMS if k not in ['FILENAME', 'DATE']}
    result['PFAS'] = ""
    result['DATE'] = ""

    lines = first_page_text.split('\n')
    date_pat = r"(?i)(?:Date|Issue Date|ë°œí–‰ì¼ì)\s*[:ï¼š]?\s*([A-Za-z]{3}\s+\d{1,2},?\s*\d{4}|\d{4}[.\s]+\d{1,2}[.\s]+\d{1,2})"
    for line in lines[:25]:
        match = re.search(date_pat, line)
        if match:
            result['DATE'] = clean_date_str(match.group(1))
            break
            
    pbb_sum = 0; pbde_sum = 0; pbb_found = False; pbde_found = False
    with pdfplumber.open(pdf_obj) as pdf:
        for page in pdf.pages:
            tables = page.extract_tables()
            for table in tables:
                if not table: continue
                header = table[0]
                mdl_idx = -1
                for i, col in enumerate(header):
                    if col and re.search(r"(?i)(MDL|RL|Limit of Detection|ê²€ì¶œí•œê³„)", str(col)):
                        mdl_idx = i; break
                if mdl_idx == -1: continue 
                
                res_idx = -1
                if len(table) > 1:
                    row1 = table[1]
                    left_val = str(row1[mdl_idx-1]) if mdl_idx > 0 else ""
                    right_val = str(row1[mdl_idx+1]) if mdl_idx + 1 < len(row1) else ""
                    if re.search(r"(?i)(N\.?D|Negative|<)", left_val): res_idx = mdl_idx - 1
                    elif re.search(r"(?i)(N\.?D|Negative|<)", right_val): res_idx = mdl_idx + 1
                    elif mdl_idx + 1 < len(header) and re.search(r"(?i)(Result|ê²°ê³¼)", str(header[mdl_idx+1])): res_idx = mdl_idx + 1
                    elif mdl_idx - 1 >= 0 and re.search(r"(?i)(Result|ç»“æœ)", str(header[mdl_idx-1])): res_idx = mdl_idx - 1
                if res_idx == -1: continue

                for row in table[1:]:
                    if len(row) <= res_idx: continue
                    row_str = " ".join([str(c) for c in row if c]).replace("\n", " ")
                    val = clean_value(row[res_idx])
                    if "PFAS" in row_str and not result.get('PFAS'): result['PFAS'] = "REPORT"
                    for pat, key in UNIFIED_REGEX_MAP.items():
                        if re.search(pat, row_str):
                            if val is not None:
                                current_val = result.get(key)
                                if current_val is None or current_val == "N.D.": result[key] = val
                                elif isinstance(val, (int, float)) and isinstance(current_val, (int, float)): result[key] = max(val, current_val)
                            break
                    if re.search(PBB_SUBITEMS, row_str):
                        pbb_found = True; pbb_sum += val if isinstance(val, (int, float)) else 0
                    if re.search(PBDE_SUBITEMS, row_str):
                        pbde_found = True; pbde_sum += val if isinstance(val, (int, float)) else 0

    if "PFAS" in first_page_text: result["PFAS"] = "REPORT"
    result["PBBs"] = pbb_sum if pbb_found and pbb_sum > 0 else "N.D."
    result["PBDEs"] = pbde_sum if pbde_found and pbde_sum > 0 else "N.D."
    return result

# ==========================================
# 5. ä¸»ç¨‹å¼
# ==========================================

def identify_vendor(first_page_text):
    text = first_page_text.lower()
    if "intertek" in text: return "INTERTEK"
    if "cti" in text or "åæµ‹" in text: return "CTI"
    if "sgs" in text: return "SGS"
    return "UNKNOWN"

def aggregate_reports(valid_results):
    if not valid_results: return pd.DataFrame()
    final_row = {k: None for k in TARGET_ITEMS}
    
    sorted_by_pb = sorted(
        valid_results, 
        key=lambda x: (
            get_value_priority(x.get("Pb"))[0],
            get_value_priority(x.get("Pb"))[1],
            x.get("DATE", "1900/01/01")
        ), 
        reverse=True
    )
    final_row["FILENAME"] = sorted_by_pb[0]["FILENAME"]
    all_dates = [r.get("DATE", "1900/01/01") for r in valid_results if r.get("DATE")]
    final_row["DATE"] = max(all_dates) if all_dates else "Unknown"

    for key in TARGET_ITEMS:
        if key in ["FILENAME", "DATE"]: continue
        best_val = None
        for res in valid_results:
            val = res.get(key)
            if get_value_priority(val) > get_value_priority(best_val):
                best_val = val
        final_row[key] = best_val
    return pd.DataFrame([final_row])

def main():
    st.set_page_config(page_title="åŒ–å­¸å ±å‘Šè‡ªå‹•å½™æ•´ç³»çµ± v4.7 (SGS Optimized)", layout="wide")
    st.title("ğŸ§ª åŒ–å­¸æ¸¬è©¦å ±å‘Šè‡ªå‹•å½™æ•´ç³»çµ± v4.7 (SGS Optimized)")
    st.markdown("""
    **SGS å°ˆå±¬ä¿®æ­£ (åŸºæ–¼ç”¨æˆ¶å„ªåŒ–åˆ—è¡¨)ï¼š**
    1. **å­—å…¸é‡æ§‹**ï¼šæ¡ç”¨ç”¨æˆ¶æä¾›çš„ `SGS Optimization Map`ï¼ŒåŒ…å«ä¸­è‹±æ–‡é—œéµå­—ã€‚
    2. **å®Œæ•´é»‘åå–®**ï¼šæ¢å¾© `1000, 100, 50, 10, 8, 5, 2` éæ¿¾ï¼Œæ¡ç”¨å­—ä¸²ç›´æ¯”ã€‚
    3. **æ—¥æœŸé–å®š**ï¼šé–å®šå‰ 15 è¡Œçš„ `Date:`ï¼Œç›´æ¥è§£æï¼Œé¿å…æŠ“éŒ¯ã€‚
    4. **å¼·åˆ¶é‡ç½®**ï¼šæ¯æ¬¡åŸ·è¡Œè‡ªå‹•æ¸…é™¤å¿«å–ï¼Œé˜²æ­¢çµæœå¡ä½ã€‚
    """)

    uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ PDF å ±å‘Š (æ”¯æ´å¤šæª”)", type="pdf", accept_multiple_files=True)

    if uploaded_files:
        if st.button("é–‹å§‹åˆ†æ"):
            valid_results = []
            bucket_unknown = []
            bucket_error = []
            
            progress_bar = st.progress(0)
            status_text = st.empty()

            for i, file in enumerate(uploaded_files):
                status_text.text(f"æ­£åœ¨è™•ç†: {file.name}...")
                try:
                    with pdfplumber.open(file) as pdf:
                        if len(pdf.pages) == 0:
                            bucket_error.append(file.name)
                            continue
                        
                        first_page_text = pdf.pages[0].extract_text()
                        if not first_page_text:
                            bucket_error.append(f"{file.name} (ç„¡æ³•è®€å–)")
                            continue
                        
                        full_text = ""
                        for page in pdf.pages:
                            txt = page.extract_text()
                            if txt: full_text += txt + "\n"

                    vendor = identify_vendor(first_page_text)
                    
                    data = None
                    if vendor == "SGS":
                        data = parse_sgs(file, full_text, first_page_text)
                    elif vendor == "CTI":
                        data = parse_cti(file, full_text, first_page_text)
                    elif vendor == "INTERTEK":
                        data = parse_intertek(file, full_text, first_page_text)
                    else:
                        if "SGS" in first_page_text:
                            data = parse_sgs(file, full_text, first_page_text)
                        else:
                            bucket_unknown.append(file.name)
                            continue

                    if data:
                        data["
