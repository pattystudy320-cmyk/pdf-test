import streamlit as st
import pdfplumber
import pandas as pd
import re
import math

# --- è¨­å®šé é¢ ---
st.set_page_config(page_title="é€šç”¨æª¢æ¸¬å ±å‘Šæ“·å–å·¥å…· (V8 æœ€çµ‚å®Œç¾ç‰ˆ)", layout="wide")
st.title("ğŸ§ª é€šç”¨å‹ç¬¬ä¸‰æ–¹æª¢æ¸¬å ±å‘Šæ•¸æ“šæ“·å–å·¥å…· (V8 æœ€çµ‚å®Œç¾ç‰ˆ)")
st.markdown("""
**V8 æ ¸å¿ƒå‡ç´šï¼š**
1.  **âš“ é»ƒé‡‘æ¬„ä½é–å®š**ï¼šåˆ©ç”¨ Cd/Hg ç©©å®šæ€§é–å®š Pb æ¬„ä½ï¼Œè§£æ±º SGS Pb(3.53) èª¤åˆ¤å•é¡Œã€‚
2.  **ğŸ›¡ï¸ èªç¾©é˜²ç«ç‰†**ï¼šæœå°‹ Chlorine æ™‚å¼·åˆ¶æ’é™¤ PVCï¼Œè§£æ±º CTI Cl èª¤åˆ¤ç‚º Negativeã€‚
3.  **ğŸ“‘ PFAS å€å¡Šé™å®š**ï¼šåƒ…åœ¨ã€Œæ¸¬è©¦éœ€æ±‚ã€æ®µè½æœå°‹ PFASï¼Œé¿å…èª¤åˆ¤ã€‚
4.  **ğŸ“… æ—¥æœŸè§£æå¢å¼·**ï¼šæ”¯æ´ `æ—¥æœŸ(Date):` ç­‰æ··åˆæ ¼å¼ï¼Œä¸”åƒ…æŠ“å–é¦–é ç°½ç™¼æ—¥ã€‚
5.  **â­• ç©ºå€¼ä¿ç•™**ï¼šæœªæª¢æ¸¬é …ç›®ç¶­æŒç©ºç™½ï¼Œä¸é è¨­ N.D.ã€‚
""")

# --- 1. å®šç¾©ç›®æ¨™æ¬„ä½ ---
TARGET_FIELDS = {
    "Lead": {"name": "Pb", "keywords": [r"^Lead\b", r"^Pb\b", r"é“…", r"Lead \(Pb\)", r"Pb"]},
    "Cadmium": {"name": "Cd", "keywords": [r"^Cadmium\b", r"^Cd\b", r"é•‰", r"Cadmium \(Cd\)", r"Cd"]},
    "Mercury": {"name": "Hg", "keywords": [r"^Mercury\b", r"^Hg\b", r"æ±", r"Mercury \(Hg\)", r"Hg"]},
    "Hexavalent Chromium": {"name": "Cr(VI)", "keywords": [r"Hexavalent Chromium", r"Cr\(VI\)", r"Cr6\+", r"å…­ä»·é“¬", r"å…­åƒ¹é‰»"]},
    "DEHP": {"name": "DEHP", "keywords": [r"Bis\(2-ethylhexyl\) phthalate", r"DEHP", r"é‚»è‹¯äºŒç”²é…¸äºŒ\(2-ä¹™åŸºå·±åŸº\)é…¯"]},
    "BBP": {"name": "BBP", "keywords": [r"Butyl benzyl phthalate", r"BBP", r"é‚»è‹¯äºŒç”²é…¸ä¸åŸºè‹„åŸºé…¯"]},
    "DBP": {"name": "DBP", "keywords": [r"Dibutyl phthalate", r"DBP", r"é‚»è‹¯äºŒç”²é…¸äºŒä¸é…¯"]},
    "DIBP": {"name": "DIBP", "keywords": [r"Diisobutyl phthalate", r"DIBP", r"é‚»è‹¯äºŒç”²é…¸äºŒå¼‚ä¸é…¯"]},
    "Fluorine": {"name": "F", "keywords": [r"Fluorine", r"æ°Ÿ", r"Fluorine \(F\)"]},
    "Chlorine": {"name": "Cl", "keywords": [r"Chlorine", r"æ°¯", r"Chlorine \(Cl\)"]},
    "Bromine": {"name": "Br", "keywords": [r"Bromine", r"æº´", r"Bromine \(Br\)"]},
    "Iodine": {"name": "I", "keywords": [r"Iodine", r"ç¢˜", r"Iodine \(I\)"]},
    "PFOS": {"name": "PFOS", "keywords": [r"Perfluorooctane Sulfonates", r"PFOS", r"å…¨æ°Ÿè¾›ç£ºé…¸"]},
}

PBBS_KEYWORDS = [r"Monobromobiphenyl", r"Dibromobiphenyl", r"Tribromobiphenyl", r"Tetrabromobiphenyl", 
                 r"Pentabromobiphenyl", r"Hexabromobiphenyl", r"Heptabromobiphenyl", r"Octabromobiphenyl", 
                 r"Nonabromobiphenyl", r"Decabromobiphenyl", r"ä¸€æº´è”è‹¯", r"åæº´è”è‹¯", r"ä¸€æº´è¯è‹¯"]
PBDES_KEYWORDS = [r"Monobromodiphenyl ether", r"Dibromodiphenyl ether", r"Tribromodiphenyl ether", 
                  r"Tetrabromodiphenyl ether", r"Pentabromodiphenyl ether", r"Hexabromodiphenyl ether", 
                  r"Heptabromodiphenyl ether", r"Octabromodiphenyl ether", r"Nonabromodiphenyl ether", 
                  r"Decabromodiphenyl ether", r"ä¸€æº´äºŒè‹¯é†š", r"åæº´äºŒè‹¯é†š"]

# --- 2. è¼”åŠ©å‡½å¼ ---

def clean_text(text):
    if not text: return ""
    return re.sub(r'\s+', ' ', str(text)).strip()

def normalize_date(date_str):
    """æ—¥æœŸæ ¼å¼æ¨™æº–åŒ–"""
    if not date_str: return ""
    # ç§»é™¤å‰ç¶´èˆ‡ç„¡é—œå­—å…ƒï¼Œæ”¯æ´ "æ—¥æœŸ(Date):" é€™ç¨®æ ¼å¼
    clean_date = re.sub(r"Date:|Issue Date:|Report Date:|æ—¥æœŸ\s*\(?Date\)?[:ï¼š]?", "", date_str, flags=re.IGNORECASE).strip()
    try:
        # 1. æ•¸å­—æ ¼å¼ (2025.06.16, 2025/06/16)
        match_num = re.search(r"(\d{4})[-/. ](\d{1,2})[-/. ](\d{1,2})", clean_date)
        if match_num:
            return f"{match_num.group(1)}/{int(match_num.group(2)):02d}/{int(match_num.group(3)):02d}"
        
        # è‹±æ–‡æœˆä»½è™•ç†
        months = {"JAN": 1, "FEB": 2, "MAR": 3, "APR": 4, "MAY": 5, "JUN": 6, 
                  "JUL": 7, "AUG": 8, "SEP": 9, "OCT": 10, "NOV": 11, "DEC": 12}
        
        # 2. 16-Jun-25
        match_dd_mon_yy = re.search(r"(\d{1,2})[-/\s]([A-Za-z]{3})[-/\s](\d{2,4})", clean_date, re.IGNORECASE)
        if match_dd_mon_yy:
            d, m_str, y = match_dd_mon_yy.groups()
            m = months.get(m_str.upper(), 0)
            if m > 0:
                if len(y) == 2: y = "20" + y
                return f"{y}/{m:02d}/{int(d):02d}"

        # 3. Jan 08, 2025
        match_mon_dd_yyyy = re.search(r"([A-Za-z]{3})\.?\s+(\d{1,2}),?\s+(\d{4})", clean_date, re.IGNORECASE)
        if match_mon_dd_yyyy:
            m_str, d, y = match_mon_dd_yyyy.groups()
            m = months.get(m_str.upper(), 0)
            if m > 0:
                return f"{y}/{m:02d}/{int(d):02d}"
    except:
        pass
    return ""

def find_date_in_first_page(text):
    """åªåœ¨ç¬¬ä¸€é æŠ“å–æ—¥æœŸ"""
    lines = text.split('\n')
    for line in lines:
        if "RECEIVED" in line.upper() or "PERIOD" in line.upper() or "STARTED" in line.upper(): continue
        
        # æ“´å…… Regex æ”¯æ´ "æ—¥æœŸ(Date)"
        if re.search(r"(Date|Issue Date|Report Date|æ—¥æœŸ)[:ï¼š\s\(]", line, re.IGNORECASE):
            # å„ªå…ˆåŒ¹é…å®Œæ•´æ—¥æœŸæ ¼å¼
            m1 = re.search(r"(\d{4}[-/. ]\d{1,2}[-/. ]\d{1,2})", line)
            if m1: return normalize_date(m1.group(1))
            
            m2 = re.search(r"([A-Za-z]{3}\.?\s+\d{1,2},?\s+\d{4})", line)
            if m2: return normalize_date(m2.group(1))
            
            m3 = re.search(r"(\d{1,2}-[A-Za-z]{3}-\d{2,4})", line)
            if m3: return normalize_date(m3.group(1))
    return ""

def extract_value_logic(val_str):
    """
    V8 æ•¸å€¼æå–ï¼šCAS éæ¿¾ã€å¹´ä»½éæ¿¾ã€å…§å®¹å„ªå…ˆç´š
    """
    if not val_str: return None, "" # æ”¹ç‚ºå›å‚³ None è¡¨ç¤ºæ²’æŠ“åˆ°
    
    val_upper = str(val_str).upper().replace(" ", "")
    
    # 1. CAS é˜²ç«ç‰†
    if re.search(r"\b\d{2,7}-\d{2}-\d\b", val_str): return None, ""

    # 2. æ–‡å­—ç‹€æ…‹
    if "N.D." in val_upper or "ND" in val_upper or "<" in val_upper: return 0, "N.D."
    if "NEGATIVE" in val_upper or "é˜´æ€§" in val_upper: return 0.0001, "NEGATIVE"
    if "POSITIVE" in val_upper or "é˜³æ€§" in val_upper: return 999999, "POSITIVE"
    
    # 3. æ•¸å­—æå–
    val_clean = re.sub(r"(mg/kg|ppm|%|Âµg/cmÂ²|ug/cm2)", "", val_str, flags=re.IGNORECASE)
    match = re.search(r"(\d+(\.\d+)?)", val_clean)
    
    if match:
        num = float(match.group(1))
        # å¹´ä»½éæ¿¾
        if 2010 <= num <= 2030: return None, ""
        return num, match.group(1)
    
    return None, ""

# --- 3. æ ¸å¿ƒè™•ç†é‚è¼¯ ---

def check_pfas_in_section(full_text):
    """
    PFAS å€å¡Šé™å®šï¼šåªåœ¨ Test Requested åˆ° Conclusion ä¹‹é–“æœå°‹
    """
    start_keywords = ["TEST REQUESTED", "æ¸¬è©¦éœ€æ±‚", "TEST REQUEST"]
    end_keywords = ["TEST METHOD", "TEST RESULTS", "CONCLUSION", "æ¸¬è©¦çµæœ", "çµè«–"]
    
    upper_text = full_text.upper()
    start_idx = -1
    end_idx = -1
    
    for kw in start_keywords:
        idx = upper_text.find(kw)
        if idx != -1:
            start_idx = idx
            break
            
    if start_idx == -1: return "" # æ‰¾ä¸åˆ°é–‹å§‹é»ï¼Œä¿å®ˆèµ·è¦‹ä¸å›å‚³ REPORT
    
    # å¾é–‹å§‹é»ä¹‹å¾Œæ‰¾çµæŸé»
    for kw in end_keywords:
        idx = upper_text.find(kw, start_idx)
        if idx != -1:
            end_idx = idx
            break
            
    # å¦‚æœæ‰¾ä¸åˆ°çµæŸé»ï¼Œå°±æœåˆ°æœ€å¾Œ
    if end_idx == -1: end_idx = len(upper_text)
    
    target_section = upper_text[start_idx:end_idx]
    
    if "PFAS" in target_section or "PER- AND POLYFLUOROALKYL" in target_section:
        return "REPORT"
        
    return ""

def get_column_score(header_cells, table_data=None):
    """æ¬Šé‡è©•åˆ†ï¼šæ‰¾å‡ºæœ€åƒ Result çš„æ¬„ä½ç´¢å¼•"""
    scores = {} 
    num_cols = len(header_cells)
    
    exclude_kw = ["ITEM", "METHOD", "UNIT", "MDL", "LOQ", "LIMIT", "REQUIREMENT", "é¡¹ç›®", "æ–¹æ³•", "å•ä½", "é™å€¼", "RL", "CAS", "NO.", "åº"]
    result_kw = ["RESULT", "ç»“æœ", "SAMPLE", "ID", "001", "002", "A1", "DATA", "å«é‡"]
    mdl_kw = ["MDL", "LOQ", "RL", "LIMIT", "é™å€¼"]
    
    for i, cell in enumerate(header_cells):
        if not cell: continue
        txt = clean_text(str(cell)).upper()
        
        score = 0
        
        if any(ex in txt for ex in exclude_kw): score -= 100
        if any(res in txt for res in result_kw): score += 50
        if "CAS" in txt: score -= 200 
        
        if i + 1 < num_cols:
            right_txt = clean_text(str(header_cells[i+1])).upper()
            if any(k in right_txt for k in mdl_kw): score += 30
            
        if i - 1 >= 0:
            left_txt = clean_text(str(header_cells[i-1])).upper()
            if "ITEM" in left_txt or "é¡¹ç›®" in left_txt: score += 20
            
        scores[i] = score

    if table_data and len(table_data) > 3:
        for i in range(num_cols):
            if i not in scores: continue
            sample_vals = []
            for row in table_data[1:5]:
                if i < len(row): sample_vals.append(clean_text(str(row[i])).upper())
            
            is_numeric_or_nd = 0
            is_cas = 0
            is_method = 0
            is_float = 0
            
            for val in sample_vals:
                if "N.D." in val or "NEGATIVE" in val or re.search(r"^\d+(\.\d+)?$", val):
                    is_numeric_or_nd += 1
                # V8 æ–°å¢ï¼šå¦‚æœæ˜¯æµ®é»æ•¸ (å¦‚ 3.53)ï¼Œå¤§å¤§åŠ åˆ† (å› ç‚º MDL/Limit é€šå¸¸æ˜¯æ•´æ•¸)
                if re.search(r"^\d+\.\d+$", val):
                    is_float += 1
                if re.search(r"\d{2,7}-\d{2}-\d", val): is_cas += 1
                if "IEC" in val or "EPA" in val: is_method += 1
            
            if is_cas > 0: scores[i] -= 200
            if is_method > 0: scores[i] -= 100
            if is_numeric_or_nd > 0: scores[i] += 20
            if is_float > 0: scores[i] += 100 # å¼·åŠ›åŠ åˆ†é …

    if not scores: return -1
    best_col = max(scores, key=scores.get)
    if scores[best_col] < -50: return -1
    return best_col

def find_golden_column(table, result_col_idx):
    """
    V8 é»ƒé‡‘æ¬„ä½é–å®šï¼š
    æƒæè¡¨æ ¼ï¼Œçœ‹ Cd, Hg åœ¨ result_col_idx æ˜¯å¦æœ‰å€¼ã€‚
    å¦‚æœæ˜¯ï¼Œå›å‚³ Trueï¼Œè¡¨ç¤ºè©²æ¬„ä½éå¸¸å¯é ã€‚
    """
    if result_col_idx == -1: return False
    
    score = 0
    for row in table:
        if len(row) <= result_col_idx: continue
        row_text = " ".join([str(c).upper() for c in row if c])
        val_text = clean_text(row[result_col_idx])
        val_num, val_disp = extract_value_logic(val_text)
        
        # æª¢æŸ¥éŒ¨é»é—œéµå­—
        if ("CADMIUM" in row_text or "é•‰" in row_text) and (val_disp == "N.D." or val_num > 0):
            score += 1
        if ("MERCURY" in row_text or "æ±" in row_text) and (val_disp == "N.D." or val_num > 0):
            score += 1
            
    return score >= 1 # åªè¦æŠ“åˆ°å…¶ä¸­ä¸€å€‹éŒ¨é»ï¼Œå°±é–å®š

def process_file(uploaded_file):
    filename = uploaded_file.name
    # åˆå§‹å€¼ç‚º Noneï¼Œè¡¨ç¤ºæœªæŠ“å– (å€åˆ† "æœªæŠ“åˆ°" å’Œ "N.D.")
    results = {k: {"val": None, "display": ""} for k in TARGET_FIELDS.keys()}
    results["PBBs"] = {"val": None, "display": "", "sum_val": 0}
    results["PBDEs"] = {"val": None, "display": "", "sum_val": 0}
    results["PFAS"] = ""
    results["Date"] = ""
    
    is_scanned = True
    full_text_content = ""
    
    with pdfplumber.open(uploaded_file) as pdf:
        # A. å…¨æ–‡æƒæ
        for i, page in enumerate(pdf.pages):
            text = page.extract_text()
            if text and len(text) > 50:
                is_scanned = False
                full_text_content += text + "\n"
                if i == 0: results["Date"] = find_date_in_first_page(text)

        if is_scanned: return None, filename

        # PFAS å€å¡Šé™å®šåˆ¤æ–·
        results["PFAS"] = check_pfas_in_section(full_text_content)

        # B. è¡¨æ ¼æ•¸æ“šæå–
        for page in pdf.pages:
            tables = page.extract_tables()
            
            # æ¨¡å¼ 1: çµæ§‹åŒ–è¡¨æ ¼
            if tables:
                for table in tables:
                    if not table or len(table) < 2: continue
                    
                    header_row_idx = -1
                    result_col_idx = -1
                    
                    for r_idx, row in enumerate(table[:6]):
                        row_str = " ".join([str(c).upper() for c in row if c])
                        if ("ITEM" in row_str or "é¡¹ç›®" in row_str) and ("UNIT" in row_str or "MDL" in row_str or "RESULT" in row_str or "ç»“æœ" in row_str):
                            header_row_idx = r_idx
                            result_col_idx = get_column_score(row, table)
                            if result_col_idx == -1 and r_idx + 1 < len(table):
                                result_col_idx = get_column_score(table[r_idx+1], table)
                            break
                    
                    if result_col_idx != -1:
                        # å•Ÿå‹•é»ƒé‡‘æ¬„ä½æª¢æŸ¥
                        is_golden = find_golden_column(table, result_col_idx)
                        
                        for r_idx in range(header_row_idx + 1, len(table)):
                            row = table[r_idx]
                            if len(row) <= result_col_idx: continue
                            
                            item_name = clean_text(row[0])
                            if len(row) > 1: item_name += " " + clean_text(row[1])
                            
                            val_text = clean_text(row[result_col_idx])
                            # å¦‚æœæ˜¯é»ƒé‡‘æ¬„ä½ï¼Œå¼·åˆ¶æ›´æ–° (force_update=True)
                            update_results(results, item_name, val_text, force_update=is_golden)

            # æ¨¡å¼ 2: æ–‡å­—æµ (Fallback)
            # åªæœ‰ç•¶è©²é è¡¨æ ¼æå–ä¸ç†æƒ³æ™‚æ‰ä¾è³´ï¼Œæˆ–è€…é‡å°æ²’æŠ“åˆ°çš„é …ç›®è£œå¼·
            words = page.extract_words(keep_blank_chars=True)
            target_x_center = -1
            for w in words:
                txt = w['text'].upper()
                if txt in ["RESULT", "ç»“æœ", "SAMPLE", "001", "A1"] and "ITEM" not in txt: 
                    target_x_center = (w['x0'] + w['x1']) / 2
                    break
            
            if target_x_center != -1:
                rows = {}
                for w in words:
                    y = round(w['top'] / 5) * 5
                    if y not in rows: rows[y] = []
                    rows[y].append(w)
                
                for y, row_words in rows.items():
                    line_text = " ".join([w['text'] for w in row_words])
                    
                    for field, config in TARGET_FIELDS.items():
                        for kw in config["keywords"]:
                            if re.search(kw, line_text, re.IGNORECASE):
                                # èªç¾©é˜²ç«ç‰†: é˜²æ­¢ Chlorine æŠ“åˆ° Polyvinyl Chloride
                                if field == "Chlorine" and ("POLYVINYL" in line_text.upper() or "PVC" in line_text.upper()):
                                    continue
                                    
                                # å¦‚æœå·²ç¶“æœ‰å€¼(ä¾†è‡ªè¡¨æ ¼)ï¼Œä¸”ä¸æ˜¯ Noneï¼Œå°±ä¸è¦†è“‹
                                if results[field]["val"] is not None: continue

                                for w in row_words:
                                    w_center = (w['x0'] + w['x1']) / 2
                                    if abs(w_center - target_x_center) < 150: 
                                        val, disp = extract_value_logic(w['text'])
                                        if val is not None:
                                            update_results(results, field, disp)
                                            break

                    # PBBs/PBDEs åŠ ç¸½
                    for pbb_kw in PBBS_KEYWORDS + PBDES_KEYWORDS:
                        if re.search(pbb_kw, line_text, re.IGNORECASE):
                             for w in row_words:
                                w_center = (w['x0'] + w['x1']) / 2
                                if abs(w_center - target_x_center) < 150:
                                    val, disp = extract_value_logic(w['text'])
                                    if val is not None and val > 0 and val != 1000:
                                        cat = "PBBs" if any(k in pbb_kw for k in PBBS_KEYWORDS) else "PBDEs"
                                        results[cat]["sum_val"] += val
                                        # æ¨™è¨˜æœ‰æŠ“åˆ°å€¼
                                        results[cat]["val"] = 1 
                                        break

    finalize_results(results)
    
    # å¡«å……ï¼šæœªæŠ“åˆ°çš„ä¿æŒç©ºç™½ (ä¸å¡« N.D.)
    for k, v in results.items():
        if isinstance(v, dict) and "val" in v and v["val"] is None:
            v["display"] = "" # ä¿æŒç©ºç™½
            v["val"] = 0 # æ’åºç”¨é è¨­å€¼

    final_output = {
        "File Name": filename,
        "Pb": results["Lead"]["display"],
        "Cd": results["Cadmium"]["display"],
        "Hg": results["Mercury"]["display"],
        "Cr(VI)": results["Hexavalent Chromium"]["display"],
        "PBBs": results["PBBs"]["display"],
        "PBDEs": results["PBDEs"]["display"],
        "DEHP": results["DEHP"]["display"],
        "BBP": results["BBP"]["display"],
        "DBP": results["DBP"]["display"],
        "DIBP": results["DIBP"]["display"],
        "F": results["Fluorine"]["display"],
        "Cl": results["Chlorine"]["display"],
        "Br": results["Bromine"]["display"],
        "I": results["Iodine"]["display"],
        "PFOS": results["PFOS"]["display"],
        "PFAS": results["PFAS"],
        "Date": results["Date"],
        "_sort_pb": results["Lead"]["val"],
        "_sort_max": max([v["val"] for k, v in results.items() if isinstance(v, dict) and "val" is not None])
    }
    
    return final_output, None

def update_results(results, item_name, val_text, force_update=False):
    item_upper = str(item_name).upper()
    
    # èªç¾©é˜²ç«ç‰†
    if "CHLORINE" in item_upper and ("POLYVINYL" in item_upper or "PVC" in item_upper): return

    val_num, val_disp = extract_value_logic(val_text)
    if val_num is None: return # ç„¡æ•ˆæ•¸å€¼

    for field_key, config in TARGET_FIELDS.items():
        for kw in config["keywords"]:
            if re.search(kw, item_upper, re.IGNORECASE):
                # é»ƒé‡‘æ¬„ä½å¼·åˆ¶æ›´æ–°
                if force_update:
                    results[field_key]["val"] = val_num
                    results[field_key]["display"] = val_disp
                    return

                # æ­£å¸¸æ¯”è¼ƒé‚è¼¯
                current_val = results[field_key]["val"]
                if current_val is None or val_num > current_val:
                    results[field_key]["val"] = val_num
                    results[field_key]["display"] = val_disp
                elif val_num == 0 and (current_val == 0 or current_val is None):
                    # N.D. vs Negative
                    if val_disp == "NEGATIVE": results[field_key]["display"] = "NEGATIVE"
                    elif not results[field_key]["display"]: results[field_key]["display"] = "N.D."
                    results[field_key]["val"] = 0
                return

    for pbb_kw in PBBS_KEYWORDS:
        if re.search(pbb_kw, item_upper, re.IGNORECASE):
            if val_num > 0:
                results["PBBs"]["sum_val"] += val_num
                results["PBBs"]["val"] = 1 # æ¨™è¨˜æœ‰å€¼
            return

    for pbde_kw in PBDES_KEYWORDS:
        if re.search(pbde_kw, item_upper, re.IGNORECASE):
            if val_num > 0:
                results["PBDEs"]["sum_val"] += val_num
                results["PBDEs"]["val"] = 1
            return

def finalize_results(results):
    if results["PBBs"]["sum_val"] > 0:
        results["PBBs"]["display"] = str(round(results["PBBs"]["sum_val"], 2))
    elif results["PBBs"]["val"] is None: # å¦‚æœå®Œå…¨æ²’æŠ“åˆ°å­é …ç›®
        results["PBBs"]["display"] = "" # ä¿æŒç©ºç™½
    else:
        results["PBBs"]["display"] = "N.D."

    if results["PBDEs"]["sum_val"] > 0:
        results["PBDEs"]["display"] = str(round(results["PBDEs"]["sum_val"], 2))
    elif results["PBDEs"]["val"] is None:
        results["PBDEs"]["display"] = ""
    else:
        results["PBDEs"]["display"] = "N.D."

# --- ä¸»ä»‹é¢ ---

uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ PDF æª¢æ¸¬å ±å‘Š (æ”¯æ´ SGS, CTI, Intertek ç­‰)", type="pdf", accept_multiple_files=True)

if uploaded_files:
    all_data = []
    scanned_files = []

    with st.spinner('æ­£åœ¨é€²è¡Œ V8 å¼•æ“åˆ†æ (é»ƒé‡‘é–å®š + èªç¾©é˜²ç«ç‰†)...'):
        for pdf_file in uploaded_files:
            data, scanned_name = process_file(pdf_file)
            if scanned_name:
                scanned_files.append(scanned_name)
            else:
                all_data.append(data)

    if all_data:
        df = pd.DataFrame(all_data)
        if "_sort_pb" in df.columns:
            df = df.sort_values(by=["_sort_pb", "_sort_max"], ascending=[False, False])
            display_df = df.drop(columns=["_sort_pb", "_sort_max"])
        else:
            display_df = df
        
        st.success(f"âœ… æˆåŠŸæ“·å– {len(all_data)} ä»½å ±å‘Šï¼(V8 æ ¸å¿ƒ)")
        st.dataframe(display_df, use_container_width=True)
        
        csv = display_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel/CSV å ±è¡¨",
            data=csv,
            file_name="rohs_report_v8_final.csv",
            mime="text/csv",
        )

    if scanned_files:
        st.error("âš ï¸ ä»¥ä¸‹æª”æ¡ˆç‚ºæƒæåœ–ç‰‡ (ç„¡æ³•æ“·å–æ–‡å­—)ï¼š")
        for f in scanned_files:
            st.write(f"- {f}")

else:
    st.info("è«‹ä¸Šå‚³ PDF æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚")
