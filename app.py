import streamlit as st
import pdfplumber
import pandas as pd
import re
from datetime import datetime

# --- è¨­å®šé é¢ ---
st.set_page_config(page_title="é€šç”¨æª¢æ¸¬å ±å‘Šæ“·å–å·¥å…· (V14 æœ€çµ‚å…¨èƒ½ç‰ˆ)", layout="wide")
st.title("ğŸ§ª é€šç”¨å‹ç¬¬ä¸‰æ–¹æª¢æ¸¬å ±å‘Šæ•¸æ“šæ“·å–å·¥å…· (V14 æœ€çµ‚å…¨èƒ½ç‰ˆ)")
st.markdown("""
**V14 ç‰ˆæœ¬æ›´æ–°æ‘˜è¦ï¼š**
1.  **ğŸ“… æ—¥æœŸé–å®š V2**ï¼šå¼•å…¥ã€Œé»‘åå–®éæ¿¾ã€èˆ‡ã€Œæœ€æ™šæ—¥æœŸæ³•å‰‡ã€ï¼Œç²¾æº–é–å®šç™¼è¡Œæ—¥ï¼Œæ’é™¤æ¥æ”¶/æ¸¬è©¦æ—¥ã€‚
2.  **âˆ‘ æœ‰æ©Ÿç‰©å„ªåŒ–**ï¼šPBBs/PBDEs æ¡ç”¨ã€Œå…¨è¡Œæƒæ+æ™ºæ…§éæ¿¾ã€ï¼Œä¸ä¾è³´æ¬„ä½ï¼Œè§£æ±º Intertek ç©ºå€¼å•é¡Œã€‚
3.  **ğŸ¯ æ ¸å¿ƒä¿ç•™**ï¼šPb é»ƒé‡‘æ¬„ä½ã€Cl PVC é˜²ç«ç‰†ã€PFOS å–®é …ç›´å–ã€‚
""")

# --- 1. å®šç¾©ç›®æ¨™æ¬„ä½ ---
TARGET_FIELDS = {
    "Lead": {"name": "Pb", "keywords": [r"^Lead\b", r"^Pb\b", r"é“…", r"Lead \(Pb\)", r"Pb"]},
    "Cadmium": {"name": "Cd", "keywords": [r"^Cadmium\b", r"^Cd\b", r"é•‰", r"Cadmium \(Cd\)", r"Cd"]},
    "Mercury": {"name": "Hg", "keywords": [r"^Mercury\b", r"^Hg\b", r"æ±", r"Mercury \(Hg\)", r"Hg"]},
    "Hexavalent Chromium": {"name": "Cr(VI)", "keywords": [r"Hexavalent Chromium", r"Cr\(VI\)", r"Cr6\+", r"å…­ä»·é“¬", r"å…­åƒ¹é‰»"]},
    "DEHP": {"name": "DEHP", "keywords": [r"Bis\(2-ethylhexyl\) phthalate", r"DEHP", r"é‚»è‹¯äºŒç”²é…¸äºŒ\(2-ä¹™åŸºå·±åŸº\)é…¯"]},
    "BBP": {"name": "BBP", "keywords": [r"Butyl benzyl phthalate", r"BBP", r"é‚»è‹¯äºŒç”²é…¸ä¸åŸºè‹„åŸºé…¯"]},
    "DBP": {"name": "DBP", "keywords": [r"Dibutyl phthalate", r"DBP", r"é‚»è‹¯äºŒç”²é…¸äºŒä¸é…¯"]},
    "DIBP": {"name": "DIBP", "keywords": [r"Diisobutyl phthalate", r"DIBP", r"é‚»è‹¯äºŒç”²é…¸äºŒå¼‚ä¸é…¯"]},
    "Fluorine": {"name": "F", "keywords": [r"Fluorine", r"æ°Ÿ", r"Fluorine \(F\)"]},
    "Chlorine": {"name": "Cl", "keywords": [r"Chlorine", r"æ°¯", r"Chlorine \(Cl\)"]},
    "Bromine": {"name": "Br", "keywords": [r"Bromine", r"æº´", r"Bromine \(Br\)"]},
    "Iodine": {"name": "I", "keywords": [r"Iodine", r"ç¢˜", r"Iodine \(I\)"]},
    "PFOS": {"name": "PFOS", "keywords": [r"Perfluorooctane Sulfonates", r"PFOS", r"å…¨æ°Ÿè¾›ç£ºé…¸"]},
}

PBBS_KEYWORDS = [r"Monobromobiphenyl", r"Dibromobiphenyl", r"Tribromobiphenyl", r"Tetrabromobiphenyl", 
                 r"Pentabromobiphenyl", r"Hexabromobiphenyl", r"Heptabromobiphenyl", r"Octabromobiphenyl", 
                 r"Nonabromobiphenyl", r"Decabromobiphenyl", r"ä¸€æº´è”è‹¯", r"åæº´è”è‹¯", r"ä¸€æº´è¯è‹¯"]
PBDES_KEYWORDS = [r"Monobromodiphenyl ether", r"Dibromodiphenyl ether", r"Tribromodiphenyl ether", 
                  r"Tetrabromodiphenyl ether", r"Pentabromodiphenyl ether", r"Hexabromodiphenyl ether", 
                  r"Heptabromodiphenyl ether", r"Octabromodiphenyl ether", r"Nonabromodiphenyl ether", 
                  r"Decabromodiphenyl ether", r"ä¸€æº´äºŒè‹¯é†š", r"åæº´äºŒè‹¯é†š"]

# --- 2. è¼”åŠ©å‡½å¼å€ ---

def clean_text(text):
    if not text: return ""
    return re.sub(r'\s+', ' ', str(text)).strip()

def parse_date_obj(date_str):
    """å°‡å­—ä¸²è§£æç‚º datetime ç‰©ä»¶ï¼Œç”¨æ–¼æ¯”è¼ƒæ—¥æœŸå…ˆå¾Œ"""
    clean = re.sub(r"Date:|Issue Date:|Report Date:|æ—¥æœŸ\s*\(?Date\)?[:ï¼š]?", "", date_str, flags=re.IGNORECASE).strip()
    clean = clean.replace("/", "-").replace(".", "-").replace(" ", "-")
    
    # å˜—è©¦å¸¸è¦‹æ ¼å¼
    formats = [
        "%Y-%m-%d", "%d-%b-%Y", "%d-%B-%Y", "%b-%d-%Y", "%B-%d-%Y",
        "%d-%b-%y", "%d-%B-%y"
    ]
    
    for fmt in formats:
        try:
            return datetime.strptime(clean, fmt)
        except:
            continue
            
    # å˜—è©¦ Regex æå–
    try:
        # 2025-06-16
        m = re.search(r"(\d{4})[-/. ](\d{1,2})[-/. ](\d{1,2})", date_str)
        if m: return datetime(int(m.group(1)), int(m.group(2)), int(m.group(3)))
        
        # 16-Jun-2025
        m2 = re.search(r"(\d{1,2})[-/\s]([A-Za-z]{3})[-/\s](\d{4})", date_str, re.IGNORECASE)
        if m2: return datetime.strptime(f"{m2.group(1)}-{m2.group(2)}-{m2.group(3)}", "%d-%b-%Y")
        
        # Jun 16, 2025
        m3 = re.search(r"([A-Za-z]{3})\.?\s+(\d{1,2}),?\s+(\d{4})", date_str, re.IGNORECASE)
        if m3: return datetime.strptime(f"{m3.group(2)}-{m3.group(1)}-{m3.group(3)}", "%d-%b-%Y")
    except:
        pass
    return None

def normalize_date_str(dt_obj):
    """å°‡ datetime ç‰©ä»¶è½‰ç‚º YYYY/MM/DD å­—ä¸²"""
    if dt_obj:
        return dt_obj.strftime("%Y/%m/%d")
    return ""

def find_date_in_first_page(text):
    """
    V14 æ—¥æœŸæŠ“å–é‚è¼¯ï¼š
    1. é»‘åå–®éæ¿¾ (Received, Period, Started...)
    2. æ”¶é›†æ‰€æœ‰å€™é¸æ—¥æœŸ
    3. å–ã€Œæœ€æ™šã€çš„ä¸€å€‹æ—¥æœŸ (Issue Date é€šå¸¸æ˜¯æœ€å¾Œç™¼ç”Ÿçš„)
    """
    lines = text.split('\n')
    candidates = []
    
    blacklist = ["RECEIVED", "PERIOD", "STARTED", "SUBMITTED", "COMPLETED", "æ”¶ä»¶", "é€±æœŸ", "æœŸé—´"]
    
    for line in lines:
        upper_line = line.upper()
        # 1. é»‘åå–®éæ¿¾ï¼šå¦‚æœè©²è¡ŒåŒ…å«é»‘åå–®é—œéµå­—ï¼Œç›´æ¥è·³é
        if any(bad in upper_line for bad in blacklist):
            continue
            
        # 2. å°‹æ‰¾æ—¥æœŸæ ¼å¼ (YYYY/MM/DD, DD-Mon-YYYY)
        # æ ¼å¼ A: 2025.06.16 æˆ– 2025/06/16
        if re.search(r"\d{4}[-/. ]\d{1,2}[-/. ]\d{1,2}", line):
            candidates.append(line)
        # æ ¼å¼ B: 16-Jun-2025 æˆ– Jun 16, 2025
        elif re.search(r"[A-Za-z]{3}", line) and re.search(r"\d{4}", line):
            candidates.append(line)
            
    if not candidates:
        return ""
        
    # 3. è§£æå€™é¸æ—¥æœŸä¸¦æ‰¾å‡ºæœ€æ™šçš„ä¸€å¤©
    valid_dates = []
    for c in candidates:
        dt = parse_date_obj(c)
        if dt:
            # ç°¡å–®éæ¿¾ï¼šå¹´ä»½å¿…é ˆåˆç† (ä¾‹å¦‚ 2010~2030)
            if 2010 <= dt.year <= 2030:
                valid_dates.append(dt)
    
    if valid_dates:
        latest_date = max(valid_dates) # å–æœ€æ™šæ—¥æœŸ
        return normalize_date_str(latest_date)
        
    return ""

def extract_value_logic(val_str, strict_numeric=False):
    """
    æ•¸å€¼æå–é‚è¼¯
    strict_numeric: ç”¨æ–¼ Cl/PFOSï¼Œæ‹’çµ• Negative
    """
    if not val_str: return None, ""
    
    val_upper = str(val_str).upper().replace(" ", "")
    
    # CAS é˜²ç«ç‰†
    if re.search(r"\b\d{2,7}-\d{2}-\d\b", val_str): return None, ""

    if "N.D." in val_upper or "ND" in val_upper or "<" in val_upper: return 0, "N.D."
    
    if "NEGATIVE" in val_upper or "é˜´æ€§" in val_upper: 
        if strict_numeric: return None, "" # Cl/PFOS ä¸æ¥å— Negative
        return 0.0001, "NEGATIVE"
        
    if "POSITIVE" in val_upper or "é˜³æ€§" in val_upper: 
        if strict_numeric: return None, ""
        return 999999, "POSITIVE"
    
    val_clean = re.sub(r"(mg/kg|ppm|%|Âµg/cmÂ²|ug/cm2)", "", val_str, flags=re.IGNORECASE)
    match = re.search(r"(\d+(\.\d+)?)", val_clean)
    
    if match:
        num = float(match.group(1))
        # å¹´ä»½éæ¿¾
        if 2010 <= num <= 2030: return None, ""
        return num, match.group(1)
    
    return None, ""

def check_pfas_in_section(full_text):
    """PFAS å€å¡Šé™å®š"""
    start_keywords = ["TEST REQUESTED", "æ¸¬è©¦éœ€æ±‚", "TEST REQUEST"]
    end_keywords = ["TEST METHOD", "TEST RESULTS", "CONCLUSION", "æ¸¬è©¦çµæœ", "çµè«–"]
    
    upper_text = full_text.upper()
    start_idx = -1
    end_idx = -1
    
    for kw in start_keywords:
        idx = upper_text.find(kw)
        if idx != -1:
            start_idx = idx
            break
    if start_idx == -1: return "" 
    
    for kw in end_keywords:
        idx = upper_text.find(kw, start_idx)
        if idx != -1:
            end_idx = idx
            break
    if end_idx == -1: end_idx = len(upper_text)
    
    target_section = upper_text[start_idx:end_idx]
    if "PFAS" in target_section or "PER- AND POLYFLUOROALKYL" in target_section:
        return "REPORT"
    return ""

def get_column_score(header_cells, table_data=None):
    """æ‰¾å‡ºæœ€åƒ Result çš„æ¬„ä½ç´¢å¼•"""
    scores = {} 
    num_cols = len(header_cells)
    
    exclude_kw = ["ITEM", "METHOD", "UNIT", "MDL", "LOQ", "LIMIT", "REQUIREMENT", "é¡¹ç›®", "æ–¹æ³•", "å•ä½", "é™å€¼", "RL", "CAS", "NO.", "åº"]
    result_kw = ["RESULT", "ç»“æœ", "SAMPLE", "ID", "001", "002", "A1", "DATA", "å«é‡"]
    mdl_kw = ["MDL", "LOQ", "RL", "LIMIT", "é™å€¼"]
    
    for i, cell in enumerate(header_cells):
        if not cell: continue
        txt = clean_text(str(cell)).upper()
        
        score = 0
        if any(ex in txt for ex in exclude_kw): score -= 100
        if any(res in txt for res in result_kw): score += 50
        if "CAS" in txt: score -= 200 
        
        if i + 1 < num_cols:
            right_txt = clean_text(str(header_cells[i+1])).upper()
            if any(k in right_txt for k in mdl_kw): score += 30
        if i - 1 >= 0:
            left_txt = clean_text(str(header_cells[i-1])).upper()
            if "ITEM" in left_txt or "é¡¹ç›®" in left_txt: score += 20
            
        scores[i] = score

    if table_data and len(table_data) > 3:
        for i in range(num_cols):
            if i not in scores: continue
            sample_vals = []
            for row in table_data[1:6]:
                if i < len(row): sample_vals.append(clean_text(str(row[i])).upper())
            
            is_numeric_or_nd = 0
            is_cas = 0
            is_method = 0
            is_float = 0
            
            for val in sample_vals:
                if "N.D." in val or "NEGATIVE" in val or re.search(r"^\d+(\.\d+)?$", val): is_numeric_or_nd += 1
                if re.search(r"^\d+\.\d+$", val): is_float += 1
                if re.search(r"\d{2,7}-\d{2}-\d", val): is_cas += 1
                if "IEC" in val or "EPA" in val: is_method += 1
            
            if is_cas > 0: scores[i] -= 200
            if is_method > 0: scores[i] -= 100
            if is_numeric_or_nd > 0: scores[i] += 20
            if is_float > 0: scores[i] += 100

    if not scores: return -1
    best_col = max(scores, key=scores.get)
    if scores[best_col] < -50: return -1
    return best_col

def find_golden_column(table, result_col_idx):
    """åˆ©ç”¨ Cd/Hg é–å®š Result æ¬„ä½"""
    if result_col_idx == -1: return False
    score = 0
    for row in table:
        if len(row) <= result_col_idx: continue
        row_text = " ".join([str(c).upper() for c in row if c])
        val_text = clean_text(row[result_col_idx])
        val_num, val_disp = extract_value_logic(val_text)
        
        if val_num is not None:
            if ("CADMIUM" in row_text or "é•‰" in row_text) and (val_disp == "N.D." or val_num > 0): score += 1
            if ("MERCURY" in row_text or "æ±" in row_text) and (val_disp == "N.D." or val_num > 0): score += 1
            
    return score >= 1

def process_file(uploaded_file):
    filename = uploaded_file.name
    results = {k: {"val": None, "display": ""} for k in TARGET_FIELDS.keys()}
    results["PBBs"] = {"val": None, "display": "", "sum_val": 0}
    results["PBDEs"] = {"val": None, "display": "", "sum_val": 0}
    results["PFAS"] = ""
    results["Date"] = ""
    
    is_scanned = True
    full_text_content = ""
    
    with pdfplumber.open(uploaded_file) as pdf:
        # A. å…¨æ–‡æƒæ
        for i, page in enumerate(pdf.pages):
            text = page.extract_text()
            if text and len(text) > 50:
                is_scanned = False
                full_text_content += text + "\n"
                if i == 0: results["Date"] = find_date_in_first_page(text)

        if is_scanned: return None, filename
        results["PFAS"] = check_pfas_in_section(full_text_content)

        # B. è¡¨æ ¼æ•¸æ“šæå– (V14 åˆ†æµèˆ‡å„ªåŒ–)
        for page in pdf.pages:
            tables = page.extract_tables()
            if tables:
                for table in tables:
                    if not table or len(table) < 2: continue
                    
                    header_row_idx = -1
                    result_col_idx = -1
                    
                    # 1. å®šä½ Result æ¬„ä½ (ç‚ºäº†é‡é‡‘å±¬å’Œå–®é …)
                    for r_idx, row in enumerate(table[:6]):
                        row_str = " ".join([str(c).upper() for c in row if c])
                        if ("ITEM" in row_str or "é¡¹ç›®" in row_str) and ("UNIT" in row_str or "MDL" in row_str or "RESULT" in row_str or "ç»“æœ" in row_str):
                            header_row_idx = r_idx
                            result_col_idx = get_column_score(row, table)
                            if result_col_idx == -1 and r_idx + 1 < len(table):
                                result_col_idx = get_column_score(table[r_idx+1], table)
                            break
                    
                    start_row = header_row_idx + 1 if header_row_idx != -1 else 0
                    is_golden_table = find_golden_column(table, result_col_idx) if result_col_idx != -1 else False

                    # 2. éæ­·è¡¨æ ¼è¡Œ
                    for r_idx in range(start_row, len(table)):
                        row = table[r_idx]
                        if not row: continue
                        
                        item_name = clean_text(row[0])
                        if len(row) > 1: item_name += " " + clean_text(row[1])
                        item_upper = item_name.upper()

                        # =======================================================
                        # [V14] ç­–ç•¥ A: PBBs/PBDEs å…¨åŸŸåŠ ç¸½ + æ™ºæ…§éæ¿¾
                        # =======================================================
                        def process_organic_sum(keywords_list, category_key):
                            if any(re.search(kw, item_upper, re.IGNORECASE) for kw in keywords_list):
                                # æƒææ•´è¡Œï¼Œå°‹æ‰¾åˆé©æ•¸å€¼
                                potential_vals = []
                                for cell in row:
                                    v_num, v_disp = extract_value_logic(clean_text(str(cell)))
                                    if v_num is not None:
                                        # [é—œéµ] æ’é™¤ Limit (1000) å’Œ MDL (5, 10) å¹²æ“¾
                                        if v_num in [5, 10, 50, 100, 1000] and v_disp != "N.D.": 
                                            continue 
                                        potential_vals.append(v_num)
                                
                                if potential_vals:
                                    val = potential_vals[-1] # å–æœ€å¾Œä¸€å€‹æœ‰æ•ˆå€¼
                                    if val > 0:
                                        results[category_key]["sum_val"] += val
                                        results[category_key]["val"] = 1

                        process_organic_sum(PBBS_KEYWORDS, "PBBs")
                        process_organic_sum(PBDES_KEYWORDS, "PBDEs")

                        # =======================================================
                        # [V14] ç­–ç•¥ B: å–®é …æ•¸å€¼ (Pb, Cl, PFOS) - ä¾è³´æ¬„ä½å®šä½
                        # =======================================================
                        if result_col_idx != -1 and len(row) > result_col_idx:
                            val_text = clean_text(row[result_col_idx])
                            
                            # èªç¾©é˜²ç«ç‰† (Cl)
                            if "CHLORINE" in item_upper and ("POLYVINYL" in item_upper or "PVC" in item_upper):
                                continue

                            # åš´æ ¼å‹åˆ¥ (Cl, Br, PFOS)
                            is_strict = any(x in item_upper for x in ["CHLORINE", "BROMINE", "PFOS", "FLUORINE", "IODINE"])
                            
                            val_num, val_disp = extract_value_logic(val_text, strict_numeric=is_strict)
                            
                            if val_num is not None:
                                update_results(results, item_name, val_num, val_disp, is_golden_col=is_golden_table)

            # C. æ–‡å­—æµæ¨¡å¼ (Fallback)
            words = page.extract_words(keep_blank_chars=True)
            target_x_center = -1
            for w in words:
                txt = w['text'].upper()
                if txt in ["RESULT", "ç»“æœ", "SAMPLE", "001", "A1"] and "ITEM" not in txt: 
                    target_x_center = (w['x0'] + w['x1']) / 2
                    break
            
            if target_x_center != -1:
                rows = {}
                for w in words:
                    y = round(w['top'] / 5) * 5
                    if y not in rows: rows[y] = []
                    rows[y].append(w)
                
                for y, row_words in rows.items():
                    line_text = " ".join([w['text'] for w in row_words])
                    
                    # è£œæ¼ PBBs (æ–‡å­—æµæ¨¡å¼)
                    for pbb_kw in PBBS_KEYWORDS + PBDES_KEYWORDS:
                        if re.search(pbb_kw, line_text, re.IGNORECASE):
                             for w in row_words:
                                w_center = (w['x0'] + w['x1']) / 2
                                if abs(w_center - target_x_center) < 150:
                                    val, disp = extract_value_logic(w['text'])
                                    if val is not None and val > 0 and val not in [1000, 5, 25]:
                                        cat = "PBBs" if any(k in pbb_kw for k in PBBS_KEYWORDS) else "PBDEs"
                                        results[cat]["sum_val"] += val
                                        results[cat]["val"] = 1 
                                        break

    finalize_results(results)
    
    # å¡«å……
    for k, v in results.items():
        if isinstance(v, dict) and "val" in v and v["val"] is None:
            v["display"] = "" # ä¿æŒç©ºç™½
            v["val"] = 0

    final_output = {
        "File Name": filename,
        "Pb": results["Lead"]["display"],
        "Cd": results["Cadmium"]["display"],
        "Hg": results["Mercury"]["display"],
        "Cr(VI)": results["Hexavalent Chromium"]["display"],
        "PBBs": results["PBBs"]["display"],
        "PBDEs": results["PBDEs"]["display"],
        "DEHP": results["DEHP"]["display"],
        "BBP": results["BBP"]["display"],
        "DBP": results["DBP"]["display"],
        "DIBP": results["DIBP"]["display"],
        "F": results["Fluorine"]["display"],
        "Cl": results["Chlorine"]["display"],
        "Br": results["Bromine"]["display"],
        "I": results["Iodine"]["display"],
        "PFOS": results["PFOS"]["display"],
        "PFAS": results["PFAS"],
        "Date": results["Date"],
        "_sort_pb": results["Lead"]["val"],
        "_sort_max": max([v["val"] for k, v in results.items() if isinstance(v, dict) and v["val"] is not None])
    }
    
    return final_output, None

def update_results(results, item_name, val_num, val_disp, is_golden_col=False):
    item_upper = str(item_name).upper()
    
    for field_key, config in TARGET_FIELDS.items():
        for kw in config["keywords"]:
            if re.search(kw, item_upper, re.IGNORECASE):
                # é»ƒé‡‘æ¬„ä½å¼·åˆ¶æ›´æ–° (åªé‡å°é‡é‡‘å±¬)
                if is_golden_col and field_key in ["Lead", "Cadmium", "Mercury", "Hexavalent Chromium"]:
                    results[field_key]["val"] = val_num
                    results[field_key]["display"] = val_disp
                    return

                # ä¸€èˆ¬æ›´æ–° (æ¯”å¤§å°)
                current_val = results[field_key]["val"]
                if current_val is None or val_num > current_val:
                    results[field_key]["val"] = val_num
                    results[field_key]["display"] = val_disp
                elif val_num == 0 and (current_val == 0 or current_val is None):
                    if val_disp == "NEGATIVE": results[field_key]["display"] = "NEGATIVE"
                    elif not results[field_key]["display"]: results[field_key]["display"] = "N.D."
                    results[field_key]["val"] = 0
                return

def finalize_results(results):
    if results["PBBs"]["sum_val"] > 0:
        results["PBBs"]["display"] = str(round(results["PBBs"]["sum_val"], 2))
    elif results["PBBs"]["val"] is None:
        results["PBBs"]["display"] = ""
    else:
        results["PBBs"]["display"] = "N.D."

    if results["PBDEs"]["sum_val"] > 0:
        results["PBDEs"]["display"] = str(round(results["PBDEs"]["sum_val"], 2))
    elif results["PBDEs"]["val"] is None:
        results["PBDEs"]["display"] = ""
    else:
        results["PBDEs"]["display"] = "N.D."

# --- ä¸»ä»‹é¢ ---
uploaded_files = st.file_uploader("è«‹ä¸Šå‚³ PDF æª¢æ¸¬å ±å‘Š (æ”¯æ´ SGS, CTI, Intertek ç­‰)", type="pdf", accept_multiple_files=True)

if uploaded_files:
    all_data = []
    scanned_files = []

    with st.spinner('æ­£åœ¨é€²è¡Œ V14 å¼•æ“åˆ†æ (å…¨èƒ½æ—¥æœŸé–å®š + æœ‰æ©Ÿç‰©å…¨åŸŸæƒæ)...'):
        for pdf_file in uploaded_files:
            data, scanned_name = process_file(pdf_file)
            if scanned_name:
                scanned_files.append(scanned_name)
            else:
                all_data.append(data)

    if all_data:
        df = pd.DataFrame(all_data)
        if "_sort_pb" in df.columns:
            df = df.sort_values(by=["_sort_pb", "_sort_max"], ascending=[False, False])
            display_df = df.drop(columns=["_sort_pb", "_sort_max"])
        else:
            display_df = df
        
        st.success(f"âœ… æˆåŠŸæ“·å– {len(all_data)} ä»½å ±å‘Šï¼(V14 æ ¸å¿ƒ)")
        st.dataframe(display_df, use_container_width=True)
        
        csv = display_df.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Excel/CSV å ±è¡¨",
            data=csv,
            file_name="rohs_report_v14_final.csv",
            mime="text/csv",
        )

    if scanned_files:
        st.error("âš ï¸ ä»¥ä¸‹æª”æ¡ˆç‚ºæƒæåœ–ç‰‡ (ç„¡æ³•æ“·å–æ–‡å­—)ï¼š")
        for f in scanned_files:
            st.write(f"- {f}")
else:
    st.info("è«‹ä¸Šå‚³ PDF æª”æ¡ˆä»¥é–‹å§‹åˆ†æã€‚")
