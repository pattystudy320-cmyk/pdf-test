import streamlit as st
import pdfplumber
import pandas as pd
import re
from dateutil import parser
import io

# è¨­å®šé é¢è³‡è¨Š
st.set_page_config(page_title="SGS Report Parser", layout="wide")
st.title("ğŸ“„ SGS Report æª¢æ¸¬çµæœå½™ç¸½å·¥å…· (DEHP ä¿®æ­£ç‰ˆ)")

# =========================
# 1. æ¬„ä½å®šç¾©è¦å‰‡
# =========================
ITEM_RULES = {
    "Pb": r"Lead\s*\(Pb\)",
    "Cd": r"Cadmium\s*\(Cd\)",
    "Hg": r"Mercury\s*\(Hg\)",
    "CrVI": r"Hexavalent Chromium",
    "PBBs": r"Sum of PBBs",
    "PBDEs": r"Sum of PBDEs",
    "DEHP": r"DEHP|Di\(2-ethylhexyl\)\s*phthalate",
    "BBP": r"BBP|Benzyl\s*butyl\s*phthalate",
    "DBP": r"DBP|Dibutyl\s*phthalate",
    "DIBP": r"DIBP|Diisobutyl\s*phthalate",
    "F": r"\bFluorine\b",
    "CL": r"\bChlorine\b",
    "BR": r"\bBromine\b",
    "I": r"\bIodine\b",
    "PFOS": r"PFOS"
}

FINAL_COLUMNS = [
    "Pb", "Cd", "Hg", "CrVI", "PBBs", "PBDEs",
    "DEHP", "BBP", "DBP", "DIBP",
    "F", "CL", "BR", "I",
    "PFOS", "PFAS", "DATE"
]

# =========================
# 2. æ ¸å¿ƒåŠŸèƒ½å‡½å¼
# =========================

def extract_text_and_pages(pdf_file):
    """è®€å– PDF æ–‡å­—å…§å®¹"""
    full_text = ""
    pages_text = []
    with pdfplumber.open(pdf_file) as pdf:
        for page in pdf.pages:
            text = page.extract_text() or ""
            pages_text.append(text)
            full_text += text + "\n"
    return full_text, pages_text

def extract_result(text, keyword, item_name):
    """
    V6 æœ€çµ‚é‚è¼¯:
    1. DEHP ç‰¹ä¾‹: æ“´å¤§è®€å– 4 è¡Œï¼Œä¸¦åˆªé™¤åå­—è£¡çš„ "2"ã€‚
    2. é™¤å™ª: åˆªé™¤ Max, MDL, Year, CASã€‚
    3. N.D. å„ªå…ˆ: åªè¦æœ‰ N.D. å°±å›å‚³ã€‚
    4. æ•¸å­—è¨ˆæ•¸: 
       - PBBs/PBDEs: 1 å€‹æ•¸å­— -> Result
       - å…¶ä»–: 1 å€‹æ•¸å­— -> MDL (å›å‚³ N.D.) / 2 å€‹æ•¸å­— -> å–ç¬¬ 1 å€‹
    """
    lines = text.splitlines()

    for i, line in enumerate(lines):
        # æ­¥é©Ÿ A: é–å®šé—œéµå­—æ‰€åœ¨çš„è¡Œ
        if re.search(keyword, line, re.IGNORECASE):
            
            # --- DEHP ç‰¹ä¾‹è¨­å®š 1: æ“´å¤§è¦–é‡ ---
            if item_name == "DEHP":
                # DEHP åå­—é•·ä¸”å¸¸æ›è¡Œï¼Œå¤šè®€å¹¾è¡Œç¢ºä¿æŠ“åˆ° N.D.
                context = " ".join(lines[i:i+4])
            else:
                # ä¸€èˆ¬é …ç›®è®€ 2 è¡Œå°±å¤  (é¿å…æŠ“åˆ°åˆ¥æ¬„)
                context = " ".join(lines[i:i+2])

            # ==========================================
            # æ­¥é©Ÿ B: æ‰‹è¡“å®¤ - å¼·åŠ›åˆ‡é™¤é›œè¨Š
            # ==========================================
            
            # --- DEHP ç‰¹ä¾‹è¨­å®š 2: æ¶ˆæ»…å…§é¬¼ ---
            if item_name == "DEHP":
                # åˆªé™¤ "2-ethylhexyl" å’Œ "Di(2-"ï¼Œé¿å…æŠ“åˆ°åå­—è£¡çš„ 2
                context = re.sub(r"2-ethylhexyl", " ", context, flags=re.IGNORECASE)
                context = re.sub(r"Di\(2-", " ", context, flags=re.IGNORECASE)

            # 1. åˆ‡é™¤å–®ä½
            context = re.sub(r"mg/kg|ppm|%|wt%", " ", context, flags=re.IGNORECASE)

            # 2. åˆ‡é™¤ CAS No.
            context = re.sub(r"\(?CAS\s*No\.?[\s\d-]+\)?", " ", context, flags=re.IGNORECASE)

            # 3. åˆ‡é™¤ æ¨™æº–ç·¨è™Ÿèˆ‡å¹´ä»½
            context = re.sub(r"IEC\s*62321[-\d:+A]*", " ", context, flags=re.IGNORECASE)
            context = re.sub(r"\b(19|20)\d{2}\b", " ", context) 

            # 4. åˆ‡é™¤ Limit / MDL æ¨™ç±¤èˆ‡æ•¸å€¼
            context = re.sub(r"(Max|Limit|MDL|LOQ)\s*\d+(\.\d+)?", " ", context, flags=re.IGNORECASE)

            # ==========================================
            # æ­¥é©Ÿ C: N.D. åˆ¤å®š (æœ€é«˜å„ªå…ˆç´š)
            # ==========================================
            
            nd_pattern = r"(\bN\s*\.?\s*D\s*\.?\b)|(Not\s*Detected)"
            if re.search(nd_pattern, context, re.IGNORECASE):
                return "N.D."
            
            if re.search(r"NEGATIVE", context, re.IGNORECASE):
                return "NEGATIVE"

            # ==========================================
            # æ­¥é©Ÿ D: æ•¸å­—è¨ˆæ•¸æ³• (æ ¸å¿ƒé‚è¼¯)
            # ==========================================
            
            nums = re.findall(r"\b\d+(?:\.\d+)?\b", context)
            
            if not nums:
                return "N.D."

            # --- ä¾ç…§ Item æ±ºå®šç­–ç•¥ ---
            
            # ç‰¹æ¬Šé …ç›®: PBBs / PBDEs (MDL ç‚º Dash "-")
            if item_name in ["PBBs", "PBDEs"]:
                return nums[0] # ç›´æ¥å›å‚³å”¯ä¸€çš„æ•¸å­—
            
            # ä¸€èˆ¬é …ç›®: Pb, Cd, DEHP ç­‰ (MDL å¿…å¡«)
            else:
                if len(nums) >= 2:
                    # å‰©ä¸‹å…©å€‹ä»¥ä¸Šæ•¸å­—ï¼š[çµæœ] [MDL] -> å–ç¬¬ 1 å€‹
                    found_val = nums[0]
                    # é˜²å‘†ï¼šå¦‚æœæ˜¯å¹´ä»½æ®˜æ¸£
                    try:
                        f_val = float(found_val)
                        if 1990 <= f_val <= 2030 and f_val.is_integer():
                             return nums[1]
                    except:
                        pass
                    return found_val
                
                elif len(nums) == 1:
                    # åªå‰©ä¸‹ä¸€å€‹æ•¸å­—ï¼Œæ¥µå¤§æ©Ÿç‡æ˜¯ MDL (å¦‚ 2.0, 50.0) -> å¼·åˆ¶åˆ¤å®šç‚º N.D.
                    return "N.D."

    return ""

def extract_pfas(text):
    return "REPORT" if re.search(r"\bPFAS\b", text, re.IGNORECASE) else ""

def extract_date(first_page_text):
    match = re.search(
        r"(REPORTED DATE|TEST REPORT REPORTED DATE)\s*[:\-]?\s*([^\n]+)",
        first_page_text,
        re.IGNORECASE
    )
    return match.group(2).strip() if match else ""

def normalize_date(date_text):
    if not date_text:
        return ""
    try:
        dt = parser.parse(date_text, dayfirst=True)
        return dt.strftime("%Y/%m/%d")
    except:
        return ""

def merge_results(values):
    nums = []
    has_nd = False
    has_neg = False

    for v in values:
        if not v:
            continue
        v_upper = str(v).upper()
        
        if "N.D." in v_upper:
            has_nd = True
        elif "NEGATIVE" in v_upper:
            has_neg = True
        else:
            try:
                nums.append(float(v))
            except:
                pass

    if nums:
        return str(max(nums))
    if has_neg:
        return "NEGATIVE"
    if has_nd:
        return "N.D."
    return ""

# =========================
# 3. Streamlit ä¸»ç¨‹å¼ä»‹é¢
# =========================

uploaded_files = st.file_uploader(
    "è«‹ä¸Šå‚³ SGS PDF Reportï¼ˆå¯ä¸€æ¬¡å¤šé¸ï¼‰",
    type="pdf",
    accept_multiple_files=True
)

if uploaded_files:
    rows = []
    for file in uploaded_files:
        full_text, pages_text = extract_text_and_pages(file)
        record = {}

        # å‚³å…¥ item name ä»¥ä¾¿å•Ÿç”¨ DEHP ç‰¹ä¾‹é‚è¼¯
        for item, keyword in ITEM_RULES.items():
            record[item] = extract_result(full_text, keyword, item)

        record["PFAS"] = extract_pfas(full_text)
        raw_date = extract_date(pages_text[0]) if pages_text else ""
        record["DATE"] = normalize_date(raw_date)

        rows.append(record)

    df_all = pd.DataFrame(rows)

    # åŒæ‰¹æ¬¡å½™ç¸½
    merged = {}
    if not df_all.empty:
        for col in FINAL_COLUMNS:
            if col in ["DATE", "PFAS"]:
                continue
            if col in df_all.columns:
                merged[col] = merge_results(df_all[col].tolist())
            else:
                merged[col] = ""

        merged["PFAS"] = "REPORT" if "REPORT" in df_all["PFAS"].tolist() else ""
        
        valid_dates = [d for d in df_all["DATE"] if d]
        merged["DATE"] = max(valid_dates) if valid_dates else ""

        df_final = pd.DataFrame([merged], columns=FINAL_COLUMNS)

        st.subheader("ğŸ“Š å½™ç¸½çµæœï¼ˆåŒæ‰¹ SGS Reportï¼‰")
        st.dataframe(df_final, use_container_width=True)

        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df_final.to_excel(writer, sheet_name="SGS_Result", index=False)

        st.download_button(
            "â¬‡ï¸ ä¸‹è¼‰å…¬å¸åˆ¶å¼ Excel",
            output.getvalue(),
            file_name="SGS_Test_Result.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    else:
        st.warning("æœªè®€å–åˆ°æœ‰æ•ˆè³‡æ–™ã€‚")
